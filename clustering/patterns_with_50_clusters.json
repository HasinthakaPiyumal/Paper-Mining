{"Pattern Name":{"0":"LLM as a Knowledge Base Augmenter","1":"LLM as a Content Interpreter","2":"LLM as an Explainer","3":"LLM for In-Context Learning Recommendations","4":"Chain-of-Thought Prompting","5":"LLM for Automated ML (AutoML) Search","6":"LLM as a Conversational Recommender Agent","7":"LLM as a Tool Orchestrator","8":"LLM as a Personalized Content Creator (AIGC for Personalization)","9":"Agent-Computer Interface (ACI)","10":"LM-Friendly Search and Navigation","11":"LM-Centric File Editing with Guardrails","12":"Context Management for Agents","13":"LLM-Powered Symbolic World Model Engineering","14":"LLM as Goal Translator","15":"Classical Planner with LLM-Acquired World Model","16":"LLM Planner with Symbolic Validation and Feedback","17":"LLM as a Planner","18":"Feedback Integration","19":"Tool Selection","20":"Prompt-based Tool Understanding","21":"Chain of Thought (CoT) Prompting","22":"Introspective Reasoning","23":"Extrospective Reasoning","24":"Formalism-Enhanced Reasoning","25":"Parallel Tool Execution","26":"Multi-Agent Collaboration","27":"Self-supervised Tool Learning","28":"Reinforcement Learning from Human Feedback (RLHF) for Tool Learning","29":"Unified Tool Interface","30":"Meta Tool Learning","31":"Curriculum Tool Learning","32":"AI-Driven Tool Creation\/Encapsulation","33":"Personalized Tool Learning","34":"Proactive AI Agent","35":"Conflict Resolution for Augmented Knowledge","36":"Task Decomposition","37":"Multiplan Selection","38":"External Planner-Aided Planning","39":"Reflection and Refinement","40":"Memory-Augmented Planning","41":"LLMPlanner (Embodied Agent Few-Shot Grounded Planning)","42":"Hierarchical Planning for Embodied Agents","43":"LLM as a Planner","44":"Grounded Replanning (with LLMs)","45":"In-Context Learning for Agent Planning","46":"Dynamic In-Context Example Retrieval","47":"Logit Biases for LLM Output Constraint","48":"Retrieval-Augmented Generation (RAG)","49":"RAGSequence","50":"RAGToken","51":"Index Hotswapping (Dynamic Knowledge Update)","52":"Prompt Chaining \/ Multi-Step Prompting","53":"Retrieval Augmented Generation (RAG)","54":"Self-Critique \/ Self-Refinement","55":"Agentic Loop \/ Cognitive Loop \/ Decision-Making Loop","56":"Modular Memory System","57":"Grounding Actions \/ Tool Use","58":"Reasoning Actions","59":"Learning Actions","60":"Decision Making (Planning & Execution)","61":"Skill Learning \/ Procedural Knowledge Acquisition","62":"Memory-Augmented Reflection","63":"Tree of Thoughts (ToT) \/ Deliberative Search-Based Planning","64":"LLM-Code Hybrid \/ Complementary Capabilities","65":"ReAct (Reasoning and Acting)","66":"Function Calling \/ Structured Output Parsing","67":"End-to-End Domain-Adaptive RAG Training","68":"Domain-Specific Retriever Finetuning","69":"LLM as RL Policy with Online Grounding","70":"LLM as High-Level Planner","71":"Behavioral Cloning for LLM Policy Initialization","72":"Reinforcement Learning from Human Feedback (RLHF) for LLMs","73":"Distributed LLM Policy Inference and Training","74":"Action Head for LLM Policy","75":"InContext Retrieval-Augmented Language Model (InContext RALM)","76":"LM-Oriented Reranking","77":"Nearest Neighbor Language Model (kNNLM)","78":"Retriever-Aware Training (RAT)","79":"Instruction-Tuned API Invocation","80":"AST-based Code\/API Evaluation","81":"LLM as Knowledge Graph Agent","82":"LLM-Guided Iterative Knowledge Graph Exploration (ThinkonGraph)","83":"Knowledge Traceability and Correctability via Explicit Reasoning Paths","84":"Retrieval Augmented Fine Tuning (RAFT)","85":"Training with Distractor Documents","86":"Chain-of-Thought Reasoning","87":"Retrieval-Augmented Generation (RAG)","88":"Retrieval-Augmented Generation for Blackbox LLMs","89":"Self-Correction with Automated Feedback","90":"Adaptive LLM Orchestration","91":"Conversable Agents","92":"Conversation Programming","93":"Unified Conversation Interfaces and Autoreply Mechanisms","94":"Control by Fusion of Programming and Natural Language","95":"Composable Conversation Patterns","96":"Human-in-the-Loop Multi-Agent Systems","97":"Interactive Retrieval","98":"Grounding Agent","99":"Adversarial\/Collaborative Agent Interactions","100":"Executor Agent","101":"Adaptive Retrieval-Augmented Generation (AdaptiveRAG)","102":"Query Complexity Classifier","103":"Interpretability-Constrained Learning","104":"Global Surrogate Model","105":"Local Surrogate Model","106":"Shapley Value Explanation","107":"Local Rule-Based Explanation","108":"Counterfactual Explanation","109":"Divergent Subgroup Analysis","110":"Human-in-the-Loop Explanation","111":"RAG Knowledge Cache","112":"Prefix-Aware KV Cache Replacement Policy (PGDSF)","113":"RAG Cache-Aware Request Reordering","114":"Dynamic Speculative RAG Pipelining","115":"Direct Prompting","116":"Chain-of-Thought (CoT)","117":"ReAct (Reasoning and Acting)","118":"Reflexion (Self-Correction with Verbal Reinforcement Learning)","119":"Tool Use \/ Tool Augmentation","120":"Memory Augmentation (Long-term and Short-term)","121":"Task Decomposition","122":"Tree-of-Thoughts (ToT) \/ Graph-of-Thoughts (GoT)","123":"Tool Augmentation","124":"Faithful Tool-Use Evaluation Dataset Generation","125":"LLM as a Planner \/ Decomposed Planning","126":"Self-Correction \/ Feedback Loop","127":"LLM as an Orchestrator","128":"Retrieval Augmentation","129":"Chain-of-Thought Prompting","130":"Memory Augmentation","131":"Tool-Integrated Reasoning Agent (TORA)","132":"Output Space Shaping","133":"Trajectory Synthesis for Training","134":"Iterative Invocation Tool Learning","135":"Single Invocation Tool Learning","136":"Task Decomposition","137":"Chain-of-Thought (CoT) Planning","138":"ReAct (Reasoning and Acting)","139":"Fine-tuned Task Planner","140":"Retriever-based Tool Selection","141":"LLM-based Tool Selection","142":"Parameter Extraction and Formatting","143":"Error Handling for Tool Calling","144":"Information Integration for Response Generation","145":"Direct Insertion for Response Generation","146":"Distinguish Business Logic from ML Models","147":"DataAlgorithm Serving Evaluator","148":"Event-driven ML Microservices","149":"ParameterServer Abstraction","150":"Daisy Architecture","151":"ClosedLoop Intelligence","152":"Federated Learning","153":"ML Versioning","154":"Isolate and Validate Output of Model","155":"Canary Model","156":"Design Holistically about Data Collection and Feature Extraction","157":"Secure Aggregation","158":"Two-Phase Predictions","159":"Encapsulating ML Models within Rule-based Safeguards","160":"AI Pipelines","161":"Ethics Credentials","162":"Distinguish Business Logic from ML Model","163":"Microservice Vertical Pattern","164":"Microservice Horizontal Pattern","165":"Deploy Canary Model","166":"Agent Profiling","167":"Memory-Augmented Agent","168":"LLM as a Planner","169":"Planning with Feedback","170":"Grounded Replanning","171":"Tool-Augmented LLM Agent","172":"Multi-Agent Debate","173":"Self-Driven Evolution","174":"Trial-and-Error Learning Agent","175":"Loan Approval Solution Pattern","176":"Fraud Detection Solution Pattern","177":"Task Assignment Solution Pattern","178":"Agentic Web Browser Interaction","179":"Behavior Cloning (BC)","180":"Reward Modeling (RM)","181":"Reinforcement Learning from Human Feedback (RLHF)","182":"Rejection Sampling (Best-of-N)","183":"Reference Collection for Factual Accuracy","184":"ReAct (Reasoning and Acting)","185":"Chain-of-Thought (CoT) Prompting","186":"Self-Consistency (CoTSC)","187":"Combining Internal and External Knowledge","188":"LLM as a Planner (SayCan)","189":"Inner Monologue","190":"Self-Taught Reasoner (STaR)","191":"Scratchpads","192":"Selection-Inference","193":"Faithful Reasoning","194":"Act-Only","195":"Least-to-Most Prompting","196":"Retrieval-Augmented Generation (RAG)","197":"Retrieve-Rerank-Generate Pipeline","198":"Unified Instruction Tuning for RAG and Ranking (RankRAG Framework)","199":"Reasoning on Graphs (RoG)","200":"LLM-KG Integration","201":"Retrieval-Augmented Generation (RAG) for LLMs","202":"Plan-and-Solve Reasoning (Task Decomposition for LLMs)","203":"Agentic LLM for External Interaction","204":"Semantic Parsing for LLMs","205":"Chain-of-Thought (CoT) Reasoning","206":"Advanced Reasoning Structures (Tree\/Graph of Thoughts)","207":"Self-Correction\/Verification for LLMs","208":"Monte-Carlo Planning for Faithful Reasoning"},"cluster":{"0":8,"1":8,"2":8,"3":8,"4":9,"5":35,"6":8,"7":35,"8":6,"9":26,"10":44,"11":44,"12":26,"13":47,"14":47,"15":47,"16":47,"17":0,"18":20,"19":19,"20":49,"21":9,"22":0,"23":0,"24":47,"25":42,"26":42,"27":49,"28":20,"29":19,"30":19,"31":7,"32":19,"33":19,"34":20,"35":18,"36":0,"37":0,"38":0,"39":16,"40":0,"41":32,"42":47,"43":32,"44":16,"45":32,"46":32,"47":6,"48":21,"49":30,"50":30,"51":21,"52":41,"53":18,"54":23,"55":16,"56":26,"57":24,"58":41,"59":10,"60":0,"61":10,"62":10,"63":41,"64":24,"65":11,"66":27,"67":21,"68":21,"69":25,"70":0,"71":17,"72":6,"73":25,"74":25,"75":21,"76":30,"77":21,"78":5,"79":5,"80":5,"81":14,"82":14,"83":23,"84":21,"85":1,"86":9,"87":18,"88":18,"89":6,"90":35,"91":2,"92":2,"93":2,"94":2,"95":2,"96":45,"97":1,"98":43,"99":43,"100":43,"101":46,"102":46,"103":37,"104":3,"105":3,"106":22,"107":3,"108":45,"109":45,"110":45,"111":15,"112":15,"113":36,"114":30,"115":46,"116":9,"117":11,"118":11,"119":11,"120":26,"121":11,"122":41,"123":35,"124":18,"125":0,"126":11,"127":35,"128":18,"129":9,"130":26,"131":0,"132":32,"133":32,"134":7,"135":7,"136":41,"137":41,"138":11,"139":7,"140":19,"141":19,"142":27,"143":7,"144":27,"145":27,"146":13,"147":28,"148":4,"149":29,"150":4,"151":28,"152":29,"153":12,"154":12,"155":12,"156":28,"157":29,"158":34,"159":12,"160":31,"161":48,"162":13,"163":40,"164":40,"165":12,"166":35,"167":26,"168":0,"169":16,"170":16,"171":35,"172":42,"173":10,"174":16,"175":33,"176":38,"177":33,"178":1,"179":17,"180":39,"181":6,"182":39,"183":18,"184":11,"185":9,"186":9,"187":9,"188":0,"189":11,"190":9,"191":9,"192":9,"193":9,"194":11,"195":9,"196":18,"197":30,"198":30,"199":14,"200":14,"201":18,"202":41,"203":35,"204":14,"205":41,"206":41,"207":23,"208":23}}