[
  {
    "Pattern Name": "Task Decomposition",
    "Problem": "Real-life tasks are usually complicated and multistep, bringing severe hardness for LLM planning. A one-step planning process is formidable, and LLMs may suffer from task forgetting and hallucinations for complex tasks.",
    "Context": "LLM-based autonomous agents need to accomplish complex, multistep tasks in environments characterized by complexity and variability.",
    "Solution": "Adopt a 'divide and conquer' strategy by decomposing a complicated task into several simpler subtasks and then sequentially planning for each subtask. This can be implemented in two manners:\n1.  **Decomposition-First:** Decompose the entire task into subgoals first, then plan for each subgoal successively.\n2.  **Interleaved Decomposition:** Dynamically adjust task decomposition and subtask planning based on environmental feedback, revealing only a few subtasks at the current state.",
    "Result": "Simplifies complex tasks, making them manageable for LLMs. Decomposition-first methods create a stronger correlation between subtasks and original tasks, reducing the risk of task forgetting and hallucinations. Interleaved decomposition improves fault tolerance by dynamically adjusting based on feedback.",
    "Related Patterns": [
      "Agentic AI Patterns",
      "Planning Patterns",
      "Prompt Design Patterns"
    ],
    "Uses": [
      "Chain-of-Thought (CoT)",
      "ReAct",
      "HuggingGPT",
      "PlanandSolve",
      "ProgPrompt",
      "PAL (Program-Aided Language models)",
      "Program-of-Thought (PoT)",
      "Visual ChatGPT"
    ]
  },
  {
    "Pattern Name": "Multiplan Selection",
    "Problem": "Due to task complexity and the inherent uncertainty of LLMs, a single plan generated by an LLM is likely to be suboptimal or even infeasible.",
    "Context": "LLM agents need to find robust and optimal plans for complex tasks where initial LLM outputs might be unreliable or require validation.",
    "Solution": "Generate various alternative plans for a given task (Multiplan Generation) and then employ a task-related search algorithm to select the optimal plan to execute (Optimal Plan Selection).\n1.  **Multiplan Generation:** Achieved by employing uncertainty in the decoding process of generative models (e.g., temperature sampling, top-k sampling) or by explicitly instructing the LLM to generate multiple plans via few-shot examples in prompts.\n2.  **Optimal Plan Selection:** Utilizes diverse strategies adopted as heuristic search algorithms, such as majority vote, conventional BFS/DFS, Monte Carlo Tree Search (MCTS), or the A* algorithm.",
    "Result": "Provides a broader exploration of potential solutions in the expansive search space, leading to more robust and potentially optimal plans by mitigating the unreliability of a single LLM output.",
    "Related Patterns": [
      "Agentic AI Patterns",
      "Planning Patterns",
      "Generative AI Patterns",
      "LLM-specific Patterns"
    ],
    "Uses": [
      "Self-consistency",
      "Tree-of-Thought (ToT)",
      "Graph-of-Thought (GoT)",
      "LLMMCTS",
      "RAP",
      "LLM-A*"
    ]
  },
  {
    "Pattern Name": "External Planner-Aided Planning",
    "Problem": "LLMs face challenges when confronted with environments featuring intricate constraints (e.g., mathematical problem-solving, generating admissible actions) and may struggle with the efficiency and feasibility of generated plans.",
    "Context": "LLM agents need to perform planning in environments with strict rules, complex logical dependencies, or where computational efficiency and guaranteed plan feasibility are critical.",
    "Solution": "Integrate LLMs with specialized external planners. The LLM primarily plays a supportive role, parsing textual feedback, formalizing tasks (e.g., into PDDL or ASP), and providing additional reasoning information, while the external planner handles the precise, constrained planning.\n1.  **Symbolic Planner:** LLM converts natural language problems into well-established symbolic formalized models (e.g., PDDL, atomic facts for ASP), which are then solved by classical symbolic planners (e.g., FastDownward, BFS solver, CLINGO, LPG).\n2.  **Neural Planner:** LLM combines with deep models trained on planning data (e.g., RL-based policy networks, Decision Transformers). LLM can generate candidate actions or handle complex 'slow thinking,' while the neural planner performs rapid, domain-specific 'fast thinking.'",
    "Result": "Elevates planning proficiency, addresses issues of efficiency and infeasibility of generated plans, and enables LLMs to deal with more general tasks for symbolic AI. It combines LLM's semantic understanding and code generation capabilities with the theoretical completeness, stability, and interpretability of symbolic systems or the efficiency of neural planners.",
    "Related Patterns": [
      "Tools Integration Patterns",
      "Planning Patterns",
      "Knowledge & Reasoning Patterns",
      "Agentic AI Patterns",
      "Classical AI"
    ],
    "Uses": [
      "LLMP",
      "LLMDP",
      "LLMPDDL",
      "LLMASP"
    ]
  },
  {
    "Pattern Name": "Reflection and Refinement",
    "Problem": "LLM agents may suffer from hallucinations, make errors, or get stuck in thought loops during planning due to insufficient reasoning abilities for complex problems and limited feedback.",
    "Context": "LLM agents need to improve their performance over time, learn from mistakes, and self-correct to enhance fault tolerance and achieve specified goals.",
    "Solution": "Implement an iterative process where the LLM reflects on its past actions and failures, summarizes feedback, and then refines its plan. This involves generating an initial plan, receiving feedback (internal or external, potentially from external tools like Knowledge Bases or Search Engines), evaluating trajectories, generating self-reflections upon error detection, and using these textual feedbacks to adjust subsequent planning outputs.",
    "Result": "Enhances the fault tolerance and error correction capabilities of LLM agent planning. It helps agents correct errors, break out of thought loops, and improves performance on complex tasks by leveraging self-reflection.",
    "Related Patterns": [
      "Agentic AI Patterns",
      "Planning Patterns",
      "Prompt Design Patterns",
      "Knowledge & Reasoning Patterns"
    ],
    "Uses": [
      "SelfRefine",
      "Reflexion",
      "CRITIC",
      "InteRecAgent",
      "LEMA"
    ]
  },
  {
    "Pattern Name": "Memory-Augmented Planning",
    "Problem": "LLMs have limited context length, leading to 'forgetting' valuable information (commonsense knowledge, past experiences, domain-specific knowledge) crucial for long-term or complex planning, potentially causing hallucinations or suboptimal decisions.",
    "Context": "LLM agents need to retain and leverage a broad range of information over time to enhance planning capabilities, enable growth, and improve fault tolerance.",
    "Solution": "Integrate an additional memory module to store valuable information, which is then retrieved and used as auxiliary signals during planning. This can be achieved through two major approaches:\n1.  **RAG-based Memory (Retrieval Augmented Generation):** Stores memories (e.g., texts, tabular forms, knowledge graphs) in external storage. Task-relevant experiences are retrieved based on similarity (e.g., using vector embeddings and indexing structures like FAISS) and provided to the LLM as additional context.\n2.  **Embodied Memory (Finetuning-based):** Embeds memories directly into the LLM's parameters by finetuning the model with the agent's historical experiential samples (e.g., ground truth action trajectories, Markov decision process data). Parameter-Efficient Finetuning (PEFT) techniques can be leveraged to reduce costs.",
    "Result": "Provides LLM agents with long-term memory, allowing them to leverage past experiences, commonsense knowledge, and domain-specific priors. Enhances planning capabilities, growth, and fault tolerance by reducing task forgetting and improving decision-making.",
    "Related Patterns": [
      "Knowledge & Reasoning Patterns",
      "LLM-specific Patterns",
      "Agentic AI Patterns",
      "Generative AI Patterns",
      "Personalization Pattern"
    ],
    "Uses": [
      "Generative Agents",
      "MemoryBank",
      "TiM",
      "RecMind",
      "MemGPT",
      "REMEMBER"
    ]
  }
]