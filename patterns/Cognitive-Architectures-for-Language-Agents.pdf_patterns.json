[
  {
    "Pattern Name": "Production System",
    "Problem": "How to define systems capable of complex, hierarchically structured behaviors through iterative rule application, often for symbolic manipulation.",
    "Context": "Originating in efforts to characterize the limits of computation (e.g., string rewriting), later adopted by the AI community to capture human problem solving.",
    "Solution": "A formalism consisting of a set of rules, each specifying a precondition and an action. When the precondition is met, the action can be taken, modifying a state (e.g., a string or logical state).",
    "Result": "Generates a set of outcomes by iteratively applying rules, capable of complex behaviors, and can be shown to be Turing complete when control flow is imposed.",
    "Related Patterns": ["Cognitive Architecture", "Language Models as Probabilistic Production Systems"],
    "Uses": "String manipulation, formal languages (Chomsky's phrase structure grammar), logical systems, early AI problem-solving (e.g., thermostat agent).",
    "Category": ["Classical AI", "Knowledge & Reasoning"]
  },
  {
    "Pattern Name": "Cognitive Architecture",
    "Problem": "How to build flexible, rational, real-time agents that mimic human cognition, explicitly instantiating processes such as perception, memory, and planning.",
    "Context": "Building on production systems, AI researchers sought to integrate these rule-based systems with sensory input, actuators, and knowledge bases to achieve human-like problem-solving.",
    "Solution": "Augments a production system with sensory groundings, various types of long-term memory (procedural, semantic, episodic), and a generalized decision procedure for selecting, applying, and even generating new productions.",
    "Result": "Agents capable of flexible, rational, and real-time behaviors, with structured internal state management and adaptive learning mechanisms.",
    "Related Patterns": ["Production System", "Modular Memory", "Generalized Decision-Making Loop", "Grounding Actions"],
    "Uses": "Psychological modeling, robotics, military simulations, intelligent tutoring (e.g., Soar architecture).",
    "Category": ["Agentic AI", "Classical AI", "Knowledge & Reasoning"]
  },
  {
    "Pattern Name": "Modular Memory",
    "Problem": "Large language models (LLMs) are stateless; how to enable language agents to persist, organize, and maintain information internally for multistep interactions with the world.",
    "Context": "Designing language agents that require internal state to remember past interactions, store knowledge, track current goals, and support reasoning and planning across multiple LLM calls.",
    "Solution": "Organize information (primarily textual, but other modalities allowed) into multiple distinct memory modules, each containing a different form of information. These typically include short-term working memory and several long-term memories (episodic, semantic, and procedural).",
    "Result": "Agents can maintain internal state, leverage past experiences, access world knowledge, and store operational procedures, overcoming the inherent statelessness of LLMs and enabling complex, long-duration interactions.",
    "Related Patterns": ["Working Memory", "Episodic Memory", "Semantic Memory", "Procedural Memory", "Cognitive Architecture"],
    "Uses": "Language agents, cognitive language agents (e.g., CoALA framework), any AI system requiring persistent internal state.",
    "Category": ["Agentic AI", "Knowledge & Reasoning", "LLM-specific"]
  },
  {
    "Pattern Name": "Working Memory",
    "Problem": "How to manage active and readily available information for an agent's current decision cycle, including perceptual inputs, active knowledge, and intermediate reasoning results.",
    "Context": "Within a language agent, needing a dynamic data structure that persists across LLM calls to track the agent's current circumstances and facilitate decision-making.",
    "Solution": "A memory module that maintains active and readily available information as symbolic variables for the current decision cycle. It stores perceptual inputs, active knowledge generated by reasoning or retrieved from long-term memory, and core information carried over from previous cycles (e.g., active goals). LLM input is synthesized from it, and LLM output is parsed back into it.",
    "Result": "Serves as the central hub connecting different components of a language agent (LLM, long-term memories, grounding interfaces), enabling context-aware and responsive decision-making.",
    "Related Patterns": ["Modular Memory", "Reasoning Actions", "Structured Output Parsing"],
    "Uses": "Cognitive architectures (Soar), language agents (CoALA framework), prompt templates and variable population for LLM calls.",
    "Category": ["Agentic AI", "Knowledge & Reasoning"]
  },
  {
    "Pattern Name": "Episodic Memory",
    "Problem": "How to store and leverage experience from earlier decision cycles, past behaviors, or event flows for future reasoning, learning, or planning.",
    "Context": "Agents needing to learn from their history, retrieve relevant past events, or reflect on sequences of actions and observations to adapt their behavior.",
    "Solution": "A memory module that stores representations of the agent's experiences, such as training input-output pairs, history event flows, or game trajectories. These episodes can be retrieved into working memory during the planning stage to support reasoning.",
    "Result": "Allows agents to access and learn from their past, enabling recall of relevant examples, bases for reasoning, and support for learning by storing new experiences.",
    "Related Patterns": ["Modular Memory", "Learning Actions", "Reflection / Self-Improvement"],
    "Uses": "RL agents storing episodic trajectories, Generative Agents (storing events), support for reasoning and decision-making in language agents.",
    "Category": ["Agentic AI", "Knowledge & Reasoning"]
  },
  {
    "Pattern Name": "Semantic Memory",
    "Problem": "How to store and access an agent's explicit knowledge about the world and itself, including facts, concepts, and general information.",
    "Context": "Agents requiring external knowledge support for reasoning or decision-making, or needing to incrementally build up their understanding of the world from experience.",
    "Solution": "A memory module that stores an agent's knowledge about the world and itself, often initialized from external databases (e.g., Wikipedia) or game manuals. Language agents may also write new knowledge obtained from LLM reasoning into semantic memory as a form of learning.",
    "Result": "Provides a knowledge base that can be retrieved to inform reasoning and decision-making, allowing agents to ground their understanding and incrementally build world knowledge.",
    "Related Patterns": ["Modular Memory", "Retrieval Augmented Generation (RAG)", "Learning Actions", "Reflection / Self-Improvement"],
    "Uses": "Retrieval-augmented NLP methods, reading-to-learn RL approaches, Generative Agents (storing reflections), robotics (semantic maps).",
    "Category": ["Agentic AI", "Knowledge & Reasoning"]
  },
  {
    "Pattern Name": "Procedural Memory",
    "Problem": "How to store the agent's operational knowledge, including its rules of behavior, skills, and how to implement actions and decision-making processes.",
    "Context": "Agents requiring both implicit (learned via weights) and explicit (coded rules and procedures) knowledge to define their behavior and control flow.",
    "Solution": "Comprises two forms: implicit knowledge stored in the LLM weights, and explicit knowledge written in the agent's code. Explicit knowledge includes procedures for implementing actions (reasoning, retrieval, grounding, learning) and procedures for decision-making itself. Learning actions can update this memory by writing new agent code.",
    "Result": "Defines the agent's capabilities and control flow, allowing for both the flexible, implicit knowledge of LLMs and the interpretable, extensible (but potentially brittle) explicit code.",
    "Related Patterns": ["Modular Memory", "Code as Policies / Skill Library", "Learning Actions", "LLM-Code Hybrid Control"],
    "Uses": "Cognitive architectures (Soar), language agents (CoALA framework), Voyager (skill library), prompt templates.",
    "Category": ["Agentic AI", "Knowledge & Reasoning"]
  },
  {
    "Pattern Name": "Structured Action Space",
    "Problem": "How to systematically define the range of actions an agent can take, encompassing both interactions with the external world and internal cognitive processes, for clear and task-suitable agent design.",
    "Context": "Designing language agents that need to perform complex tasks requiring both external manipulation (e.g., controlling a robot, using tools) and internal deliberation (e.g., reasoning, memory access, learning).",
    "Solution": "Divide the agent's action space into two main categories: external actions (interacting with external environments through 'grounding') and internal actions (interacting with internal memories and processes, further decomposed into retrieval, reasoning, and learning).",
    "Result": "Provides a clear and task-suitable set of capabilities for the agent, enabling the design of more complex and autonomous systems by systematically considering all possible operations.",
    "Related Patterns": ["Grounding Actions", "Retrieval Actions", "Reasoning Actions", "Learning Actions", "Modular Agent Design"],
    "Uses": "Language agent design (CoALA framework), reinforcement learning, cognitive architectures.",
    "Category": ["Agentic AI", "Tools Integration"]
  },
  {
    "Pattern Name": "Grounding Actions",
    "Problem": "How to connect an agent's internal (often language-based) representations and decisions to its external environment, enabling it to perceive and act in the real or digital world.",
    "Context": "Language agents needing to interact with physical robots, engage in dialogue with humans, or manipulate digital interfaces (games, APIs, websites) where direct LLM output is insufficient.",
    "Solution": "Procedures that execute external actions (e.g., motor commands, API calls, natural language responses) and process environmental feedback (e.g., sensor data, website observations, human dialogue) into textual representations for the agent's working memory.",
    "Result": "Allows language models to operate in interactive environments, translating high-level instructions into concrete actions and observations into text, effectively simplifying external interaction to a 'text game'.",
    "Related Patterns": ["Structured Action Space", "Tool Use / Digital Grounding"],
    "Uses": "Robotics (Ahn et al. 2022), web manipulation (Yao et al. 2022a), human-agent dialogue, game interaction.",
    "Category": ["Tools Integration", "AI-Human Interaction", "Agentic AI"]
  },
  {
    "Pattern Name": "Retrieval Actions",
    "Problem": "How to efficiently access and bring relevant information from an agent's long-term memories (episodic, semantic, procedural) into its working memory for current decision-making.",
    "Context": "Agents needing to leverage stored experiences, world knowledge, or operational skills to inform their reasoning, planning, or to provide context-specific information.",
    "Solution": "A procedure that reads information from long-term memory modules into working memory. This can be implemented using various methods such as rule-based, sparse, or dense retrieval, depending on the information and memory type.",
    "Result": "Enhances decision-making by providing context-specific information from the agent's knowledge base and history, improving the agent's ability to plan and reason.",
    "Related Patterns": ["Structured Action Space", "Modular Memory", "Retrieval Augmented Generation (RAG)"],
    "Uses": "Voyager (loading code-based skills), Generative Agents (retrieving relevant events), DocPrompting (leveraging library documents), supporting planning stages in decision cycles.",
    "Category": ["Knowledge & Reasoning", "Agentic AI"]
  },
  {
    "Pattern Name": "Reasoning Actions",
    "Problem": "How to process the contents of working memory to generate new information, distill insights, or elaborate on observations, supporting learning and decision-making.",
    "Context": "Language agents needing to analyze recent observations, summarize trajectories, or process retrieved information to form new conclusions or intermediate steps before acting or learning.",
    "Solution": "Procedures that read from and write to working memory, often using the LLM itself to summarize, distill insights, or infer new information about observations, trajectories, or retrieved facts.",
    "Result": "Supports learning by generating results that can be written into long-term memory, and enhances decision-making by providing additional context or intermediate steps for subsequent LLM calls.",
    "Related Patterns": ["Structured Action Space", "Working Memory", "Chain-of-Thought (CoT) Prompting", "Reflection / Self-Improvement"],
    "Uses": "ReAct (analyze situation, remake action plans), Generative Agents (generate reflections), Tree of Thoughts (propose thoughts), creating additional context for LLM prompts.",
    "Category": ["Knowledge & Reasoning", "Agentic AI", "LLM-specific"]
  },
  {
    "Pattern Name": "Learning Actions",
    "Problem": "How to enable an agent to acquire new knowledge, skills, or modify its behavior over its lifetime by committing information to long-term memory.",
    "Context": "Agents needing to adapt to new environments, improve performance, or build up their internal representations of the world and their capabilities.",
    "Solution": "Procedures that involve writing information to long-term memory modules (episodic, semantic, procedural) or updating LLM parameters. This spectrum includes storing experiences, inferred knowledge, finetuning LLMs (implicit procedural knowledge), or modifying agent code (explicit procedural knowledge).",
    "Result": "Allows agents to continuously improve, adapt, and build a richer internal model of the world and their own capabilities, leading to efficient lifelong learning.",
    "Related Patterns": ["Structured Action Space", "Modular Memory", "Episodic Memory", "Semantic Memory", "Procedural Memory", "Reflection / Self-Improvement", "Metalearning for Agents"],
    "Uses": "Voyager (adding new grounding procedures), Generative Agents (storing reflections), Reflexion (storing inferences from failed episodes), finetuning LLMs via supervised or reinforcement learning.",
    "Category": ["Agentic AI", "MLOps", "Knowledge & Reasoning"]
  },
  {
    "Pattern Name": "Generalized Decision-Making Loop",
    "Problem": "How to structure the top-level control flow of a language agent to enable deliberate, multi-step planning and action selection, moving beyond direct, single-step action generation.",
    "Context": "Agents facing complex tasks where a direct action might not be optimal, requiring foresight, evaluation of alternatives, and iterative refinement of plans.",
    "Solution": "A repeated decision cycle that yields an external (grounding) action or an internal (learning) action. In each cycle, program code defines a sequence of reasoning and retrieval actions to propose and evaluate alternatives (planning stage), then executes the selected action (execution stage), and the cycle loops again after an observation.",
    "Result": "Enables agents to engage in more sophisticated, deliberative behaviors, including iterative improvement of plans and consideration of multiple alternatives, leading to more robust and intelligent actions.",
    "Related Patterns": ["Cognitive Architecture", "Propose-Evaluate-Select Planning", "Reasoning Actions", "Retrieval Actions"],
    "Uses": "CoALA framework for language agents, Tree of Thoughts, RAP (Reasoning and Acting with Planning).",
    "Category": ["Planning", "Agentic AI"]
  },
  {
    "Pattern Name": "Propose-Evaluate-Select Planning",
    "Problem": "Within a generalized decision cycle, how to systematically generate, assess, and choose among multiple possible actions or 'thoughts' to make informed decisions.",
    "Context": "Agents needing to consider potential outcomes and optimize for desired goals in complex situations where a direct action is insufficient, requiring deliberation.",
    "Solution": "A substage within the planning stage of a decision loop, comprising three steps: 1) Proposal: Generating one or more action candidates (e.g., via LLM sampling, code structures, simulators). 2) Evaluation: Assigning a value to each candidate (e.g., heuristic rules, LLM perplexity, learned values, internal simulation). 3) Selection: Choosing the best action based on evaluation (e.g., argmax, softmax, majority vote) or rejecting candidates and looping back to proposal.",
    "Result": "Enables agents to make more informed and robust decisions by considering potential outcomes, optimizing for desired goals, and allowing for iterative improvement of candidate solutions.",
    "Related Patterns": ["Generalized Decision-Making Loop", "Reasoning Actions", "Tree of Thoughts (ToT)"],
    "Uses": "Classical planning algorithms, Tree of Thoughts, RAP, advanced language agents.",
    "Category": ["Planning", "Agentic AI"]
  },
  {
    "Pattern Name": "Language Models as Probabilistic Production Systems",
    "Problem": "How to conceptually link modern LLMs to classical AI formalisms, understanding their generative capabilities in a structured way that supports agent design.",
    "Context": "Drawing parallels between LLMs and historical production systems to build a theoretical foundation for cognitive language agents and apply control mechanisms.",
    "Solution": "View an LLM as defining a probability distribution over which 'productions' (string completions or modifications) to select when presented with an input (prompt), yielding a distribution P(Y|X). This treats the LLM as sampling a possible completion each time it is called.",
    "Result": "Provides a theoretical bridge between symbolic AI and LLMs, suggesting that control mechanisms from cognitive architectures, originally used with production systems, can be equally applicable to transform LLMs into language agents.",
    "Related Patterns": ["Production System", "Cognitive Language Agent"],
    "Uses": "Conceptual framework for LLM behavior, foundation for LLM-based agent design, understanding LLM's role in a cognitive architecture.",
    "Category": ["LLM-specific", "Generative AI", "Classical AI"]
  },
  {
    "Pattern Name": "Prompt Engineering",
    "Problem": "How to guide or bias the output of an LLM towards high-quality, task-specific responses or to elicit targeted reasoning, without altering its internal weights.",
    "Context": "Using LLMs for various tasks where their general knowledge needs to be focused, or their reasoning capabilities need to be enhanced for specific problems.",
    "Solution": "Preprocessing the input string (the prompt) by concatenating additional text, few-shot examples, instructions, or external observations to influence the LLM's conditional distribution over completions. These manipulations can be seen as 'productions' themselves.",
    "Result": "Allows users to elicit targeted reasoning and desired outputs, making LLMs more versatile for specific tasks, and serving as a form of task-specific prioritization of productions.",
    "Related Patterns": ["Zeroshot Prompting", "Fewshot Prompting", "Retrieval Augmented Generation (RAG)", "Socratic Models", "Self-Critique Prompting", "Chain-of-Thought (CoT) Prompting", "Prompt Chaining"],
    "Uses": "Question answering, code generation, various NLP tasks, biasing LLMs towards specific behaviors or reasoning processes.",
    "Category": ["Prompt Design", "LLM-specific"]
  },
  {
    "Pattern Name": "Zeroshot Prompting",
    "Problem": "How to make an LLM perform a task it hasn't been explicitly trained for, with minimal or no examples, relying solely on its pre-trained knowledge.",
    "Context": "Applying LLMs to novel tasks where labeled data for finetuning is unavailable, too costly, or when a quick, initial solution is needed.",
    "Solution": "Formulating the task directly as an input string (a question or instruction) to the LLM, expecting it to generate a relevant completion or answer based on its vast pre-training corpus.",
    "Result": "Enables immediate application of LLMs to a wide range of tasks 'out of the box' without task-specific examples, leveraging their implicit world knowledge.",
    "Related Patterns": ["Prompt Engineering"],
    "Uses": "General question answering, simple instruction following, initial exploration of LLM capabilities for a new task.",
    "Category": ["Prompt Design", "LLM-specific"]
  },
  {
    "Pattern Name": "Fewshot Prompting",
    "Problem": "How to improve an LLM's performance on a specific task by providing a small number of in-context examples, especially when finetuning is not feasible or desired.",
    "Context": "Tasks where zeroshot performance is insufficient, but full finetuning is impractical due to data scarcity, cost, or a desire for rapid adaptation.",
    "Solution": "Including a few input-output examples directly in the prompt, demonstrating the desired task behavior before presenting the actual query. These examples guide the LLM's inference for the new input.",
    "Result": "Biases the LLM towards high-quality productions relevant to the task, improving accuracy and adherence to desired formats by showing the model 'how' to respond.",
    "Related Patterns": ["Prompt Engineering"],
    "Uses": "Adapting LLMs to novel tasks with limited data, improving specific task performance, demonstration-based learning.",
    "Category": ["Prompt Design", "LLM-specific"]
  },
  {
    "Pattern Name": "Retrieval Augmented Generation (RAG)",
    "Problem": "How to ground LLM generations in external, up-to-date, or specific knowledge, mitigating hallucinations, outdated information, and limitations of the LLM's internal knowledge base.",
    "Context": "LLMs needing to answer questions or generate text that requires specific factual information not present in their training data, or to be current and attributable.",
    "Solution": "Preprocessing the prompt by retrieving relevant external observations or documents (e.g., from Wikipedia, databases, or specialized knowledge bases) and concatenating them with the original query before passing it to the LLM.",
    "Result": "LLMs can generate more accurate, grounded, and up-to-date responses by leveraging external knowledge sources, reducing hallucinations and improving factual consistency.",
    "Related Patterns": ["Prompt Engineering", "Semantic Memory", "Retrieval Actions"],
    "Uses": "Knowledge-intensive NLP tasks, open-domain question answering, fact-checking, generating text with specific external context.",
    "Category": ["Prompt Design", "Knowledge & Reasoning", "Generative AI", "LLM-specific"]
  },
  {
    "Pattern Name": "Socratic Models",
    "Problem": "How to combine different specialized models (e.g., vision, language) to perform complex multimodal reasoning, orchestrating their individual strengths.",
    "Context": "Tasks requiring processing of multiple modalities (e.g., image and text) where a single LLM might not be sufficient or efficient, and modularity is desired.",
    "Solution": "Using an LLM as a central orchestrator that queries other specialized models (e.g., a Vision-Language Model for observations) to translate perceptual data into text, and then integrates their outputs into its reasoning process.",
    "Result": "Enables multimodal reasoning by leveraging the strengths of different models, with the LLM providing high-level control and coherence for complex tasks.",
    "Related Patterns": ["Prompt Engineering", "Tools Integration", "Grounding Actions"],
    "Uses": "Multimodal question answering, embodied reasoning, integrating specialized perception models with LLMs.",
    "Category": ["Prompt Design", "Generative AI", "Tools Integration", "LLM-specific"]
  },
  {
    "Pattern Name": "Self-Critique Prompting",
    "Problem": "How to enable an LLM to evaluate and refine its own outputs, improving quality and correctness without relying solely on external human feedback.",
    "Context": "Improving the reliability, accuracy, or creativity of LLM generations, especially for tasks where a single pass might produce errors, suboptimal results, or require iterative improvement.",
    "Solution": "After an initial generation, the LLM is prompted again, often with its previous output and a specific request to critique, identify defects, or propose modifications. This can occur in multiple iterations, allowing the LLM to act as its own evaluator.",
    "Result": "Leads to iterative refinement and potentially higher-quality, more accurate outputs by allowing the LLM to identify and correct its own mistakes, mimicking human self-correction.",
    "Related Patterns": ["Prompt Engineering", "Reasoning Actions", "Reflection / Self-Improvement", "Prompt Chaining"],
    "Uses": "Improving code, creative writing, complex problem-solving, self-evaluation in agents.",
    "Category": ["Prompt Design", "Generative AI", "LLM-specific"]
  },
  {
    "Pattern Name": "Chain-of-Thought (CoT) Prompting",
    "Problem": "How to enable LLMs to perform complex reasoning tasks that require multiple intermediate steps, making their decision process more transparent and accurate.",
    "Context": "Tasks that humans would solve by breaking them down into logical steps (e.g., arithmetic, multi-step logical problems), where direct generation often fails or produces incorrect results.",
    "Solution": "Prompting the LLM to generate a series of intermediate reasoning steps before providing the final answer. This can be achieved by adding explicit instructions like 'Let's think step by step' or by providing few-shot examples that include the desired reasoning process.",
    "Result": "Elicits more deliberate and accurate reasoning, improving performance on arithmetic, common sense, and symbolic reasoning tasks, and making the LLM's process more interpretable.",
    "Related Patterns": ["Prompt Engineering", "Reasoning Actions"],
    "Uses": "Complex problem-solving, arithmetic, logical reasoning, improving transparency of LLM decisions.",
    "Category": ["Prompt Design", "Generative AI", "LLM-specific"]
  },
  {
    "Pattern Name": "Prompt Chaining",
    "Problem": "How to construct increasingly complicated algorithms or multi-step processes by sequencing multiple calls to an LLM, where each step's output informs the next.",
    "Context": "Tasks that require a sequence of operations, or iterative refinement, moving beyond single-shot prompting to build more sophisticated workflows or algorithms.",
    "Solution": "Structuring a series of LLM calls, where the output of one call is processed (parsed, modified, combined with other information) and then used to construct the prompt for the subsequent LLM call.",
    "Result": "Enables the implementation of complex, multi-stage algorithms and workflows, turning LLMs into more versatile computational units capable of multi-step reasoning and iterative processes.",
    "Related Patterns": ["Prompt Engineering", "Generalized Decision-Making Loop", "Self-Critique Prompting"],
    "Uses": "Multi-step reasoning, iterative refinement, agent control, generating complicated algorithms.",
    "Category": ["Prompt Design", "LLM-specific", "Agentic AI"]
  },
  {
    "Pattern Name": "Cognitive Language Agent",
    "Problem": "How to design and implement AI systems that leverage the powerful language understanding and generation capabilities of LLMs to interact with complex environments, perform reasoning, and learn over time.",
    "Context": "Building autonomous or semi-autonomous agents that combine the strengths of LLMs with structured internal processes and a feedback loop with the external world.",
    "Solution": "Place an LLM as the core computational unit within a larger cognitive architecture (like CoALA), integrating it into a feedback loop with an external environment. The agent uses the LLM to manage internal state (via modular memory), perform intermediate reasoning, and employ sophisticated learning strategies.",
    "Result": "Creates agents capable of more human-like intelligence, adapting to novel tasks, performing complex reasoning, and operating effectively in interactive environments.",
    "Related Patterns": ["Cognitive Architecture", "Language Models as Probabilistic Production Systems", "Modular Memory", "Structured Action Space", "Generalized Decision-Making Loop"],
    "Uses": "Robotics, web manipulation, puzzle solving, interactive code generation, social simulation, general-purpose language agents.",
    "Category": ["Agentic AI", "LLM-specific"]
  },
  {
    "Pattern Name": "Tool Use / Digital Grounding",
    "Problem": "How to extend the capabilities of LLMs beyond text generation to perform actions in digital environments or access external functionalities, overcoming their inherent limitations in computation or real-time data access.",
    "Context": "LLMs needing to interact with games, APIs, websites, or execute code to gather information, perform computations, or carry out operations beyond their inherent knowledge or capabilities.",
    "Solution": "Packaging external digital services (e.g., search engines, calculators, translators, web browsers, code interpreters) as 'tools' that the LLM can call. The LLM's output includes calls to these tools, and their results are fed back to the LLM as observations or additional context.",
    "Result": "Greatly expands the LLM's agency and problem-solving capacity in digital domains, allowing it to perform computations, access real-time data, interact with software, and augment its knowledge.",
    "Related Patterns": ["Grounding Actions", "Structured Action Space", "Socratic Models"],
    "Uses": "Web agents, API interaction, general code execution, augmented NLP tasks requiring external knowledge or computation.",
    "Category": ["Tools Integration", "Agentic AI", "LLM-specific"]
  },
  {
    "Pattern Name": "Reflection / Self-Improvement",
    "Problem": "How to enable an agent to learn from its past failures or experiences by critically analyzing its performance and generating new insights, knowledge, or behavioral modifications.",
    "Context": "Agents needing to improve their strategies or knowledge base based on feedback from the environment or internal evaluation of trajectories, leading to more robust and efficient future behaviors.",
    "Solution": "Using an LLM to reason about past episodes, failed attempts, or observed trajectories, distilling insights, generating new semantic inferences, or proposing modifications to its behavior. These insights are then often stored in long-term memory (semantic or episodic) to inform future decisions.",
    "Result": "Allows agents to adapt and improve their future behaviors, making them more robust, efficient, and capable of learning from their own experiences, leading to continuous self-improvement.",
    "Related Patterns": ["Learning Actions", "Reasoning Actions", "Episodic Memory", "Semantic Memory", "Self-Critique Prompting"],
    "Uses": "Reflexion (storing inferences from failed episodes), Generative Agents (generating reflections), adapting future behaviors based on past experience.",
    "Category": ["Agentic AI", "Knowledge & Reasoning", "LLM-specific"]
  },
  {
    "Pattern Name": "Code as Policies / Skill Library",
    "Problem": "How to enable an agent to acquire, store, and reuse complex, code-based skills for interacting with its environment, particularly in domains requiring precise, programmatic actions.",
    "Context": "Agents operating in environments (e.g., robotics, complex digital interfaces like Minecraft) that require a diverse set of specific, programmatic actions, where LLMs can generate high-level plans but need concrete execution mechanisms.",
    "Solution": "Maintain a long-term procedural memory that stores a library of code-based grounding procedures (skills). These skills can be retrieved (e.g., via dense retrieval) and executed by the agent. The agent can also learn new skills by generating code and adding it to this library.",
    "Result": "Provides a hierarchical and extensible action space, allowing agents to master complex tasks and generalize to unseen scenarios by composing and learning new skills, complementing LLM planning with deterministic execution.",
    "Related Patterns": ["Procedural Memory", "Learning Actions", "Retrieval Actions", "Tool Use / Digital Grounding", "LLM-Code Hybrid Control"],
    "Uses": "Voyager in Minecraft (e.g., combatZombie, craftStoneSword), robotic control, general code generation for agent actions.",
    "Category": ["Tools Integration", "Agentic AI", "MLOps"]
  },
  {
    "Pattern Name": "Tree of Thoughts (ToT)",
    "Problem": "How to perform deliberate, multi-step problem-solving with LLMs that involves exploring multiple reasoning paths, backtracking, and foresight, similar to classical search algorithms, for tasks beyond simple sequential reasoning.",
    "Context": "Complex reasoning problems (e.g., game of 24, creative writing, crosswords) where a single chain of thought is insufficient, and evaluation of intermediate steps ('thoughts') and global exploration is crucial.",
    "Solution": "The LLM iteratively proposes 'thoughts' (which are reasoning actions) and evaluates them, maintaining them via a tree search algorithm (e.g., BFS, DFS, Monte Carlo Tree Search). The LLM is used to generate proposals (simulate rollouts conditioned on an action) and evaluate outcomes (value the outcome of the proposed action).",
    "Result": "Enables global exploration and local backtracking, significantly improving performance on tasks requiring planning, systematic exploration of possibilities, and deliberate problem-solving beyond linear thought processes.",
    "Related Patterns": ["Propose-Evaluate-Select Planning", "Reasoning Actions", "Generalized Decision-Making Loop"],
    "Uses": "Game of 24, creative writing, crosswords, complex reasoning problems requiring search and evaluation.",
    "Category": ["Planning", "LLM-specific"]
  },
  {
    "Pattern Name": "Modular Agent Design",
    "Problem": "The proliferation of custom terminology and implementations makes it difficult to compare, evolve, and build new language agents, leading to technical debt and compatibility issues.",
    "Context": "The emerging field of language agents lacks a standardized framework for organization and development, hindering research progress and industrial deployment.",
    "Solution": "Structure agents into distinct, interchangeable modules (e.g., Memory, Action, Agent classes) with standardized interfaces and terminology. This involves defining useful abstractions and casting simpler agents into such a framework.",
    "Result": "Consolidates technical investment, improves compatibility, facilitates modular 'plug-and-play' and reuse of components, and standardizes the customer experience in industry applications, reducing technical debt.",
    "Related Patterns": ["Cognitive Architecture", "Structured Action Space", "Modular Memory"],
    "Uses": "Academic research frameworks (like CoALA), industry language agent libraries, general software engineering for AI systems.",
    "Category": ["MLOps", "Agentic AI"]
  },
  {
    "Pattern Name": "LLM-Code Hybrid Control",
    "Problem": "How to combine the strengths of LLMs (flexibility, commonsense priors, zero-shot generalization) with the reliability, interpretability, and deterministic control of traditional agent code.",
    "Context": "LLMs are powerful but often brittle, opaque, and stochastic, while handcrafted code is reliable but lacks generalization and adaptability to unforeseen situations.",
    "Solution": "Use agent code to implement generic, deterministic algorithms (e.g., tree search, conditional logic, loops) that complement LLM limitations, while leveraging LLMs for flexible, context-dependent reasoning, planning, and generation in new contexts.",
    "Result": "Creates more robust and capable agents that benefit from both explicit, reliable control and learned flexibility, mitigating the weaknesses of each approach and improving overall agent performance.",
    "Related Patterns": ["Procedural Memory", "Tool Use / Digital Grounding", "Tree of Thoughts (ToT)"],
    "Uses": "Implementing tree search with LLMs, managing complex control flows, building agents that require both precise execution and adaptable reasoning.",
    "Category": ["Tools Integration", "LLM-specific", "Agentic AI"]
  },
  {
    "Pattern Name": "Structured Output Parsing",
    "Problem": "How to reliably extract specific, structured information from the free-form text output of an LLM and map it to internal variables or executable actions in an agent system.",
    "Context": "Integrating LLMs into agent systems where their natural language output needs to drive specific, programmatic actions, update structured state variables, or conform to predefined data schemas.",
    "Solution": "Employing techniques or tools (e.g., OpenAI function calling, Guidance, custom parsers) to define expected output formats (e.g., JSON schema, function calls with arguments) and parse the LLM's generated text into corresponding structured variables or commands.",
    "Result": "Enables seamless and reliable integration of LLM reasoning with code infrastructure, allowing LLM outputs to directly trigger agent actions, update working memory, or control other system components in a predictable and consistent manner.",
    "Related Patterns": ["Prompt Engineering", "Working Memory", "Tools Integration"],
    "Uses": "LangChain, LlamaIndex, OpenAI function calling, Guidance, any agent system needing to convert LLM text to structured data or actions.",
    "Category": ["Tools Integration", "Prompt Design", "LLM-specific"]
  },
  {
    "Pattern Name": "Metalearning for Agents",
    "Problem": "How to enable agents to learn *how* to learn more effectively, rather than just learning specific tasks or acquiring specific knowledge.",
    "Context": "Improving the efficiency, adaptability, and long-term self-improvement capabilities of agents, especially in complex or open-ended environments where learning strategies themselves can be optimized.",
    "Solution": "Modifying the agent's own code or procedures related to its learning, retrieval, or decision-making processes. Examples include learning better retrieval procedures (e.g., query-document expansion, retrieval distillation) or adapting learning schedules.",
    "Result": "Enhances the agent's ability to acquire and utilize information and skills, leading to more significant adaptability and self-improvement beyond what can be hard-coded, enabling agents to go beyond human-written code.",
    "Related Patterns": ["Learning Actions", "Procedural Memory"],
    "Uses": "Research direction for future agents, adaptive retrieval mechanisms, optimizing learning schedules, improving prompt templates.",
    "Category": ["Agentic AI", "MLOps", "Knowledge & Reasoning"]
  },
  {
    "Pattern Name": "Synergistic Reasoning and Acting (ReAct)",
    "Problem": "How to design language agents that effectively combine internal reasoning with external actions in a feedback loop to solve complex interactive tasks.",
    "Context": "Early language agents either acted directly or used predefined prompt chains. There was a need for agents that could dynamically reason about a situation and then act, using environmental feedback to refine subsequent reasoning.",
    "Solution": "A fixed decision cycle that uses a single internal reasoning action to analyze the situation and remake action plans, followed by generating an external grounding action. This process is repeated, creating a feedback loop where reasoning guides acting, and acting provides environmental feedback to support reasoning.",
    "Result": "Demonstrates that combining internal reasoning with external actions in an interactive feedback loop leads to more effective and adaptive language agents, especially in interactive digital environments.",
    "Related Patterns": ["Reasoning Actions", "Grounding Actions", "Generalized Decision-Making Loop", "Cognitive Language Agent"],
    "Uses": "Text games, Wikipedia API interaction, general web-based tasks (e.g., ReAct agent).",
    "Category": ["Agentic AI", "LLM-specific", "Planning"]
  }
]