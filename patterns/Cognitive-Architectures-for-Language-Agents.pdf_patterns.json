[
  {
    "Pattern Name": "Prompt Chaining / Multi-Step Prompting",
    "Problem": "Single LLM calls are often insufficient for complex tasks requiring iterative refinement, multi-step reasoning, or interaction.",
    "Context": "Tasks that can be broken down into a sequence of dependent sub-tasks or require intermediate steps of reasoning and/or action.",
    "Solution": "Decompose a complex task into a sequence of smaller steps, where the output of one LLM call (or external action) informs the next prompt. This can involve using the LLM itself for preprocessing, eliciting reasoning, or generating intermediate steps.",
    "Result": "Enables more complex algorithms and behaviors from LLMs, allowing for structured, multi-stage problem-solving.",
    "Related Patterns": [
      "Self-Critique / Self-Refinement",
      "ReAct (Reasoning and Acting)",
      "Reasoning Actions",
      "Decision Making (Planning & Execution)",
      "Tree of Thoughts (ToT) / Deliberative Search-Based Planning"
    ],
    "Uses": "Complex question answering, interactive agents, code generation, planning"
  },
  {
    "Pattern Name": "Retrieval Augmented Generation (RAG)",
    "Problem": "LLMs have limited knowledge (knowledge cutoff, factual inaccuracies) and struggle with domain-specific, private, or real-time information.",
    "Context": "Tasks requiring access to up-to-date, specific, or external knowledge not present in the LLM's training data, or to ground responses in verifiable sources.",
    "Solution": "Augment the LLM's input prompt with relevant information retrieved from an external knowledge source (e.g., vector database, document store, web search, API). This retrieved context guides the LLM's generation.",
    "Result": "Improves factual accuracy, reduces hallucinations, provides transparency, and grounds the LLM to specific, external information.",
    "Related Patterns": [
      "Modular Memory System",
      "Reasoning Actions"
    ],
    "Uses": "Knowledge-intensive NLP tasks, question answering, data-driven intelligence, agents requiring external information"
  },
  {
    "Pattern Name": "Self-Critique / Self-Refinement",
    "Problem": "LLM outputs may contain errors, biases, or suboptimal solutions, and a single generation might not be sufficient.",
    "Context": "Tasks where quality control, error detection, and iterative improvement of LLM-generated content are crucial, or where multiple attempts can lead to a better solution.",
    "Solution": "Use the LLM itself (or another model) to evaluate its own previous output, identify flaws, and generate revised outputs or critiques. This often involves feeding the initial output and a critique/feedback back into the LLM as part of a new prompt, or generating multiple options and selecting the best.",
    "Result": "Improves the quality, accuracy, and safety of LLM outputs by allowing for iterative correction and optimization.",
    "Related Patterns": [
      "Prompt Chaining / Multi-Step Prompting",
      "Reasoning Actions",
      "Learning Actions",
      "Memory-Augmented Reflection"
    ],
    "Uses": "Code generation, complex problem-solving, dialogue systems, safety alignment, creative tasks"
  },
  {
    "Pattern Name": "Agentic Loop / Cognitive Loop / Decision-Making Loop",
    "Problem": "LLMs are inherently stateless and passive, making them unsuitable for autonomous, adaptive behavior in dynamic, interactive environments.",
    "Context": "Building intelligent agents that need to operate continuously, interact with external environments (physical, digital, human), maintain internal state, and pursue long-term goals.",
    "Solution": "Implement a continuous feedback loop where the agent iteratively performs the following steps: 1. Observe (perceive the environment, often grounded to text). 2. Plan (use internal processes like reasoning and retrieval from memory to decide on the next action). 3. Act (execute the chosen action, internal or external). 4. Learn (update internal memory or parameters based on the action's outcome or new experiences).",
    "Result": "Transforms stateless LLMs into stateful, adaptive, and autonomous agents capable of sustained interaction and goal-directed behavior.",
    "Related Patterns": [
      "Modular Memory System",
      "Grounding Actions / Tool Use",
      "Reasoning Actions",
      "Learning Actions",
      "Decision Making (Planning & Execution)",
      "ReAct (Reasoning and Acting)"
    ],
    "Uses": "Robotics, web agents, game AI, social simulations, long-running conversational agents"
  },
  {
    "Pattern Name": "Modular Memory System",
    "Problem": "LLMs have limited context windows and are stateless, making it challenging to retain long-term information, track dialogue history, or store agent-specific knowledge and experiences.",
    "Context": "Agents requiring persistence of information across interactions, access to past experiences, domain-specific knowledge, or the ability to learn and update internal state.",
    "Solution": "Design the agent with distinct, specialized memory modules, each optimized for different types of information and access patterns. These include: Working Memory (active, short-term), Episodic Memory (past experiences), Semantic Memory (general knowledge/facts), and Procedural Memory (agent's code, LLM weights, skills). Information is dynamically moved between these memories and working memory via retrieval and learning actions.",
    "Result": "Overcomes LLM statelessness and context window limitations, enabling long-term memory, learning, more sophisticated reasoning, and a richer internal state for the agent.",
    "Related Patterns": [
      "Retrieval Augmented Generation (RAG)",
      "Learning Actions",
      "Memory-Augmented Reflection"
    ],
    "Uses": "Long-running dialogue agents, embodied agents, lifelong learning systems, personalized agents"
  },
  {
    "Pattern Name": "Grounding Actions / Tool Use",
    "Problem": "LLMs operate on text and are isolated from the real world or specific digital tools, limiting their ability to perceive non-textual inputs or perform concrete actions.",
    "Context": "Agents designed to operate in physical robots, interact with digital interfaces (APIs, websites, games), or engage in human dialogue, requiring interaction beyond pure text generation.",
    "Solution": "Implement specific procedures (tools, APIs, or direct code execution) that translate non-textual perceptual inputs (vision, audio, sensor data) into textual observations for the LLM, and translate LLM-generated textual commands or structured function calls into executable actions in the environment (e.g., motor commands, API calls, web interactions, natural language responses).",
    "Result": "Enables LLMs to perceive and act in the external world, connecting their linguistic and reasoning abilities to real-world effects, expanding their capabilities beyond text generation.",
    "Related Patterns": [
      "Agentic Loop / Cognitive Loop / Decision-Making Loop",
      "Function Calling / Structured Output Parsing",
      "ReAct (Reasoning and Acting)",
      "LLM-Code Hybrid / Complementary Capabilities"
    ],
    "Uses": "Robotics, web automation, API integration, game playing, conversational AI, data querying"
  },
  {
    "Pattern Name": "Reasoning Actions",
    "Problem": "LLMs often generate direct answers or actions without explicit intermediate thought processes, which can lead to suboptimal or incorrect outputs for complex tasks.",
    "Context": "Tasks requiring deeper analysis, summarization, distillation of observations, inference from retrieved knowledge, or the generation of intermediate steps before a final action or answer.",
    "Solution": "Design specific internal actions where the LLM is prompted to process and synthesize information within its working memory (e.g., recent observations, retrieved facts) to generate new, temporary insights, analyses, or intermediate steps. This output is then written back into working memory, informing subsequent decisions.",
    "Result": "Enables more deliberate, robust, and interpretable thought processes, leading to better-informed actions and improved problem-solving.",
    "Related Patterns": [
      "Prompt Chaining / Multi-Step Prompting",
      "Self-Critique / Self-Refinement",
      "Decision Making (Planning & Execution)",
      "Tree of Thoughts (ToT) / Deliberative Search-Based Planning",
      "Memory-Augmented Reflection",
      "ReAct (Reasoning and Acting)"
    ],
    "Uses": "Planning, self-reflection, summarization, complex problem-solving, generating Chain-of-Thought"
  },
  {
    "Pattern Name": "Learning Actions",
    "Problem": "Agents need to continuously acquire and store new information, update their knowledge, or refine their behaviors based on experience or feedback to improve performance over time, beyond just in-context learning.",
    "Context": "Agents operating in dynamic environments, requiring adaptation, skill acquisition, long-term knowledge retention, or self-improvement.",
    "Solution": "Implement explicit internal actions that allow the agent to write new information to its long-term memory modules or update its internal parameters. This includes: updating episodic memory with experiences, updating semantic memory with knowledge/inferences, finetuning LLM parameters (implicit procedural memory), and modifying agent code (explicit procedural memory).",
    "Result": "Enables agents to improve their capabilities, adapt to new situations, and achieve lifelong learning and self-improvement, reducing dependence on static knowledge.",
    "Related Patterns": [
      "Modular Memory System",
      "Self-Critique / Self-Refinement",
      "Skill Learning / Procedural Knowledge Acquisition",
      "Memory-Augmented Reflection"
    ],
    "Uses": "Lifelong learning, skill acquisition, adaptation to new tasks/environments, self-improving agents"
  },
  {
    "Pattern Name": "Decision Making (Planning & Execution)",
    "Problem": "With a diverse action space and memory, agents need a structured and deliberate way to choose the most appropriate action at any given time, especially for complex, multi-step tasks.",
    "Context": "Agents operating in environments requiring deliberation, exploration of alternatives, anticipation of consequences, or complex goal-directed behavior.",
    "Solution": "Structure the agent's internal decision process into a planning phase that precedes execution. This involves: 1. Proposal (generating one or more candidate actions or intermediate thoughts). 2. Evaluation (assessing the potential value, outcomes, or feasibility of proposed actions/thoughts, often using LLM reasoning or internal simulations). 3. Selection (choosing the best action or thought, or deciding to backtrack/re-propose). The selected action is then executed.",
    "Result": "Enables deliberate, goal-oriented behavior, allowing agents to explore options, anticipate consequences, and make more informed decisions than direct, single-pass action generation.",
    "Related Patterns": [
      "Agentic Loop / Cognitive Loop / Decision-Making Loop",
      "Reasoning Actions",
      "Tree of Thoughts (ToT) / Deliberative Search-Based Planning",
      "LLM-Code Hybrid / Complementary Capabilities"
    ],
    "Uses": "Complex task solving, strategic games, robotics, problem-solving, general agent control flow"
  },
  {
    "Pattern Name": "Skill Learning / Procedural Knowledge Acquisition",
    "Problem": "Agents often require domain-specific skills or complex action sequences that are difficult to hardcode or learn from scratch with a single LLM, and need to expand their capabilities over time.",
    "Context": "Embodied agents or agents in complex digital environments (e.g., games, software development) where new, reusable capabilities (code-based skills, prompt templates) are needed.",
    "Solution": "Enable the agent to autonomously generate, test, refine, and store new code-based skills (grounding procedures) or prompt templates (reasoning procedures) in its procedural memory. These learned skills can then be retrieved and reused for future tasks.",
    "Result": "Allows agents to autonomously expand their action space, master complex tasks, and generalize to unseen tasks, reducing reliance on human pre-specification and enabling curriculum learning.",
    "Related Patterns": [
      "Learning Actions",
      "Modular Memory System",
      "Grounding Actions / Tool Use",
      "Self-Critique / Self-Refinement",
      "LLM-Code Hybrid / Complementary Capabilities"
    ],
    "Uses": "Robotics, game AI (e.g., Minecraft's tech tree), interactive code generation, automating complex workflows"
  },
  {
    "Pattern Name": "Memory-Augmented Reflection",
    "Problem": "Agents accumulate raw episodic experiences, but need to distill these into higher-level, generalized knowledge or insights to improve future decision-making and planning, beyond just direct recall.",
    "Context": "Agents with a growing episodic memory that contains many past interactions or trajectories, where abstracting lessons learned is beneficial.",
    "Solution": "Periodically use the LLM to perform 'reasoning actions' over a collection of past 'episodic memories' to generate 'reflections' or 'inferences.' These distilled insights are then stored in 'semantic memory' as new, generalized knowledge, which can be retrieved later to inform planning or decision-making.",
    "Result": "Enables agents to learn higher-level, abstract knowledge from their experiences, leading to more robust planning, better self-correction, and improved generalization.",
    "Related Patterns": [
      "Modular Memory System",
      "Reasoning Actions",
      "Learning Actions",
      "Retrieval Augmented Generation (RAG)",
      "Self-Critique / Self-Refinement"
    ],
    "Uses": "Social simulation, long-term planning, self-improvement, debugging agent behavior"
  },
  {
    "Pattern Name": "Tree of Thoughts (ToT) / Deliberative Search-Based Planning",
    "Problem": "Complex reasoning problems (e.g., creative writing, puzzle solving, multi-step planning) require exploring multiple reasoning paths, evaluating intermediate steps, and backtracking from dead ends, which single-pass LLM generation struggles with.",
    "Context": "Tasks where the optimal solution requires exploring a combinatorial space of thoughts or actions, similar to classical search problems, and where intermediate thoughts can be evaluated.",
    "Solution": "Structure the decision-making process as a tree search (e.g., BFS, DFS, MCTS) where the LLM generates 'thoughts' (intermediate reasoning steps or potential actions) as nodes, evaluates their quality or promise, and the agent selects the most promising path to explore, allowing for backtracking and global exploration.",
    "Result": "Enables more deliberate, robust, and potentially optimal problem-solving by leveraging the LLM's reasoning capabilities within a structured search framework, overcoming the 'myopia' of autoregressive generation.",
    "Related Patterns": [
      "Decision Making (Planning & Execution)",
      "Reasoning Actions",
      "Prompt Chaining / Multi-Step Prompting"
    ],
    "Uses": "Creative writing, puzzle solving (e.g., Game of 24), complex reasoning tasks, strategic planning"
  },
  {
    "Pattern Name": "LLM-Code Hybrid / Complementary Capabilities",
    "Problem": "LLMs excel at flexible, commonsense reasoning and text generation but can be brittle, opaque, and poor at deterministic logic, complex algorithms, or maintaining precise state. Traditional code is robust for logic but lacks generalization and natural language understanding.",
    "Context": "Building agents that require both flexible, open-ended reasoning and reliable, deterministic execution of complex logic, algorithms, or precise interactions.",
    "Solution": "Design agents with a hybrid architecture where the LLM handles flexible reasoning, natural language understanding, and generation of high-level plans/intentions, while deterministic code (e.g., Python functions, classical algorithms, state machines) handles structured logic, precise calculations, state management, and reliable interactions with tools/APIs.",
    "Result": "Combines the strengths of LLMs (flexibility, commonsense) with the reliability of traditional code (logic, control), leading to more robust, controllable, and capable agents. Reduces LLM hallucination in structured tasks.",
    "Related Patterns": [
      "Grounding Actions / Tool Use",
      "Function Calling / Structured Output Parsing",
      "Decision Making (Planning & Execution)",
      "Skill Learning / Procedural Knowledge Acquisition"
    ],
    "Uses": "Planning, robotics, data analysis, complex workflow automation, any agent requiring both high-level reasoning and precise execution"
  },
  {
    "Pattern Name": "ReAct (Reasoning and Acting)",
    "Problem": "LLMs struggle with tasks requiring iterative interaction with the environment and intermediate reasoning steps to effectively plan and execute actions. Direct action generation can be myopic or prone to errors.",
    "Context": "Interactive tasks in digital environments (e.g., web, APIs, text games) where the agent needs to observe, think, and act sequentially to achieve a goal.",
    "Solution": "Integrate reasoning and acting in a tight, interleaved loop. The LLM generates a 'Thought' (reasoning step) to analyze the current situation, plan, or reflect, followed by an 'Action' (grounding step) to interact with the environment or call a tool. The environment's 'Observation' (feedback) then feeds back into the next 'Thought', creating a continuous thought-action-observation cycle.",
    "Result": "Enables agents to perform complex, multi-step tasks by breaking them down into manageable, self-correcting cycles, improving task completion, robustness, and interpretability.",
    "Related Patterns": [
      "Agentic Loop / Cognitive Loop / Decision-Making Loop",
      "Prompt Chaining / Multi-Step Prompting",
      "Reasoning Actions",
      "Grounding Actions / Tool Use",
      "Decision Making (Planning & Execution)"
    ],
    "Uses": "Web navigation, API interaction, text-based games, general problem-solving, tool-use agents"
  },
  {
    "Pattern Name": "Function Calling / Structured Output Parsing",
    "Problem": "LLMs naturally generate free-form text, which is difficult to reliably parse into structured data or executable function calls needed for tools, APIs, or internal actions, leading to brittle integration.",
    "Context": "Agents needing to use external tools, APIs, or internal functions where inputs must conform to a specific schema, function signature, or data structure.",
    "Solution": "Design prompts that explicitly instruct the LLM to generate output in a structured, machine-readable format (e.g., JSON, YAML, or a specific function call syntax). Use a robust parser (or built-in LLM capabilities like OpenAI's function calling) to extract the structured data or arguments for executing a predefined function or tool. Techniques like constrained generation can enforce this.",
    "Result": "Enables reliable and robust integration of LLMs with external tools and internal code, making agent actions more predictable, controllable, and less prone to parsing errors.",
    "Related Patterns": [
      "Grounding Actions / Tool Use",
      "LLM-Code Hybrid / Complementary Capabilities"
    ],
    "Uses": "API integration, database querying, code generation, structured data extraction, controlling external systems"
  }
]