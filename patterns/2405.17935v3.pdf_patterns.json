[
  {
    "Pattern Name": "Iterative Invocation Tool Learning",
    "Problem": "LLMs struggle with complex, multi-step tasks that might fail or require adjustments based on intermediate results, leading to brittle, one-shot solutions.",
    "Context": "LLMs need to solve complex tasks that might require multiple steps, interaction with external tools, and dynamic adjustment in real-world scenarios.",
    "Solution": "The LLM does not commit to a complete task plan upfront. Instead, it iteratively interacts with tools, adjusting subtasks progressively based on feedback (results or errors) from tool execution, refining its plan continuously.",
    "Result": "Improves problem-solving capabilities by allowing LLMs to refine their plan continuously and address problems step-by-step, making the system more resilient and adaptive.",
    "Related Patterns": [
      "Single Invocation Tool Learning",
      "Task Decomposition",
      "ReAct (Reasoning and Acting)",
      "Error Handling for Tool Calling"
    ],
    "Uses": "ToolLLaMA, APIBank, Confucius, RestGPT, and general agentic systems requiring dynamic plan adjustment."
  },
  {
    "Pattern Name": "Single Invocation Tool Learning",
    "Problem": "Early LLM tool integration approaches lacked adaptability to execution errors or dynamic environments, relying on a fixed, pre-planned sequence of actions.",
    "Context": "Simpler tasks where the complete sequence of actions can be planned upfront, or where feedback from tool execution is not integrated back into planning.",
    "Solution": "Upon receiving a user question, the LLM analyzes the user intent and immediately plans all the subtasks needed to solve the problem. It then directly generates a response based on the results returned by the selected tools without considering the possibility of errors during the process or altering the plan based on tool feedback.",
    "Result": "Provides a straightforward, one-shot solution for tool-augmented tasks, suitable for less complex problems where dynamic adaptation is not critical.",
    "Related Patterns": [
      "Iterative Invocation Tool Learning",
      "Task Decomposition"
    ],
    "Uses": "Toolformer, Chameleon, HuggingGPT, and early tool learning systems."
  },
  {
    "Pattern Name": "Task Decomposition",
    "Problem": "User queries often embody complex intent that cannot be solved directly by a single tool or a simple LLM response, requiring a structured approach to problem-solving.",
    "Context": "LLMs receive complex, multi-step user queries.",
    "Solution": "The LLM analyzes the user's intent and breaks down the complex query into multiple, potentially solvable subquestions. It also identifies dependencies and the execution sequence of these subtasks.",
    "Result": "Facilitates the structured execution of complex tasks, enabling LLMs to address questions step-by-step and demonstrating logical analysis capabilities.",
    "Related Patterns": [
      "Chain-of-Thought (CoT) Planning",
      "ReAct (Reasoning and Acting)",
      "Fine-tuned Task Planner",
      "Iterative Invocation Tool Learning"
    ],
    "Uses": "ART, RestGPT, HuggingGPT, ToolChain, TPTU, ControlLLM, Attention Buckets, PLUTO, ATC, SGC, Sum2Act, BTP, DRAFT, Toolformer, TaskMatrixAI, Toolink, TPTUv2, UMi, COA, DEER, OpenAGI, SOAY, TPLLAMA, APIGen."
  },
  {
    "Pattern Name": "Chain-of-Thought (CoT) Planning",
    "Problem": "LLMs struggle with complex reasoning and multi-step task planning, especially in zero-shot or few-shot settings, often leading to incorrect or incomplete plans.",
    "Context": "LLMs are used for task planning, particularly when explicit fine-tuning is not feasible or desired.",
    "Solution": "The LLM is prompted to generate intermediate reasoning steps (a 'chain of thought') before producing the final plan or action sequence. This can involve explicit directives like 'let's think step by step,' leveraging the LLM's in-context learning abilities.",
    "Result": "Enhances the LLM's ability to decompose complex tasks into simpler subtasks, facilitates structured action planning, and improves the quality of task plans without explicit fine-tuning.",
    "Related Patterns": [
      "Task Decomposition",
      "ReAct (Reasoning and Acting)",
      "LLM-based Tool Selection"
    ],
    "Uses": "CoT, ReACT, ART, RestGPT, HuggingGPT, TPTU, ToolChain, ControlLLM, Attention Buckets, PLUTO, ATC, SGC, Sum2Act, BTP, DRAFT."
  },
  {
    "Pattern Name": "ReAct (Reasoning and Acting)",
    "Problem": "LLMs need to perform complex tasks that require both reasoning about the task and taking specific actions (e.g., using tools), and adapt their reasoning based on feedback from those actions.",
    "Context": "LLMs are used as agents in environments where they need to interact with external tools or systems.",
    "Solution": "This framework integrates reasoning (Chain-of-Thought) with actions. The LLM generates thoughts to reason about the task, decides on an action (e.g., tool call), executes it, and then observes the outcome. This feedback (observation) is then used to refine subsequent reasoning and actions.",
    "Result": "Enhances the adaptability and decision-making capabilities of LLMs by fostering a dynamic interaction between reasoning and action, leading to more robust and accurate task execution, especially in iterative tool learning scenarios.",
    "Related Patterns": [
      "Chain-of-Thought (CoT) Planning",
      "Iterative Invocation Tool Learning",
      "Task Decomposition",
      "Error Handling for Tool Calling"
    ],
    "Uses": "ReACT, and general agentic systems requiring dynamic interaction between reasoning and action."
  },
  {
    "Pattern Name": "Fine-tuned Task Planner",
    "Problem": "Zero-shot or few-shot task planning with LLMs, while impressive, often lacks the precision, domain-specific awareness, and overall effectiveness of models specifically trained for tool usage and task decomposition.",
    "Context": "Developing LLM-based agents or systems that require high-performance, domain-specific, or highly accurate task planning and tool-calling capabilities.",
    "Solution": "A base LLM is fine-tuned on carefully curated datasets that include examples of task decomposition, tool usage, and API calls. This training can involve techniques like Reinforcement Learning from Human Feedback (RLHF) or behavior cloning to enhance tool awareness and capability.",
    "Result": "Significantly enhances the LLM's awareness and capability to utilize tools effectively, improves task planning, and allows for better performance in domain-specific tasks compared to tuning-free methods.",
    "Related Patterns": [
      "Task Decomposition",
      "Parameter Extraction and Formatting"
    ],
    "Uses": "Toolformer, TaskMatrixAI, Toolink, TPTUv2, UMi, COA, DEER, OpenAGI, SOAY, TPLLAMA, APIGen."
  },
  {
    "Pattern Name": "Retriever-based Tool Selection",
    "Problem": "Real-world systems often have a vast number of available tools, making it impractical to include descriptions of all tools in the LLM's input context due to length limitations and latency constraints.",
    "Context": "LLMs need to select tools from a very large pool of available options.",
    "Solution": "An efficient tool retrieval system is employed as a preliminary step. This system uses methods (e.g., TFIDF, BM25, SentenceBert, ANCE, TASB, Contriever, coCondensor, GNNs) to identify and filter the top-K most relevant tools for a given user query or subquestion. These top-K tools are then presented to the LLM for final selection.",
    "Result": "Bridges the gap between broad LLM capabilities and practical input size limitations, enabling efficient and effective tool selection from vast tool sets, reducing latency and improving relevance.",
    "Related Patterns": [
      "LLM-based Tool Selection"
    ],
    "Uses": "Gorilla, ToolLLaMA, Confucius, TPTUv2, CRAFT, ProTIP, ToolRerank, COLT."
  },
  {
    "Pattern Name": "LLM-based Tool Selection",
    "Problem": "Given a set of candidate tools, LLMs need to accurately select the most appropriate tool(s) for a specific subquestion, often requiring reasoning about tool descriptions, parameters, and potential sequential dependencies.",
    "Context": "LLMs are provided with a limited list of candidate tools (either from a small library or pre-filtered by a retriever).",
    "Solution": "The LLM receives the user query (or subquestion) along with the descriptions and parameter lists of the candidate tools. It then uses its reasoning capabilities (e.g., in-context learning, Chain-of-Thought, fine-tuning) to select the optimal tool(s) and, if applicable, determine the correct invocation order for serial tool calling.",
    "Result": "Enables LLMs to make informed tool choices based on semantic understanding of the query and tool functionalities, improving the accuracy and effectiveness of tool usage.",
    "Related Patterns": [
      "Retriever-based Tool Selection",
      "Chain-of-Thought (CoT) Planning",
      "ReAct (Reasoning and Acting)",
      "Fine-tuned Task Planner"
    ],
    "Uses": "CoT, ReACT, ToolLLaMA, Confucius, ToolBench, RestGPT, HuggingGPT, ChatCoT, ToolNet, ToolVerifier, TRICE, AnyTool, GeckOpt."
  },
  {
    "Pattern Name": "Parameter Extraction and Formatting",
    "Problem": "LLMs need to accurately extract required parameters from user queries and format them according to specific tool API specifications, while avoiding superfluous sentences or incorrect data types, to ensure successful tool invocation.",
    "Context": "After selecting a tool, the LLM needs to invoke it by providing the correct input parameters.",
    "Solution": "The LLM processes the user query and the selected tool's documentation (including parameter specifications). It then extracts the necessary parameter content and ensures it adheres strictly to the prescribed format (e.g., data type, range, comma-separated lists). This can be achieved through few-shot prompting, rule-based methods, or fine-tuning.",
    "Result": "Enables successful and error-free invocation of external tools, preventing common API calling errors and ensuring the tool receives valid input.",
    "Related Patterns": [
      "Fine-tuned Task Planner"
    ],
    "Uses": "RestGPT, Reverse Chain, ControlLLM, EasyTool, ToolNet, ConAgents, Gorilla, GPT4Tools, ToolkenGPT, Themis, STE, ToolVerifier, TRICE."
  },
  {
    "Pattern Name": "Error Handling for Tool Calling",
    "Problem": "Tool invocations can frequently fail due to various reasons (e.g., incorrect parameter formatting, parameters out of range, tool server errors), which can disrupt the agent's workflow and lead to poor user experience.",
    "Context": "LLMs are engaged in tool learning, and tool calling is an inherent part of the process where failures can occur.",
    "Solution": "Mechanisms are integrated to detect and process error messages returned upon tool calling failure. The LLM then refines its subsequent actions (e.g., re-plan, re-select tools, adjust parameters) based on this error feedback.",
    "Result": "Enhances the resilience and adaptability of the tool learning system, ensuring continuity and efficiency even in the face of operational disruptions during tool invocation.",
    "Related Patterns": [
      "Iterative Invocation Tool Learning",
      "ReAct (Reasoning and Acting)"
    ],
    "Uses": "Robust agentic systems, real-world applications with unreliable or complex APIs, systems requiring high fault tolerance."
  },
  {
    "Pattern Name": "Information Integration for Response Generation",
    "Problem": "Directly inserting raw tool outputs into an LLM's response can be impractical (due to diverse formats, length, or potential for affecting user experience) or insufficient, as LLMs need to synthesize information and integrate their own knowledge for a coherent reply.",
    "Context": "LLMs have received outputs from external tools and need to formulate a coherent, comprehensive, and user-friendly response.",
    "Solution": "The tool outputs are incorporated into the LLM's context as input. The LLM then processes this information, synthesizes it with its internal knowledge, and generates a refined, natural-language response tailored to the user's original query. Methods to handle lengthy outputs (e.g., compression, summarization, truncation) are often employed.",
    "Result": "Produces superior, more comprehensive, and user-friendly responses by effectively combining external data with the LLM's generative capabilities, enhancing user experience and accuracy.",
    "Related Patterns": [
      "Direct Insertion for Response Generation"
    ],
    "Uses": "RestGPT, ToolLLaMA, ReCOMP, ConAgents, HuggingGPT."
  },
  {
    "Pattern Name": "Direct Insertion for Response Generation",
    "Problem": "Complex synthesis of tool outputs may be unnecessary for simple queries, but raw insertion can lead to less natural responses or issues if tool outputs are unpredictable.",
    "Context": "LLMs have received outputs from tools, particularly for simple queries where the raw output is directly relevant and easily understandable.",
    "Solution": "The output of the tool is directly inserted or substituted into a pre-defined placeholder within the generated response template, often without further LLM-based synthesis.",
    "Result": "Provides a straightforward and efficient way to integrate tool results for simple cases, but may lead to less natural or potentially confusing responses if tool outputs are complex or unexpected.",
    "Related Patterns": [
      "Information Integration for Response Generation"
    ],
    "Uses": "TALM, Toolformer, ToolkenGPT, and early tool learning systems."
  }
]