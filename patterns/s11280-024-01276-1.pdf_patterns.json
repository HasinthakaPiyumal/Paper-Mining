[
  {
    "Pattern Name": "LLMs as Knowledge Base",
    "Problem": "Traditional knowledge graphs (KGs) for recommender systems are limited, sparse, expensive to construct/complete, and lack extensive factual and cross-domain knowledge, leading to suboptimal recommendation performance.",
    "Context": "Recommender systems that can benefit from explicit knowledge to understand user-item relationships, enhance explainability, and provide cross-domain recommendations.",
    "Solution": "Leverage Large Language Models (LLMs) to retrieve factual and commonsense knowledge. LLMs are used for knowledge graph completion (predicting missing facts, entities, relations) and knowledge graph construction (entity discovery, coreference resolution, relation extraction, end-to-end KG building from raw text). This includes distilling commonsense facts from LLMs.",
    "Result": "More extensive and up-to-date knowledge bases, improved understanding of entity relations, enhanced recommendation accuracy, relevance, and personalization, particularly for cross-domain scenarios. Automation of knowledge graph construction.",
    "Related Patterns": ["LLMs as Content Interpreter", "LLMs as Explainer"],
    "Uses": "Enhancing Click-Through Rate (CTR) prediction models, graph augmentation strategies, determining complementary relationships between entities in industrial recommenders.",
    "Category": ["Knowledge & Reasoning Patterns", "LLM-specific Patterns"]
  },
  {
    "Pattern Name": "LLMs as Content Interpreter",
    "Problem": "Content-based recommender systems often suffer from sparse content features and traditional methods struggle to capture deep semantic information, long-context dependencies, and generalize effectively from textual content.",
    "Context": "Recommender systems that rely on textual attributes and characteristics of items (e.g., news articles, product descriptions, reviews) to understand item properties and match user preferences.",
    "Solution": "Employ powerful pretrained language models (PLMs) like BERT and GPT as advanced content interpreters. This involves fine-tuning PLMs for recommendation-specific objectives, initializing news encoders with PLMs, using PLMs to generate universal continuous representations from item descriptions for cold-start and cross-domain recommendations, and instruction tuning to formulate recommendation as an instruction-following task.",
    "Result": "Enhanced understanding and interpretation of textual content, improved recommendations, better capture of user interests, alleviation of cold-start problems, facilitation of cross-domain recommendations, and strong generalization abilities.",
    "Related Patterns": ["LLMs as Knowledge Base", "Prompt Design Patterns"],
    "Uses": "News recommendation, tag recommendation, tweet representations, code example recommendation, zero-shot/few-shot recommendation, rating prediction, sequential recommendation.",
    "Category": ["LLM-specific Patterns", "Personalization Pattern"]
  },
  {
    "Pattern Name": "LLMs as Explainer",
    "Problem": "Most recommender systems are black boxes, leading to a lack of transparency and diminished user trust. Traditional explanation methods are often formulaic, lack diversity, and are tightly coupled with specific models, limiting generalizability.",
    "Context": "Recommender systems where users desire comprehensible, persuasive, and transparent justifications for recommendations, and where system errors need to be identifiable.",
    "Solution": "Leverage LLMs' generative ability, extensive training data, and in-context learning capabilities (zero-shot, few-shot, Chain-of-Thought prompting) to craft customized, precise, natural, and adaptable explanations. LLMs can also provide model-agnostic interpretations of complex deep learning recommendation models.",
    "Result": "Improved user trust, transparency, and satisfaction; more diverse and coherent explanations; real-time feedback integration; a versatile and scalable interpretation framework applicable across various recommendation models.",
    "Related Patterns": ["Prompt Design Patterns", "AI–Human Interaction Patterns", "Generative AI Patterns"],
    "Uses": "Generating justifications for drug recommendations, product recommendations, and general explainable recommendations.",
    "Category": ["AI–Human Interaction Patterns", "LLM-specific Patterns", "Generative AI Patterns", "Prompt Design Patterns"]
  },
  {
    "Pattern Name": "LLMs as Common System Reasoner (Direct Recommendation)",
    "Problem": "Traditional recommendation models typically require explicit training or fine-tuning for new tasks or domains, making adaptation to new cases without extensive data and training challenging.",
    "Context": "Recommender systems aiming to provide recommendations (e.g., rating prediction, ranking prediction) with minimal or no explicit training, especially when operating on open-domain datasets.",
    "Solution": "Utilize LLMs' emergent abilities of in-context learning (zero-shot/few-shot) and step-by-step reasoning (Chain-of-Thought). By providing natural language instructions and/or a few input-output demonstrations in the prompt, LLMs can generate recommendations without explicit training. Chain-of-Thought prompting guides LLMs to break down complex tasks into intermediate reasoning steps.",
    "Result": "Ability to make predictions on new recommendation cases with minimal or no training, improved recommendation performance through multi-step reasoning, particularly effective in open-domain scenarios.",
    "Related Patterns": ["Prompt Design Patterns", "LLM-specific Patterns", "Knowledge & Reasoning Patterns"],
    "Uses": "Rating prediction, ranking prediction, sequential recommendation, and reranking tasks in open-domain datasets like MovieLens and Amazon Books.",
    "Category": ["LLM-specific Patterns", "Prompt Design Patterns", "Knowledge & Reasoning Patterns", "Personalization Pattern"]
  },
  {
    "Pattern Name": "LLMs as Common System Reasoner (Automated Selection for AutoML)",
    "Problem": "Automated Machine Learning (AutoML) in recommender systems involves complex, large search spaces (e.g., embedding size, features, interactions, model architecture) and costly manual setup or time-consuming traditional search strategies.",
    "Context": "The design and optimization of recommender systems, particularly in areas like Neural Architecture Search (NAS) and feature engineering, where automation is desired to reduce manual effort and improve efficiency.",
    "Solution": "Leverage LLMs' memorization and reasoning capabilities to automate aspects of AutoML. LLMs can generate network architectures, act as black-box agents to propose better-performing architectures based on past trials, or be integrated into existing search algorithms (e.g., genetic algorithms) to guide the search process and generate candidate crossovers/mutations.",
    "Result": "Reduced manual effort and improved efficiency in AutoML for recommender systems, generation of reasonable or better-performing architectures, and enhanced search performance when LLMs are integrated with other optimization algorithms.",
    "Related Patterns": ["Planning Patterns", "LLM-specific Patterns", "Knowledge & Reasoning Patterns"],
    "Uses": "Neural Architecture Search (NAS) for recommender systems, feature interaction search.",
    "Category": ["MLOps Patterns", "Planning Patterns", "LLM-specific Patterns", "Knowledge & Reasoning Patterns"]
  },
  {
    "Pattern Name": "LLMs as Conversational Agent",
    "Problem": "Traditional conversational recommender systems (CRSs) face challenges with scalability, lack of synergy between components, and a high demand for supervised training data. They also struggle to maintain context and memory over long conversations due to token limits.",
    "Context": "Personalized assistance and recommendation systems that interact with users through natural language dialogues to uncover preferences, provide real-time recommendations, and adapt strategies based on user feedback.",
    "Solution": "Employ LLMs as the core of CRSs due to their inherent conversational abilities, intelligence, and knowledge. This involves: 1) Leveraging LLMs' pre-trained conversational capabilities. 2) Fine-tuning LLMs with private, domain-specific dialogue data, potentially generated by user simulators. 3) Utilizing tool learning, where LLMs act as controllers to integrate and use traditional recommendation models or external data sources. 4) Implementing memory augmentation techniques to store and retrieve user profiles and facts from long dialogue contexts.",
    "Result": "Real-time understanding of user intents, adaptive and personalized recommendations, reduced data dependency for generative dialogue models, improved handling of private domain data, and enhanced ability to manage long conversational contexts.",
    "Related Patterns": ["Tools Integration Patterns", "Prompt Design Patterns", "LLM-specific Patterns", "AI–Human Interaction Patterns"],
    "Uses": "Building enterprise-level CRSs, open-domain recommendations (movies, music, news, games), personalized assistants.",
    "Category": ["Agentic AI Patterns", "AI–Human Interaction Patterns", "LLM-specific Patterns", "Tools Integration Patterns", "Personalization Pattern"]
  },
  {
    "Pattern Name": "LLM-based Tool Learning",
    "Problem": "LLMs have limitations in accessing knowledge beyond their training data, performing complex computations, or interacting with external systems. They may also struggle to break down complex tasks into executable subtasks autonomously.",
    "Context": "Any AI system where foundational models (LLMs) need to enhance their task-solving capabilities by combining with specialized external tools to overcome inherent limitations.",
    "Solution": "Apply LLMs as intelligent controllers to select, manage, and interact with various existing AI models or specialized tools. LLMs comprehend problem statements, decompose tasks into subtasks, convert them into executable instructions for tools, and then aggregate the results. This can involve LLMs learning to use tools through self-supervised methods or acting as autonomous agents.",
    "Result": "Enhanced task-solving capabilities beyond the LLM's intrinsic knowledge, more accurate and efficient solutions for complex problems, access to external, real-time knowledge and functionalities, and improved generalization across diverse tasks.",
    "Related Patterns": ["Agentic AI Patterns", "Prompt Design Patterns", "LLM-specific Patterns"],
    "Uses": "Solving general AI tasks (e.g., HuggingGPT), complex visual tasks (Visual ChatGPT), web browsing, mathematical reasoning, robotic tasks, and general downstream tasks.",
    "Category": ["Tools Integration Patterns", "Agentic AI Patterns", "LLM-specific Patterns"]
  },
  {
    "Pattern Name": "LLM-augmented Recommendation Engine",
    "Problem": "LLMs struggle to memorize domain-specific knowledge (e.g., item corpora, user profiles) and are susceptible to temporal generalization problems (external knowledge evolving), leading to inaccurate or non-grounded recommendations in personalized systems.",
    "Context": "Personalization scenarios where LLMs act as recommendation agents but require grounding in specific, up-to-date, or private domain item corpora and detailed user data.",
    "Solution": "Equip LLMs with external tools, specifically dedicated recommendation engines, search engines, and databases. The LLM acts as an orchestrator, using search engines for external knowledge, a multi-stage recommendation engine (retrieve and rerank) to ground recommendations in item corpora, and databases (e.g., vector databases, user profile modules) to handle cold-start items or store/retrieve user-specific facts.",
    "Result": "Recommendations grounded in specific item corpora, ability to handle private/domain-specific knowledge, alleviation of cold-start and temporal generalization problems, more factual and personalized responses, and improved understanding of user intent.",
    "Related Patterns": ["LLM-based Tool Learning", "LLMs as Conversational Agent", "Personalization Pattern"],
    "Uses": "Music recommendation, content recommendation, and general personalized recommendations in conversational settings.",
    "Category": ["Tools Integration Patterns", "Personalization Pattern", "LLM-specific Patterns"]
  },
  {
    "Pattern Name": "LLMs as Personalized Content Creator",
    "Problem": "Traditional recommender systems primarily suggest existing items. There is a growing need to generate appealing, customized digital content that directly matches individual user interests, especially in areas like online advertising, where existing methods often use predefined templates or struggle with sparse feedback.",
    "Context": "Online advertising, e-commerce, customer service, and other scenarios where personalized, engaging digital content (text, images, multi-modal) needs to be generated to enhance user experience and drive business growth.",
    "Solution": "Integrate AI-Generated Content (AIGC) powered by LLMs into recommender systems. LLMs provide enhanced reasoning for user personalized intent and interest, even with few-shot prompting. Reinforcement Learning from Human Feedback (RLHF) can be applied to fine-tune models to better capture user intent. LLMs' powerful generative abilities and cross-modal knowledge bases enable realistic creation of text, images, and other multi-modal content. Interactive generation processes with feedback loops allow for better capture of explicit user preferences.",
    "Result": "More appealing, customized, and realistic content generated for users; improved understanding of explicit user preferences; enhanced user experiences; and increased business growth through personalized content.",
    "Related Patterns": ["Generative AI Patterns", "Personalization Pattern", "AI–Human Interaction Patterns"],
    "Uses": "Text ad generation (ad titles, descriptions), image generation, chatbots for personalized product recommendations, automated customer service responses, and FAQs.",
    "Category": ["Generative AI Patterns", "Personalization Pattern", "LLM-specific Patterns", "AI–Human Interaction Patterns"]
  }
]