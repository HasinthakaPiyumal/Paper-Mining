[
  {
    "Pattern Name": "LLMPlanner (Embodied Agent Few-Shot Grounded Planning)",
    "Problem": "Building versatile, sample-efficient embodied agents that can follow natural language instructions for complex, long-horizon tasks in diverse, partially observable environments. Existing methods require large amounts of labeled data, and static plans lack environmental grounding, leading to failures.",
    "Context": "Embodied agents (e.g., robots, virtual agents) operating in dynamic, visually-perceived environments, needing to execute multi-step instructions from natural language with minimal task-specific training data.",
    "Solution": "Implement a hierarchical planning framework where a Large Language Model (LLM) serves as a few-shot high-level planner, directly generating sequences of subgoals. This planning is continuously refined by a dynamic 'grounded replanning' algorithm that updates the plan based on real-time environmental observations (e.g., perceived objects) and execution failures, feeding this context back into the LLM prompt. The solution leverages in-context learning with dynamic example retrieval and logit biases for robust plan generation.",
    "Result": "Dramatically reduces the need for human annotations and training data, enabling versatile and sample-efficient embodied agents that can dynamically adapt their plans to the current environment, overcome unforeseen challenges, and achieve competitive performance with significantly less data.",
    "Related Patterns": [
      "Hierarchical Planning for Embodied Agents",
      "LLM as a Planner",
      "Grounded Replanning (with LLMs)",
      "In-Context Learning for Agent Planning",
      "Dynamic In-Context Example Retrieval",
      "Logit Biases for LLM Output Constraint"
    ],
    "Uses": "Embodied AI, Robotics, Vision-and-Language Navigation, Autonomous Agents, Task Automation, Few-Shot Learning for Robotics",
    "Category": "Agentic AI, LLM-specific, Planning, Knowledge & Reasoning, Prompt Design"
  },
  {
    "Pattern Name": "Hierarchical Planning for Embodied Agents",
    "Problem": "Directly planning complex, long-horizon tasks for embodied agents from high-level natural language instructions to low-level primitive actions is computationally intractable, difficult to generalize, or requires extensive domain knowledge.",
    "Context": "Embodied agents (e.g., robots, virtual agents) needing to perform multi-step, complex tasks in dynamic environments.",
    "Solution": "Decompose the overall planning process into two distinct layers: a High-Level Planner that interprets natural language instructions and generates a sequence of abstract subgoals (e.g., 'Navigate to object X', 'Pickup object Y'), and a Low-Level Planner that translates each subgoal into a sequence of primitive, executable actions within the current environment state. The high-level plan makes low-level planning conditionally independent of the initial natural language instruction.",
    "Result": "Simplifies the complex planning problem, allows for modular development and different specialized models for high-level (e.g., LLMs, symbolic AI) and low-level (e.g., classical planners, trained policies) tasks, and improves scalability for long-horizon tasks.",
    "Related Patterns": [
      "LLMPlanner (Embodied Agent Few-Shot Grounded Planning)",
      "LLM as a Planner",
      "Grounded Replanning (with LLMs)"
    ],
    "Uses": "Vision-and-Language Navigation, Robotics, Autonomous Agents, Complex Task Execution",
    "Category": "Planning, Agentic AI, Classical AI"
  },
  {
    "Pattern Name": "LLM as a Planner",
    "Problem": "Generating flexible, human-interpretable, and executable plans for agents from natural language instructions often requires extensive domain-specific rule engineering, large datasets of plan-action pairs, or pre-defined admissible action lists, which are difficult to obtain or manage in complex, partially observable environments.",
    "Context": "Agentic systems where natural language instructions need to be translated into a sequence of executable steps (plans or subgoals), often in dynamic or open-ended environments.",
    "Solution": "Leverage a Large Language Model (LLM) to directly generate a sequence of high-level actions, subgoals, or a full plan in response to a natural language instruction. This is typically achieved through careful prompt engineering, allowing the LLM to use its vast pre-trained knowledge and in-context examples to infer plausible and executable plans.",
    "Result": "Enables few-shot or zero-shot planning, reduces reliance on explicit domain models or large training datasets, and allows for more natural language interaction with the agent. The LLM's commonsense knowledge can produce contextually plausible plans.",
    "Related Patterns": [
      "LLMPlanner (Embodied Agent Few-Shot Grounded Planning)",
      "Hierarchical Planning for Embodied Agents",
      "Grounded Replanning (with LLMs)",
      "In-Context Learning for Agent Planning"
    ],
    "Uses": "Embodied AI, Robotics, Conversational Agents, Task Automation, Agentic AI",
    "Category": "LLM-specific, Planning, Agentic AI"
  },
  {
    "Pattern Name": "Grounded Replanning (with LLMs)",
    "Problem": "Static plans generated by high-level planners (especially LLMs) may lack physical grounding, failing when confronted with the actual, dynamic, or partially observed environment (e.g., an object is not found, an obstacle blocks a path, or the environment state differs from initial assumptions). This leads to execution failures and an inability to complete tasks.",
    "Context": "Embodied or autonomous agents executing pre-generated plans in real-world or simulated environments where unforeseen circumstances or discrepancies between the plan's assumptions and reality can occur.",
    "Solution": "Implement a feedback loop where the agent continuously monitors its execution progress and the environment state. When an execution failure or significant deviation occurs (e.g., taking too long to reach a subgoal, failed action, or a critical object is not found), the high-level planner (an LLM) is dynamically re-prompted. This re-prompt includes the original instruction, the partially completed plan, and crucially, real-time observations from the environment (e.g., a list of currently visible objects). The LLM then generates a new, grounded continuation of the plan, adapting to the current reality.",
    "Result": "Enables agents to dynamically adapt to environmental changes, recover from execution failures, resolve ambiguities (e.g., finding an object in an alternative location), and produce more robust and physically grounded plans, leading to higher task completion rates and a closed-loop interaction between the agent and its environment.",
    "Related Patterns": [
      "LLMPlanner (Embodied Agent Few-Shot Grounded Planning)",
      "LLM as a Planner",
      "Hierarchical Planning for Embodied Agents",
      "Logit Biases for LLM Output Constraint"
    ],
    "Uses": "Embodied AI, Robotics, Autonomous Navigation, Adaptive Planning, Error Recovery in Agent Systems",
    "Category": "Agentic AI, LLM-specific, Planning, Knowledge & Reasoning"
  },
  {
    "Pattern Name": "In-Context Learning for Agent Planning",
    "Problem": "Effectively leveraging the capabilities of Large Language Models (LLMs) for specific, structured tasks like agent planning without resource-intensive fine-tuning or requiring large task-specific datasets, especially in few-shot settings.",
    "Context": "Utilizing pre-trained LLMs for downstream tasks, particularly in scenarios with limited labeled data (few-shot setting) where the desired output is a structured plan or sequence of actions for an agent.",
    "Solution": "Craft a prompt that explicitly guides the LLM to generate the desired plan. This prompt typically includes: 1) An explicit instruction explaining the task to the LLM, 2) A clear definition of allowed actions or the expected output format, and 3) A small set of high-quality, relevant input-output examples (e.g., natural language instruction-plan pairs) placed directly within the prompt, demonstrating the desired planning behavior.",
    "Result": "Enables LLMs to perform few-shot planning, significantly reducing the need for task-specific training data and development time. This allows for rapid prototyping and adaptation of agent behaviors by simply modifying prompts and examples.",
    "Related Patterns": [
      "LLMPlanner (Embodied Agent Few-Shot Grounded Planning)",
      "Dynamic In-Context Example Retrieval",
      "Logit Biases for LLM Output Constraint"
    ],
    "Uses": "Few-shot learning, Prompt Engineering, Rapid Development of LLM-powered Agents, Task-Specific LLM Adaptation",
    "Category": "Prompt Design, LLM-specific, Classical AI"
  },
  {
    "Pattern Name": "Dynamic In-Context Example Retrieval",
    "Problem": "The effectiveness of in-context learning with LLMs is highly dependent on the quality and relevance of the provided examples. A fixed set of examples may not be optimal for diverse inputs, leading to suboptimal or inconsistent performance across different tasks or instructions.",
    "Context": "Implementing in-context learning with LLMs for various tasks, especially when dealing with a varied set of user instructions or tasks, and a larger pool of potential demonstration examples is available.",
    "Solution": "Instead of using a static set of in-context examples, dynamically select the most relevant examples for each specific test input. This typically involves: 1) Encoding the test input (e.g., the natural language instruction) into an embedding, 2) Comparing this embedding to pre-computed embeddings of a pool of available training examples, and 3) Retrieving the top-K most similar examples (e.g., using k-nearest neighbors based on cosine or Euclidean distance) to include in the LLM's prompt.",
    "Result": "Improves the overall performance, robustness, and consistency of in-context learning by ensuring that the LLM receives demonstrations that are highly pertinent to the current task, leading to more accurate and appropriate outputs.",
    "Related Patterns": [
      "LLMPlanner (Embodied Agent Few-Shot Grounded Planning)",
      "In-Context Learning for Agent Planning"
    ],
    "Uses": "Few-shot learning, Prompt Engineering, LLM-based systems, Contextual AI",
    "Category": "Prompt Design, LLM-specific, Classical AI"
  },
  {
    "Pattern Name": "Logit Biases for LLM Output Constraint",
    "Problem": "When LLMs are used for structured tasks like agent planning, their unconstrained natural language generation can produce outputs that are syntactically incorrect, semantically irrelevant, or contain tokens (e.g., actions, objects) not valid in the current context or environment. This leads to unexecutable or nonsensical results.",
    "Context": "Utilizing LLMs for tasks requiring specific output formats, adherence to a defined vocabulary (e.g., a set of allowed actions, recognized objects), or where certain tokens should be prioritized based on external, real-time information.",
    "Solution": "Apply 'logit biases' during the LLM's generation process. This involves programmatically adjusting the probability scores (logits) of specific tokens before sampling, increasing the likelihood of desired tokens (e.g., known high-level actions, currently observed objects) and decreasing the likelihood of undesired ones. This bias can be based on a dynamically compiled list of admissible tokens from the environment or a predefined action space.",
    "Result": "Guides the LLM to produce outputs that are more aligned with the desired structure and available context, improving the executability and correctness of generated plans. It also aids in disambiguation (e.g., selecting 'TableLamp' over 'FloorLamp' if 'TableLamp' is the only observed lamp) and grounding the LLM's output to the physical environment.",
    "Related Patterns": [
      "LLMPlanner (Embodied Agent Few-Shot Grounded Planning)",
      "Grounded Replanning (with LLMs)",
      "In-Context Learning for Agent Planning"
    ],
    "Uses": "Prompt Engineering, Constrained Text Generation, Structured Output from LLMs, Agent Planning, Object Disambiguation",
    "Category": "Prompt Design, LLM-specific, Tools Integration"
  }
]