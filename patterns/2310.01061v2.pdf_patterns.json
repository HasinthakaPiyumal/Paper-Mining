[
  {
    "Pattern Name": "Reasoning on Graphs (RoG)",
    "Problem": "Large Language Models (LLMs) lack up-to-date knowledge, experience hallucinations during reasoning, and overlook the structural information of Knowledge Graphs (KGs), diminishing their performance and trustworthiness in knowledge-intensive tasks.",
    "Context": "Knowledge Graph Question Answering (KGQA) tasks or other knowledge-intensive reasoning tasks where LLMs need to access and leverage structured, external knowledge for faithful and interpretable results.",
    "Solution": "A planning-retrieval-reasoning framework that synergizes LLMs with KGs. The 'planning module' first generates 'relation paths' (sequences of relations in a KG) grounded by KGs as faithful plans. These plans are then used by the 'retrieval-reasoning module' to retrieve valid 'reasoning paths' (instances of relation paths with entities) from the KGs. Finally, the LLM conducts faithful reasoning based on these retrieved, structured paths.",
    "Result": "Achieves state-of-the-art performance on KG reasoning tasks and generates faithful and interpretable reasoning results by grounding LLM reasoning in KG structure and knowledge.",
    "Related Patterns": [
      "LLM-KG Integration",
      "Retrieval-Augmented Generation (RAG) for LLMs",
      "Plan-and-Solve Reasoning",
      "Agentic LLM for External Interaction"
    ],
    "Uses": "Knowledge Graph Question Answering (KGQA), multi-hop reasoning, factual verification."
  },
  {
    "Pattern Name": "LLM-KG Integration",
    "Problem": "LLMs often lack structured, up-to-date, and explicit factual knowledge, leading to hallucinations and poor performance on knowledge-intensive tasks, especially those requiring multi-hop reasoning or structural understanding.",
    "Context": "Knowledge-intensive applications, complex question answering over structured data (KGs), and scenarios requiring interpretable and faithful reasoning.",
    "Solution": "Combine Large Language Models with Knowledge Graphs. This can involve various strategies: 1) Retrieving KG facts or paths to augment LLM prompts (a form of RAG). 2) Using LLMs to generate queries for KGs (Semantic Parsing). 3) Distilling KG knowledge into LLMs through training. 4) Allowing LLMs to act as agents that interact with KGs. 5) Using KG structure to guide LLM planning and reasoning.",
    "Result": "Improves factual accuracy, enables multi-hop and structural reasoning, reduces hallucinations, and enhances interpretability and faithfulness of LLM outputs.",
    "Related Patterns": [
      "Retrieval-Augmented Generation (RAG) for LLMs",
      "Semantic Parsing for LLMs",
      "Agentic LLM for External Interaction",
      "Reasoning on Graphs (RoG)"
    ],
    "Uses": "Knowledge Graph Question Answering (KGQA), fact extraction, knowledge base construction, explainable AI, scientific discovery."
  },
  {
    "Pattern Name": "Retrieval-Augmented Generation (RAG) for LLMs",
    "Problem": "LLMs suffer from knowledge cutoff, lack of up-to-date information, and hallucinations, leading to unfaithful or incorrect responses, particularly in knowledge-intensive tasks.",
    "Context": "Knowledge-intensive tasks, questions requiring factual accuracy, domain-specific information, or dynamic, real-time data.",
    "Solution": "Integrate a retrieval mechanism that fetches relevant information (e.g., documents, passages, knowledge graph triples, or reasoning paths) from an external, up-to-date knowledge source. This retrieved context is then provided to the LLM alongside the original prompt to ground and guide its generation.",
    "Result": "Reduces hallucinations, improves factual accuracy, provides access to up-to-date and external knowledge, and enhances the trustworthiness and specificity of LLM outputs.",
    "Related Patterns": [
      "LLM-KG Integration",
      "Agentic LLM for External Interaction",
      "Reasoning on Graphs (RoG)"
    ],
    "Uses": "Open-domain Question Answering, fact-checking, information synthesis, knowledge graph question answering, personalized content generation."
  },
  {
    "Pattern Name": "Plan-and-Solve Reasoning (Task Decomposition for LLMs)",
    "Problem": "LLMs struggle with complex, long-horizon tasks, or tasks requiring multiple, intricate reasoning steps, often leading to errors or incomplete solutions.",
    "Context": "LLMs solving complex problems, multi-step instructions, code generation, or deep reasoning tasks where a monolithic approach is insufficient.",
    "Solution": "Prompt LLMs to first generate a high-level plan or decompose the complex task into a series of smaller, more manageable subtasks. Then, the LLM executes each step of the plan or solves each subtask sequentially, often leveraging intermediate results.",
    "Result": "Improves the LLM's ability to handle complexity, reduces errors by breaking down problems, makes reasoning more structured, and enhances the transparency of the solution process.",
    "Related Patterns": [
      "Chain-of-Thought (CoT) Reasoning",
      "Advanced Reasoning Structures (Tree/Graph of Thoughts)",
      "Reasoning on Graphs (RoG)"
    ],
    "Uses": "Complex reasoning, multi-step problem-solving, code generation, robotics planning, strategic decision-making."
  },
  {
    "Pattern Name": "Agentic LLM for External Interaction",
    "Problem": "LLMs are typically static models with limited ability to access real-time information, perform actions, or interact with external environments or tools.",
    "Context": "Tasks requiring dynamic information retrieval, tool use (e.g., APIs, web search), environmental interaction, or complex multi-step problem-solving that goes beyond the LLM's internal knowledge.",
    "Solution": "Design the LLM to act as an agent that can interleave reasoning steps with calls to external tools, APIs, or knowledge bases. The LLM observes the environment or tool output, uses it to update its internal state, and plans subsequent actions. This often involves specific prompting strategies to guide the LLM's 'thought' and 'action' cycles.",
    "Result": "Extends LLM capabilities to dynamic, real-world tasks; provides access to up-to-date information; enables complex action sequences; improves groundedness and reduces hallucinations.",
    "Related Patterns": [
      "Retrieval-Augmented Generation (RAG) for LLMs",
      "LLM-KG Integration",
      "Plan-and-Solve Reasoning"
    ],
    "Uses": "Web browsing, API interaction, robotics, scientific discovery, dynamic question answering, complex code execution."
  },
  {
    "Pattern Name": "Semantic Parsing for LLMs",
    "Problem": "Directly querying structured knowledge bases (like KGs or databases) requires specialized query languages (e.g., SPARQL, SQL), which natural language models cannot generate or execute directly, limiting their ability to precisely extract or infer information from structured data.",
    "Context": "Knowledge Graph Question Answering (KGQA), structured database querying, or tasks where natural language questions need to be translated into formal, executable queries.",
    "Solution": "Use LLMs to convert natural language questions into formal, executable logical queries (e.g., SPARQL, lambda calculus). These generated queries can then be executed by a dedicated query engine on a Knowledge Graph or database to obtain precise answers.",
    "Result": "Enables precise and interpretable querying of structured knowledge, leveraging the LLM's understanding of natural language while maintaining the accuracy and executability of formal queries.",
    "Related Patterns": [
      "LLM-KG Integration"
    ],
    "Uses": "Knowledge Graph Question Answering, database querying from natural language, report generation from structured data."
  },
  {
    "Pattern Name": "Chain-of-Thought (CoT) Reasoning",
    "Problem": "LLMs often struggle with complex multi-step reasoning tasks, producing direct answers that may be incorrect or lack transparency regarding their derivation.",
    "Context": "Complex problem-solving, mathematical questions, logical puzzles, or any task requiring intermediate thinking steps and justification.",
    "Solution": "Prompt the LLM to generate a series of intermediate reasoning steps or a 'thought process' before arriving at the final answer. This is typically achieved through few-shot prompting with examples that explicitly demonstrate the reasoning chain.",
    "Result": "Improves the LLM's ability to perform complex reasoning, increases transparency and interpretability of its decisions, and often leads to more accurate and reliable results.",
    "Related Patterns": [
      "Plan-and-Solve Reasoning",
      "Advanced Reasoning Structures (Tree/Graph of Thoughts)",
      "Self-Correction/Verification for LLMs"
    ],
    "Uses": "Mathematical word problems, logical inference, common-sense reasoning, multi-step instructions, code explanation."
  },
  {
    "Pattern Name": "Advanced Reasoning Structures (Tree/Graph of Thoughts)",
    "Problem": "Linear Chain-of-Thought reasoning can be insufficient for highly complex problems, potentially leading to errors or missing optimal solutions due to its sequential nature or lack of broader exploration.",
    "Context": "Tasks requiring exploration of multiple reasoning paths, complex decision-making, creative problem-solving, or scenarios where backtracking and re-evaluation of intermediate thoughts are beneficial.",
    "Solution": "Extend linear reasoning chains into more complex, non-linear structures. 'Tree of Thoughts' involves generating multiple divergent reasoning paths, exploring them in parallel, and allowing for backtracking and pruning based on evaluation. 'Graph of Thoughts' further models reasoning as a graph, enabling non-linear progression, merging of ideas, and aggregation of information from different branches or sub-problems.",
    "Result": "Enhances LLM's ability to tackle more intricate problems, improves robustness by exploring diverse solutions, and facilitates more sophisticated planning and problem-solving than linear CoT.",
    "Related Patterns": [
      "Chain-of-Thought (CoT) Reasoning",
      "Plan-and-Solve Reasoning",
      "Monte-Carlo Planning for Faithful Reasoning"
    ],
    "Uses": "Strategic game playing, complex scientific discovery, multi-agent coordination, creative writing, advanced logical puzzles."
  },
  {
    "Pattern Name": "Self-Correction/Verification for LLMs",
    "Problem": "LLMs are prone to hallucinations, logical inconsistencies, and errors in their reasoning steps or generated outputs, especially in complex or high-stakes scenarios where accuracy is critical.",
    "Context": "Critical applications requiring high factual accuracy, faithfulness, or logical soundness (e.g., legal, medical, scientific); complex reasoning tasks where intermediate steps can go wrong.",
    "Solution": "Implement mechanisms for the LLM itself, or an auxiliary component, to evaluate, validate, or self-correct its own generated reasoning steps or final answers. This can involve generating multiple solutions and checking for consistency, using a separate 'verifier' model, or prompting the LLM to explicitly check its own work based on provided criteria or external knowledge.",
    "Result": "Improves the reliability, faithfulness, and accuracy of LLM outputs; enhances trustworthiness in critical applications by reducing errors and inconsistencies.",
    "Related Patterns": [
      "Chain-of-Thought (CoT) Reasoning",
      "Monte-Carlo Planning for Faithful Reasoning"
    ],
    "Uses": "Fact-checking, mathematical problem-solving, code generation, legal/medical reasoning, content moderation."
  },
  {
    "Pattern Name": "Monte-Carlo Planning for Faithful Reasoning",
    "Problem": "Ensuring the faithfulness and correctness of reasoning steps generated by LLMs, particularly in open-ended or complex tasks where direct, deterministic verification is challenging.",
    "Context": "LLM-driven reasoning requiring high confidence, exploration of multiple reasoning trajectories, and validation against a ground truth or logical constraints to minimize hallucinations.",
    "Solution": "Apply Monte-Carlo planning techniques (e.g., Monte-Carlo Tree Search) to explore and evaluate different reasoning paths. The LLM generates potential reasoning steps, and the planning algorithm guides the search, evaluates outcomes, and prunes unpromising paths to converge on a faithful reasoning sequence. This often involves simulating reasoning outcomes or using a scoring mechanism.",
    "Result": "Improves the faithfulness and reliability of LLM-generated reasoning, provides a systematic way to explore and validate reasoning steps, and significantly reduces the likelihood of hallucinations in complex reasoning tasks.",
    "Related Patterns": [
      "Advanced Reasoning Structures (Tree/Graph of Thoughts)",
      "Self-Correction/Verification for LLMs",
      "Plan-and-Solve Reasoning"
    ],
    "Uses": "Complex logical reasoning, strategic planning, decision-making in uncertain environments, ensuring factuality in generated explanations, game AI."
  }
]