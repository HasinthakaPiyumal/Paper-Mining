[
  {
    "Pattern Name": "Retrieval-Augmented Generation for Blackbox LLMs",
    "Problem": "Large Language Models (LLMs) tend to hallucinate and lack access to up-to-date, domain-specific, or proprietary external knowledge, especially when used as blackbox models where fine-tuning is infeasible or too costly.",
    "Context": "Blackbox LLMs (e.g., ChatGPT) are deployed in mission-critical applications that require factual accuracy and grounding in specific external information (e.g., latest news, task-specific databases, customer reviews).",
    "Solution": "Augment the blackbox LLM with a 'Knowledge Consolidator' module. This module comprises a knowledge retriever, an entity linker, and an evidence chainer. It generates search queries, retrieves raw evidence from various external knowledge sources (web, databases), enriches it with related context, prunes irrelevant information, and forms concise evidence chains. This consolidated evidence is then injected into the LLM's prompt.",
    "Result": "The LLM generates responses that are factually grounded in external knowledge, significantly reducing hallucinations and improving informativeness without requiring expensive fine-tuning of the LLM itself.",
    "Related Patterns": [
      "Self-Correction with Automated Feedback",
      "Adaptive LLM Orchestration"
    ],
    "Uses": "Open-domain Question Answering, Information-Seeking Dialog, Customer Service, any application requiring LLMs to use external, dynamic, or private knowledge."
  },
  {
    "Pattern Name": "Self-Correction with Automated Feedback",
    "Problem": "Large Language Models (LLMs) can generate responses that do not meet desired quality criteria (e.g., factuality, coherence, alignment with user expectations or business rules) in a single pass.",
    "Context": "Blackbox LLMs are used for tasks where high-quality, verifiable, and aligned responses are crucial, and direct programmatic control over LLM generation is limited.",
    "Solution": "Implement a 'Utility' module that evaluates candidate LLM-generated responses using task-specific utility functions (model-based or rule-based) to produce a utility score and verbalized feedback. This feedback is then used by a 'Prompt Engine' to revise the original prompt, querying the LLM again for an improved response. This process iterates until a candidate response meets the verification criteria.",
    "Result": "LLM responses are iteratively refined and improved in terms of alignment with specific quality metrics (e.g., groundedness, factuality, informativeness), making them more suitable for mission-critical applications.",
    "Related Patterns": [
      "Retrieval-Augmented Generation for Blackbox LLMs",
      "Adaptive LLM Orchestration"
    ],
    "Uses": "Information-Seeking Dialog, Customer Service, Question Answering, content generation requiring specific quality checks, scenarios where LLM output needs to conform to strict rules or factual constraints."
  },
  {
    "Pattern Name": "Adaptive LLM Orchestration",
    "Problem": "Effectively managing the interactions between a blackbox LLM, external knowledge sources, and feedback mechanisms to achieve complex, multi-step goals in a dynamic environment. Deciding when to perform which action (e.g., retrieve knowledge, query LLM, apply feedback, respond to user) is non-trivial.",
    "Context": "Building agentic AI systems around blackbox LLMs that need to perform complex tasks, often involving multiple turns of interaction and external tool use, while optimizing for a long-term reward.",
    "Solution": "Design a 'Policy' module that, based on the current dialog state stored in 'Working Memory,' selects the optimal next system action. This policy can be rule-based (for initial bootstrapping) or trainable (e.g., using Reinforcement Learning with a neural network model like T5). Actions include acquiring evidence via the Knowledge Consolidator, calling the Prompt Engine to generate a candidate response from the LLM, or sending a verified response to the user.",
    "Result": "The LLM-augmented system gains the ability to make intelligent, adaptive decisions about its operational flow, optimizing for desired outcomes (e.g., maximizing response quality, minimizing hallucination) and efficiently utilizing its various augmentation modules.",
    "Related Patterns": [
      "Retrieval-Augmented Generation for Blackbox LLMs",
      "Self-Correction with Automated Feedback"
    ],
    "Uses": "Task-oriented Dialog Systems, Autonomous Agents, Complex Question Answering, any multi-turn AI system where dynamic decision-making for LLM and tool interaction is required."
  }
]