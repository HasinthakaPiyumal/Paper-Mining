[
  {
    "Pattern Name": "Retrieval-Augmented Generation (RAG)",
    "Problem": "Large Language Models (LLMs) have limited parametric knowledge, struggle to access up-to-date or domain-specific information, and can hallucinate. Modifying model weights for new knowledge is computationally expensive and difficult.",
    "Context": "Building LLM applications that require access to dynamic, external, or specialized knowledge beyond what the base model was trained on.",
    "Solution": "A pipeline where a retriever first fetches relevant external contexts (documents, passages) for a given user query. These retrieved contexts are then provided to the LLM along with the query, enabling the LLM to generate an answer grounded in the external information.",
    "Result": "LLMs can handle long-tail knowledge, provide up-to-date information, adapt to specific domains/tasks without costly retraining, and reduce factual errors or hallucinations by grounding responses in retrieved evidence.",
    "Related Patterns": [
      "Retrieve-Rerank-Generate Pipeline",
      "Unified Instruction Tuning for RAG and Ranking"
    ],
    "Uses": "Knowledge-intensive NLP tasks, open-domain question answering, chatbots, information retrieval, domain adaptation for LLMs."
  },
  {
    "Pattern Name": "Retrieve-Rerank-Generate Pipeline",
    "Problem": "In standard RAG, the initial retriever may return a large number of contexts, some of which are irrelevant or noisy. Providing too many contexts to the LLM can degrade generation accuracy and efficiency, even with long context windows, due to the LLM's limited capacity to effectively process and prioritize a large volume of information. Relying solely on a retrieval model might be inadequate for high recall.",
    "Context": "Retrieval-Augmented Generation systems where the initial retrieval step often yields a superset of relevant and irrelevant information, and the LLM performs better with a smaller, highly relevant set of contexts.",
    "Solution": "Extend the standard RAG pipeline by adding an intermediate reranking step. First, a retriever fetches a broad set of 'N' candidate contexts. Second, a dedicated reranker (or a reranking-capable LLM) evaluates the relevance of these 'N' contexts to the query and selects a refined, smaller set of 'k' (where 'k < N') most relevant contexts. Finally, the LLM generates the answer using only these 'k' highly relevant, reranked contexts.",
    "Result": "Significantly improves the quality and relevance of the contexts provided to the LLM, leading to higher accuracy and robustness in the generated answers. Mitigates the 'lost in the middle' or 'too much noise' problem for LLMs and optimizes the use of context window.",
    "Related Patterns": [
      "Retrieval-Augmented Generation (RAG)",
      "Unified Instruction Tuning for RAG and Ranking"
    ],
    "Uses": "High-stakes knowledge-intensive QA, complex information retrieval, improving the robustness and accuracy of RAG systems, scenarios where initial retrieval is noisy."
  },
  {
    "Pattern Name": "Unified Instruction Tuning for RAG and Ranking (RankRAG Framework)",
    "Problem": "Traditional instruction tuning for RAG often focuses only on generation from given contexts, which can be suboptimal with poor initial retrieval. Separate expert ranking models lack the zero-shot generalization capabilities of versatile LLMs and require dedicated training. The goal is to create a single LLM capable of both effectively ranking contexts and generating high-quality answers, overcoming the limitations of separate models and improving robustness to irrelevant context.",
    "Context": "Developing more capable and robust LLMs for Retrieval-Augmented Generation, aiming to integrate context selection (ranking) and answer generation capabilities into a single model.",
    "Solution": "Instruction-tune a single LLM using a specialized, multi-stage training blend that explicitly teaches both context ranking and answer generation. This involves: 1. An initial Supervised Fine-Tuning (SFT) stage on diverse instruction-following datasets to imbue basic capabilities. 2. A second instruction tuning stage using a blend of: general instruction-following data, context-rich QA data (to enhance context utilization), retrieval-augmented QA data (including hard negatives for robustness), context ranking data (training the LLM to identify relevant/irrelevant passages), and retrieval-augmented ranking data (training the LLM to identify relevant passages from a set of multiple retrieved passages). A key aspect is unifying all these diverse tasks into a standardized (question, context, target_output) format during instruction tuning to maximize knowledge transfer and mutual enhancement between ranking and generation capabilities.",
    "Result": "Produces a single, data-efficient LLM that excels at both context ranking and answer generation within the RAG framework. This LLM outperforms specialized ranking models and improves robustness to irrelevant contexts, demonstrating strong generalization capabilities to new domains. It simplifies the RAG pipeline by using one model for two critical functions.",
    "Related Patterns": [
      "Retrieval-Augmented Generation (RAG)",
      "Retrieve-Rerank-Generate Pipeline"
    ],
    "Uses": "Training foundation models for advanced RAG applications, enhancing LLM robustness to noisy retrieval, building efficient RAG systems with a unified model."
  }
]