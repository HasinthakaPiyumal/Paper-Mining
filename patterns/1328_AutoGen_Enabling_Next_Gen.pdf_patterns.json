[
  {
    "Pattern Name": "Agent Customization",
    "Problem": "How to design individual agents that are capable, reusable, and effective in multi-agent collaboration, and exhibit complex behavior tailored to specific application needs.",
    "Context": "Building LLM applications where agents need specialized capabilities and roles, potentially leveraging LLMs, human inputs, or tools, and where modularity and reusability are important.",
    "Solution": "Configure agents with a mix of basic backend types (LLMs, humans, tools). Reuse or extend built-in agents (e.g., `ConversableAgent`, `AssistantAgent`, `UserProxyAgent`) to create agents with specialized capabilities and roles. This involves setting parameters like `human_input_mode`, `termination_condition`, `code_execution_config`, and `llm_config`.",
    "Result": "Easy creation of agents with specialized capabilities and roles. Agents can exhibit complex behavior in multi-agent conversations. Maximizes reusability of implemented agents.",
    "Related Patterns": [
      "Agentic AI Patterns",
      "Tools Integration Patterns",
      "AI-Human Interaction Patterns",
      "LLM-specific Patterns"
    ],
    "Uses": [
      "Math Problem Solving (A1)",
      "Retrieval-augmented QA (A2)",
      "Decision Making in Embodied Agents (A3)",
      "Supply Chain Optimization (A4)",
      "Conversational Chess (A6)",
      "Online Decision Making in Web Interaction Tasks (A7)"
    ]
  },
  {
    "Pattern Name": "Automated Agent Chat",
    "Problem": "How to enable agents to automatically exchange messages and progress a conversation without explicit, centralized control, and to allow for custom agent behaviors.",
    "Context": "Multi-agent conversation frameworks where agents need to interact autonomously and flexibly, leveraging the conversational capabilities of LLMs.",
    "Solution": "Provide unified conversation interfaces (`send/receive`, `generate_reply`, `register_reply`) and an agent autoreply mechanism. Agents automatically invoke `generate_reply` and send a reply unless a termination condition is met. Built-in reply functions (LLM inference, code/function execution, human input) are provided, and custom reply functions can be registered via `register_reply` to define specific behavior patterns.",
    "Result": "Conversation flow is naturally induced and proceeds automatically. Decentralized, modular, and unified workflow definition. Enables diverse conversation patterns.",
    "Related Patterns": [
      "Agentic AI Patterns",
      "LLM-specific Patterns",
      "Composable Conversation Patterns"
    ],
    "Uses": [
      "General infrastructure for AutoGen applications",
      "All general agent interactions within AutoGen (Figure 2)"
    ]
  },
  {
    "Pattern Name": "Hybrid Control",
    "Problem": "How to manage and control the flow of multi-agent conversations effectively, allowing for both intuitive, high-level guidance and precise, programmatic specification.",
    "Context": "Developing complex LLM applications where conversation flow needs to be managed with varying degrees of flexibility and precision, and where both human-like guidance and deterministic logic are required.",
    "Solution": "Allow control over conversation flow using a fusion of natural language (prompting LLM-backed agents) and programming language (Python code for specifying termination conditions, human input modes, tool execution logic, and custom autoreply functions). Support dynamic transitions between these control modes.",
    "Result": "Flexible control flow management. Enables both high-level, human-readable guidance and detailed, programmatic control. Reduces development effort for complex workflows.",
    "Related Patterns": [
      "Agentic AI Patterns",
      "Prompt Design Patterns",
      "Tools Integration Patterns",
      "LLM-specific Patterns",
      "AI-Human Interaction Patterns"
    ],
    "Uses": [
      "AssistantAgent's default system message (natural language control, Figure 5)",
      "Configuring `human_input_mode` or `max_auto_replies` (programming language control)",
      "LLM-proposed function calls"
    ]
  },
  {
    "Pattern Name": "Composable Conversation Patterns",
    "Problem": "How to design and implement diverse and flexible multi-agent conversation workflows, from simple fixed interactions to complex, dynamic collaborations.",
    "Context": "Building multi-agent LLM applications that require various interaction structures depending on the task's complexity, the number of agents, and whether the flow is static or dynamic.",
    "Solution": "Provide high-level interfaces for common patterns (two-agent chat, sequential chats, nested chat, group chat). Allow these patterns to be composed recursively (e.g., nested chat with group chat) and extended via low-level interfaces (e.g., `register_reply`) or dynamic mechanisms (custom reply functions, LLM-driven function calls).",
    "Result": "Supports diverse conversation patterns (static and dynamic). Enables creation of complex, creative workflows (e.g., inner monologue). Enhances usability for common patterns.",
    "Related Patterns": [
      "Agentic AI Patterns",
      "Planning Patterns",
      "LLM-specific Patterns",
      "Automated Agent Chat"
    ],
    "Uses": [
      "Two-agent chat (A1, A2, A3, A7)",
      "Sequential chats (Listing 5)",
      "Nested chat (Listing 3 for self-reflection)",
      "Group chat (A4, A5, A6)"
    ]
  },
  {
    "Pattern Name": "Grounding Agent",
    "Problem": "LLM-based agents may lack basic commonsense knowledge, hallucinate, or get stuck in repetitive error loops, especially in interactive decision-making tasks in dynamic environments, leading to task failures.",
    "Context": "Multi-agent systems where an agent's decisions require specific, often commonsense, knowledge about the environment or task rules, and where errors can lead to persistent failures or invalid actions.",
    "Solution": "Introduce a specialized 'grounding agent' that provides crucial commonsense knowledge, factual information, or corrective feedback to the decision-making agents. This agent is triggered when specific conditions are met (e.g., early signs of recurring errors, repeated actions, invalid moves).",
    "Result": "Enhances the system's ability to avoid error loops, mitigates persistence with flawed plans, improves task success rate, and ensures adherence to rules/facts.",
    "Related Patterns": [
      "Agentic AI Patterns",
      "Knowledge & Reasoning Patterns",
      "LLM-specific Patterns"
    ],
    "Uses": [
      "Decision Making in Embodied Agents (A3, for commonsense knowledge)",
      "Conversational Chess (A6, board agent for rule validation)"
    ]
  },
  {
    "Pattern Name": "Safeguard Agent",
    "Problem": "Ensuring the safety, security, and reliability of code or actions generated by LLM agents, especially when interacting with external tools or sensitive systems (e.g., preventing malicious code, information leakage, or unsafe operations).",
    "Context": "Multi-agent systems where LLM agents generate code or make decisions that could have security implications, require adherence to specific safety protocols, or involve critical operations.",
    "Solution": "Introduce a specialized 'safeguard agent' responsible for reviewing and verifying the safety, security, and correctness of outputs (e.g., code) from other agents before execution or deployment. This agent can act in an adversarial manner to scrutinize proposed solutions.",
    "Result": "Boosts performance in identifying unsafe code, reduces risks, and ensures adherence to safety guidelines. Enhances reliability and trustworthiness of the system. Improves user experience by preventing errors.",
    "Related Patterns": [
      "Agentic AI Patterns",
      "MLOps Patterns",
      "LLM-specific Patterns",
      "Tools Integration Patterns"
    ],
    "Uses": [
      "Supply Chain Optimization (A4, checking code safety)"
    ]
  },
  {
    "Pattern Name": "Role Play Prompting",
    "Problem": "How to guide an LLM agent to adopt a specific persona, mindset, or behavior within a multi-agent conversation, influencing its responses, reasoning, and actions to align with a desired role.",
    "Context": "Designing LLM-backed agents that need to fulfill distinct roles (e.g., assistant, critic, engineer) or exhibit specific conversational styles or reasoning processes in a collaborative environment.",
    "Solution": "Incorporate explicit role-playing instructions into the agent's system message or initial prompt, clearly defining its persona, responsibilities, and expected behavior.",
    "Result": "Agent adopts the specified role, leading to more aligned, focused, and effective contributions to the multi-agent conversation. Can be used for dynamic speaker selection and fostering specific interaction dynamics.",
    "Related Patterns": [
      "Prompt Design Patterns",
      "Generative AI Patterns",
      "Agentic AI Patterns"
    ],
    "Uses": [
      "AssistantAgent's default system message (Figure 5: 'You are a helpful AI assistant')",
      "Dynamic Task Solving with Group Chat (A5, for speaker selection)",
      "CAMEL (related work, uses 'Inception prompting')"
    ]
  },
  {
    "Pattern Name": "Control Flow Prompting",
    "Problem": "How to use natural language instructions within prompts to influence the sequence of operations, decision-making logic, or overall flow of an LLM agent's behavior in a multi-agent system.",
    "Context": "LLM agents need to follow specific steps, conditions, or iterative processes in their problem-solving, and developers prefer natural language for high-level guidance.",
    "Solution": "Embed instructions related to the conversation flow, step-by-step reasoning, planning, or conditional actions directly into the LLM's system message or prompt.",
    "Result": "LLM agents follow the intended control flow, performing tasks in a structured manner, suggesting code, explaining plans, or debugging when needed.",
    "Related Patterns": [
      "Prompt Design Patterns",
      "Planning Patterns",
      "Agentic AI Patterns"
    ],
    "Uses": [
      "AssistantAgent's default system message (Figure 5: 'Solve the task step by step if you need to. If a plan is not provided explain your plan first. Be clear which step uses code and which step uses your language skill. If the result indicates there is an error fix the error and output the code again')"
    ]
  },
  {
    "Pattern Name": "Output Confinement Prompting",
    "Problem": "How to constrain the output format or content of an LLM agent to make it easily consumable by other agents or external tools, and to improve system robustness and parsing reliability.",
    "Context": "Multi-agent systems where agents exchange messages that need to adhere to specific structural or content requirements for successful automated processing by other agents, tools, or parsers.",
    "Solution": "Include explicit instructions in the LLM's prompt to confine its output to a particular format (e.g., Python coding block, shell script block, specific keywords, single code block per response, `TERMINATE` signal).",
    "Result": "LLM outputs are structured and predictable, making it easier for other agents or tools to parse and act upon them. Reduces parsing errors and improves inter-agent communication and system stability.",
    "Related Patterns": [
      "Prompt Design Patterns",
      "LLM-specific Patterns",
      "Tools Integration Patterns"
    ],
    "Uses": [
      "AssistantAgent's default system message (Figure 5: 'suggest python code in a python coding block or shell script in a sh coding block', 'Do not include multiple code blocks in one response', 'Reply TERMINATE in the end when everything is done')"
    ]
  },
  {
    "Pattern Name": "Facilitate Automation Prompting",
    "Problem": "How to design prompts that encourage LLM agents to produce outputs that directly enable or streamline automated processes, such as code execution or tool invocation, without manual intervention.",
    "Context": "LLM agents are expected to interact with tools or execute code generated by themselves or other agents, and the system needs to automate these interactions efficiently.",
    "Solution": "Instruct the LLM agent to suggest executable code or function calls in a specific, parseable format, and to use `print` statements for output capture, rather than asking for manual copy-pasting or complex parsing.",
    "Result": "Streamlines the automation of code execution and tool usage, reducing manual intervention and improving the efficiency of multi-agent workflows. Enhances the seamless integration of LLMs with external systems.",
    "Related Patterns": [
      "Prompt Design Patterns",
      "Tools Integration Patterns",
      "Automated Agent Chat",
      "LLM-specific Patterns"
    ],
    "Uses": [
      "AssistantAgent's default system message (Figure 5: 'When using code you must indicate the script type in the code block', 'The user cannot provide any other feedback or perform any other action beyond executing the code you suggest. The user cant modify your code. So do not suggest incomplete code which requires users to modify', 'Instead use print function for the output when relevant')"
    ]
  },
  {
    "Pattern Name": "Grounding Prompting",
    "Problem": "How to ensure that an LLM agent's responses and actions are factually accurate, aligned with external data, or adhere to specific domain rules, thereby preventing hallucinations or invalid outputs.",
    "Context": "LLM agents operate in environments where factual accuracy, compliance with rules, or leveraging external knowledge is critical for task success and trustworthiness.",
    "Solution": "Provide instructions in the prompt that guide the LLM to verify answers, include verifiable evidence, or adhere to domain-specific rules. This can complement or be supported by a 'Grounding Agent' that actively injects relevant knowledge.",
    "Result": "Improves factuality, reduces hallucinations, and ensures compliance with rules or external information. Builds trust in the agent's outputs.",
    "Related Patterns": [
      "Prompt Design Patterns",
      "Knowledge & Reasoning Patterns",
      "LLM-specific Patterns",
      "Grounding Agent"
    ],
    "Uses": [
      "AssistantAgent's default system message (Figure 5: 'When you find an answer verify the answer carefully. Include verifiable evidence in your response if possible')"
    ]
  }
]