[
  {
    "Pattern Name": "Distinguish Business Logic from ML Models",
    "Problem": "ML application systems are complex because their ML components must be retrained regularly and have an intrinsic nondeterministic behavior. Business requirements and ML algorithms change over time, making isolation difficult.",
    "Context": "ML application systems where business logic and ML models need independent evolution, management, and debugging.",
    "Solution": "Isolate the business logic from the ML models by defining clear APIs between traditional and ML components. Place business and ML components with different responsibilities into distinct layers and separate their dataflows.",
    "Result": "Enables easier debugging, independent monitoring, and adjustment of ML components to meet user requirements and changing inputs without impacting the core business logic.",
    "Related Patterns": [
      "ClosedLoop Intelligence",
      "DataAlgorithm Serving Evaluator"
    ],
    "Uses": "Any ML application system with outputs that depend on ML techniques, such as Chatbot systems."
  },
  {
    "Pattern Name": "DataAlgorithm Serving Evaluator",
    "Problem": "Prediction systems need to connect various data processing pipeline pieces into one coherent system, and prototyping predictive models can be challenging.",
    "Context": "Designing and prototyping prediction systems with machine learning capabilities.",
    "Solution": "Separate data (data source and data preparator), algorithms (serving), and evaluator components, applying an MVC-like pattern specifically for ML.",
    "Result": "Creates a coherent and structured system for building and prototyping predictive models, improving overall system design and manageability.",
    "Related Patterns": [
      "ClosedLoop Intelligence",
      "Distinguish Business Logic from ML Models"
    ],
    "Uses": "Prediction systems, systems for prototyping predictive models."
  },
  {
    "Pattern Name": "Event-driven ML Microservices",
    "Problem": "Frequent prototyping of ML models and constant changes necessitate agile development teams to build, deploy, and maintain complex data pipelines efficiently.",
    "Context": "Development teams managing complex ML data pipelines that require high agility and responsiveness to changes.",
    "Solution": "Construct ML data pipelines by chaining together multiple microservices, where each microservice listens for data arrival and performs its designated task.",
    "Result": "Enhances agility in building, deploying, and maintaining complex ML data pipelines, adapting to frequent changes and prototyping needs.",
    "Related Patterns": [
      "Daisy Architecture"
    ],
    "Uses": "Complex ML data pipelines, applications requiring agile development for ML model prototyping and deployment."
  },
  {
    "Pattern Name": "ParameterServer Abstraction",
    "Problem": "Widely accepted abstractions are lacking for implementing distributed machine learning.",
    "Context": "Developing and deploying distributed learning systems.",
    "Solution": "Distribute both data and workloads over worker nodes, while central server nodes maintain globally shared parameters, typically represented as vectors and matrices.",
    "Result": "Provides a structured and scalable approach for distributed machine learning training, enabling efficient parameter management across nodes.",
    "Related Patterns": [],
    "Uses": "Distributed machine learning, large-scale model training."
  },
  {
    "Pattern Name": "Daisy Architecture",
    "Problem": "Acquiring the ability to scale content production processes via ML and extending the coverage of ML tooling to a broader range of content.",
    "Context": "Organizations aiming to scale ML-driven content production and improve the efficiency of ML tooling across their content.",
    "Solution": "Utilize Kanban scaling and microservices to implement pull-based, automated, on-demand, and iterative processes for ML-driven content production.",
    "Result": "Enables scalable, automated, and iterative ML-driven content production processes.",
    "Related Patterns": [
      "Event-driven ML Microservices"
    ],
    "Uses": "ML-driven content production processes, systems requiring scalable and automated content generation."
  },
  {
    "Pattern Name": "ClosedLoop Intelligence",
    "Problem": "Addressing big, open-ended, time-changing, or intrinsically hard problems with machine learning.",
    "Context": "ML systems dealing with complex, dynamic problems where continuous feedback and interaction are crucial for improvement.",
    "Solution": "Connect machine learning directly to the user, closing the feedback loop by designing clear interactions along with implicit and direct outputs.",
    "Result": "Improves the system's ability to address complex, evolving problems by incorporating continuous user feedback and interaction into the learning process.",
    "Related Patterns": [
      "Distinguish Business Logic from ML Models",
      "DataAlgorithm Serving Evaluator"
    ],
    "Uses": "Systems addressing big, open-ended, time-changing, or intrinsically hard problems where human-in-the-loop or continuous learning from interaction is beneficial."
  },
  {
    "Pattern Name": "Federated Learning",
    "Problem": "Standard machine learning approaches require centralizing training data on one machine or in a datacenter, which can lead to privacy concerns and logistical challenges.",
    "Context": "Scenarios where data privacy, decentralization, or on-device learning is paramount, such as with mobile devices.",
    "Solution": "Employ Federated Learning, which enables mobile phones or other edge devices to collaboratively learn a shared prediction model while keeping all the training data on the device.",
    "Result": "Facilitates privacy-preserving, decentralized machine learning by allowing models to be trained on local data without centralizing sensitive user information.",
    "Related Patterns": [
      "Secure Aggregation"
    ],
    "Uses": "Mobile applications, privacy-sensitive ML scenarios, edge computing."
  },
  {
    "Pattern Name": "ML Versioning",
    "Problem": "ML models and their several versions may change the behavior of the overall ML applications, and ensuring reproducibility of training processes is difficult.",
    "Context": "Managing the lifecycle and evolution of ML models within an application, where reproducibility is critical.",
    "Solution": "Record the ML model structure, the specific training data used, and details of the training system to ensure a reproducible training process.",
    "Result": "Ensures reproducible ML training processes and provides better management and traceability of model evolution and behavior changes.",
    "Related Patterns": [
      "Decouple Training Pipeline from Production Pipeline"
    ],
    "Uses": "Any ML application where reproducibility, model lifecycle management, and auditing are critical."
  },
  {
    "Pattern Name": "Test Infrastructure Independently from ML",
    "Problem": "It is difficult to identify errors when infrastructure components and machine learning components are mixed within the testing process.",
    "Context": "Testing ML application systems where separating infrastructure concerns from ML-specific logic is beneficial for debugging and validation.",
    "Solution": "Ensure that the infrastructure is testable independently and that the learning parts of the system are encapsulated, allowing everything around them to be tested separately.",
    "Result": "Enables easier error identification and more effective, targeted testing of both the underlying infrastructure and the ML components.",
    "Related Patterns": [],
    "Uses": "Testing ML application systems, MLOps quality assurance."
  },
  {
    "Pattern Name": "Handshake / Hand Buzzer",
    "Problem": "An ML system often depends on inputs delivered outside of its normal release process, leading to potential instability or unexpected behavior due to external data changes.",
    "Context": "ML systems that rely on external, potentially dynamic, or unstable data feeds.",
    "Solution": "Create a handshake normalization process that regularly checks for significant changes in the external inputs and sends alerts when such changes are detected.",
    "Result": "Improves the robustness and reliability of ML systems by proactively managing and signaling changes in external data dependencies.",
    "Related Patterns": [],
    "Uses": "ML systems relying on external data feeds, real-time ML systems."
  },
  {
    "Pattern Name": "Isolate and Validate Output of Model",
    "Problem": "Machine learning models are known to be unstable, vulnerable to adversarial attacks, noise in data, and data drift over time.",
    "Context": "Deploying ML models in production environments where robustness, security, and reliability are critical.",
    "Solution": "Encapsulate ML models within rule-based safeguards and use redundant and diverse architectures to mitigate and absorb the inherent low robustness of ML models.",
    "Result": "Enhances the robustness, security, and reliability of deployed ML models against various vulnerabilities, including attacks, noise, and data drift.",
    "Related Patterns": [
      "Canary Model"
    ],
    "Uses": "Critical ML applications, models deployed in dynamic or adversarial environments, systems requiring high model integrity."
  },
  {
    "Pattern Name": "Canary Model",
    "Problem": "A surrogate ML model that approximates the behavior of the best ML model must be built to provide explainability or monitor subtle changes in prediction behavior.",
    "Context": "Deploying new or monitoring existing ML models, especially for A/B testing, understanding behavior, or ensuring safe deployment.",
    "Solution": "Run a canary (surrogate) inference pipeline in parallel with the primary inference pipeline to continuously monitor and compare prediction differences.",
    "Result": "Provides a mechanism for monitoring prediction differences, aiding in model explainability, detecting regressions, and enabling safer deployment strategies.",
    "Related Patterns": [
      "Isolate and Validate Output of Model"
    ],
    "Uses": "Model monitoring, A/B testing for ML models, explainable AI, safe model deployment."
  },
  {
    "Pattern Name": "Decouple Training Pipeline from Production Pipeline",
    "Problem": "It is necessary to separate and quickly change the ML data workload while stabilizing the training workload to maximize efficiency.",
    "Context": "Managing distinct ML training and production (serving) environments, each with different operational requirements and change frequencies.",
    "Solution": "Physically isolate training and production workloads on different machines, and then optimize their machine configurations and network usage independently.",
    "Result": "Maximizes efficiency and allows independent evolution and optimization of ML training and production processes, preventing conflicts and improving stability.",
    "Related Patterns": [
      "ML Versioning"
    ],
    "Uses": "ML systems requiring distinct and optimized training and serving environments, MLOps infrastructure design."
  },
  {
    "Pattern Name": "Descriptive Data Type for Rich Information",
    "Problem": "The rich semantic information used and produced by ML systems (e.g., model parameters, predictions) is often lost when encoded with plain data types like raw floats and integers.",
    "Context": "ML systems where the semantic meaning of data is crucial for robustness, interpretation, debugging, or ensuring correct usage.",
    "Solution": "Design a robust system where model parameters (e.g., a log-odds multiplier or a decision threshold) and predictions carry explicit semantic information about their nature and context.",
    "Result": "Creates a more robust and understandable system by preserving and leveraging rich semantic information directly within ML data types, improving interpretability and reducing errors.",
    "Related Patterns": [],
    "Uses": "ML systems requiring high robustness, clear interpretation of model parameters/predictions, advanced debugging, or data lineage."
  },
  {
    "Pattern Name": "Design Holistically about Data Collection and Feature Extraction",
    "Problem": "The system to prepare data in an ML-friendly format can easily become a 'pipeline jungle,' making management difficult and costly.",
    "Context": "Designing and managing data pipelines for machine learning, especially for data collection and feature engineering.",
    "Solution": "Avoid complex, unmanageable 'pipeline jungles' by thinking holistically about the entire process of data collection and feature extraction from the outset.",
    "Result": "Dramatically reduces ongoing costs and complexity by preventing the proliferation of unruly data pipelines for ML data preparation.",
    "Related Patterns": [],
    "Uses": "Designing and managing ML data pipelines, MLOps data engineering."
  },
  {
    "Pattern Name": "Reuse Code between Training Pipeline and Serving Pipeline",
    "Problem": "Training/serving skew can be caused by a discrepancy in how data is handled between the training and serving pipelines.",
    "Context": "ML systems where consistency in data processing between training and serving environments is critical to avoid performance degradation.",
    "Solution": "Reuse code for data processing steps between the training and serving pipelines, preparing objects that store results in an understandable way for humans.",
    "Result": "Mitigates training/serving skew, leading to more reliable and consistent model performance in production by ensuring identical data transformations.",
    "Related Patterns": [],
    "Uses": "ML systems susceptible to training/serving skew, MLOps for consistent data processing."
  },
  {
    "Pattern Name": "Secure Aggregation",
    "Problem": "The system needs to communicate and aggregate model updates in a secure, efficient, scalable, and fault-tolerant way, particularly in distributed learning settings.",
    "Context": "Federated Learning environments or other distributed ML scenarios where privacy of individual contributions to model updates must be maintained.",
    "Solution": "Encrypt data from each mobile device in Federated Learning and calculate totals and averages of model updates without individual examination of raw data.",
    "Result": "Ensures privacy and security of individual contributions during collaborative model training while maintaining efficiency and scalability.",
    "Related Patterns": [
      "Federated Learning"
    ],
    "Uses": "Federated Learning, privacy-preserving distributed ML, secure multi-party computation in AI."
  }
]