[
  {
    "Pattern Name": "LLM as a Planner",
    "Problem": "Complex user instructions or long-horizon tasks for AI systems are difficult to execute directly without a structured approach.",
    "Context": "Foundation models (LLMs) serving as the controller in agentic systems that need to interact with tools or environments.",
    "Solution": "Leverage the LLM's inherent reasoning and decision-making capabilities to decompose complex tasks into multiple subtasks and sequence them logically, forming an executable plan.",
    "Result": "Enables AI systems to tackle complex problems by breaking them down into manageable steps, leading to more coherent and effective task execution.",
    "Related Patterns": [
      "Introspective Reasoning",
      "Extrospective Reasoning",
      "Multi-Agent Collaboration",
      "Parallel Tool Execution"
    ],
    "Uses": "Robotics, multi-step Question Answering (QA), embodied learning, autonomous agents, general tool-learning systems."
  },
  {
    "Pattern Name": "Feedback Integration",
    "Problem": "AI systems need to adapt their behavior and plans based on the outcomes of their actions and external input from users or the environment.",
    "Context": "Interactive AI systems and agentic frameworks where actions produce observable effects and user input is dynamic.",
    "Solution": "Implement a 'perceiver' component that processes feedback from the user and the environment (e.g., execution results, state changes, human preferences) and summarizes it for the controller (foundation model). This feedback then informs subsequent decision-making and plan adjustments.",
    "Result": "Enables adaptive planning, error correction, and iterative refinement of actions, making the AI system more robust and responsive to dynamic conditions.",
    "Related Patterns": [
      "Extrospective Reasoning",
      "Reinforcement Learning from Human Feedback (RLHF) for Tool Learning",
      "Proactive AI Agent"
    ],
    "Uses": "Embodied agents, interactive Question Answering (QA), tool execution monitoring, conversational AI."
  },
  {
    "Pattern Name": "Tool Selection",
    "Problem": "Given a user's intent and a diverse set of available tools with specific functionalities, the AI system must accurately choose the most appropriate tool(s) for a given subtask.",
    "Context": "Foundation models interacting with a collection of specialized tools (APIs, software, etc.) in a tool-learning framework.",
    "Solution": "The controller (foundation model) infers the user's underlying intent and comprehends the functionalities of available tools. It then develops a plan to select the most suitable tool(s) for tackling each subtask. For large tool sets, an intermediate retrieval stage can pre-select a relevant subset of tools.",
    "Result": "Ensures efficient and effective utilization of specialized tools, bridging the gap between user intent and tool capabilities.",
    "Related Patterns": [
      "Prompt-based Tool Understanding",
      "LLM as a Planner"
    ],
    "Uses": "General tool-learning systems, multi-tool scenarios, API invocation."
  },
  {
    "Pattern Name": "Prompt-based Tool Understanding",
    "Problem": "Foundation models need to quickly comprehend the functionalities, usage, and parameters of various tools without requiring extensive re-training or large labeled datasets.",
    "Context": "Foundation models with strong few-shot and zero-shot learning capabilities interacting with diverse tools (e.g., APIs).",
    "Solution": "Construct suitable task-specific prompts (either manually designed or retrieved) that describe API functionalities, their input/output formats, and possible parameters (zero-shot prompting), or provide concrete tool-use demonstrations (few-shot prompting).",
    "Result": "Enables models to effectively unravel tool functionalities and comprehend how to use them proficiently with minimal human effort and high adaptability to tool changes.",
    "Related Patterns": [
      "Self-supervised Tool Learning",
      "Tool Selection"
    ],
    "Uses": "Integrating new APIs, adapting to modified tools, teaching models about tool capabilities."
  },
  {
    "Pattern Name": "Chain of Thought (CoT) Prompting",
    "Problem": "Foundation models often struggle with complex reasoning tasks, even when provided with few-shot examples, leading to suboptimal performance.",
    "Context": "Large language models (LLMs) used for problem-solving that require multi-step reasoning.",
    "Solution": "Augment few-shot prompts by additionally inserting the reasoning trace (the intermediate steps required to derive the final answer) for each example. This encourages the model to generate its own explicit thoughts and intermediate steps before arriving at the final answer.",
    "Result": "Significantly boosts performance on a wide range of complex reasoning tasks by eliciting more structured and transparent reasoning processes.",
    "Related Patterns": [
      "Introspective Reasoning",
      "Extrospective Reasoning"
    ],
    "Uses": "Arithmetic reasoning, commonsense reasoning, symbolic reasoning, complex problem-solving in LLMs."
  },
  {
    "Pattern Name": "Introspective Reasoning",
    "Problem": "Generating multi-step plans for complex tasks where immediate environmental feedback is either unavailable or costly during the initial planning phase, potentially leading to unrealistic plans.",
    "Context": "Foundation models acting as controllers in tool-learning frameworks, often in simulated or abstract environments.",
    "Solution": "The foundation model directly generates a static, multi-step plan for tool use based on its internal knowledge and reasoning capabilities. This can involve generating executable programs or anticipating possible anomalies in the plan execution without direct interaction with the environment.",
    "Result": "Enables upfront planning for complex tasks, suitable for scenarios where environmental interaction is delayed or for generating initial, high-level strategies. Helps in creating executable programs for agents.",
    "Related Patterns": [
      "LLM as a Planner",
      "Chain of Thought (CoT) Prompting"
    ],
    "Uses": "Program-Aided Language Models (PAL), embodied agents (ProgPrompt, Code-as-Policies), Visual ChatGPT, planning in physically grounded agents (SayCan)."
  },
  {
    "Pattern Name": "Extrospective Reasoning",
    "Problem": "Static plans generated by introspective reasoning cannot adapt to intermediate execution results or unexpected situations in dynamic environments, leading to failures.",
    "Context": "Interactive environments where an AI agent needs to generate plans incrementally and continuously adapt to real-time feedback from the user and environment.",
    "Solution": "The foundation model generates plans incrementally, typically one step at a time, with subsequent plans dynamically dependent on previous execution results and feedback. This establishes a closed-loop interaction among the controller, perceiver, environment, and user.",
    "Result": "More rational, robust, and adaptable planning, better suited for complex and dynamic tasks by enabling real-time adjustment to anomalies and intermediate outcomes.",
    "Related Patterns": [
      "Feedback Integration",
      "LLM as a Planner",
      "Chain of Thought (CoT) Prompting",
      "Conflict Resolution for Augmented Knowledge"
    ],
    "Uses": "Multi-step Question Answering (Self-Ask, ReAct, ToolFormer), embodied learning (Inner Monologue, LLMPlanner), autonomous agents, interactive problem-solving."
  },
  {
    "Pattern Name": "Formalism-Enhanced Reasoning",
    "Problem": "Relying solely on plain natural language for reasoning and planning can limit the performance of LLM-based agents in complex, logically demanding tasks.",
    "Context": "LLM-based agents operating in domains requiring high precision, structured knowledge, or complex procedural execution.",
    "Solution": "Incorporate external formalisms, such as mathematical tools, probabilistic graph models (PGMs), or integrate with structured automation frameworks like Robotic Process Automation (RPA), to represent and process information beyond natural text. This enhances the agent's reasoning capabilities.",
    "Result": "Significantly enhances agents' performance in complex reasoning tasks, improves decision-making capabilities, and maintains controllability by leveraging structured representations and external computational power.",
    "Related Patterns": [
      "Extrospective Reasoning",
      "Conflict Resolution for Augmented Knowledge"
    ],
    "Uses": "Multi-agent reasoning, agentic process automation (APA), scientific discovery, tasks requiring symbolic manipulation."
  },
  {
    "Pattern Name": "Parallel Tool Execution",
    "Problem": "Executing all subtasks sequentially can be inefficient, especially when certain subtasks are independent and do not rely on the output of others.",
    "Context": "Multi-step, multi-tool scenarios where a complex task can be decomposed into several independent subtasks.",
    "Solution": "The AI system analyzes task dependencies to identify subtasks that can be executed concurrently. These independent subtasks are then assigned for simultaneous execution, potentially by different agents or parallel processes.",
    "Result": "Improves overall execution efficiency and reduces the total time required to complete complex tasks by leveraging parallelism.",
    "Related Patterns": [
      "LLM as a Planner",
      "Multi-Agent Collaboration"
    ],
    "Uses": "Complex task decomposition, multi-agent systems, code generation for independent components."
  },
  {
    "Pattern Name": "Multi-Agent Collaboration",
    "Problem": "Complex tasks often demand a wider range of abilities and expertise than a single AI agent can possess, or require simulating human-like social interactions.",
    "Context": "Scenarios where a complex problem benefits from diverse perspectives, specialized skills, or distributed problem-solving.",
    "Solution": "Design a system where multiple AI agents, each potentially possessing unique abilities or specialized tools, collaborate to solve a task. This requires implementing mechanisms for communication, coordination, and negotiation among agents.",
    "Result": "Unlocks more effective and efficient problem-solving approaches for complex tasks, and can simulate realistic human behaviors in interactive scenarios.",
    "Related Patterns": [
      "LLM as a Planner",
      "Parallel Tool Execution"
    ],
    "Uses": "Interactive scenarios, complex task solving, simulating human behavior, distributed control systems."
  },
  {
    "Pattern Name": "Self-supervised Tool Learning",
    "Problem": "The traditional reliance on extensive human-annotated tool-use demonstrations for training models is time-consuming, labor-intensive, and limits scalability.",
    "Context": "Foundation models with strong in-context learning abilities, aiming to learn tool use with minimal human supervision.",
    "Solution": "Leverage the foundation model's in-context learning capabilities to iteratively bootstrap tool-use examples based on a small handful of human-written examples. These autogenerated examples are then filtered to reduce noise, creating a large, self-supervised dataset.",
    "Result": "Significantly reduces the dependency on extensive human annotation, improving tool-use performance and enabling models to enhance their capabilities in a scalable and efficient manner.",
    "Related Patterns": [
      "Prompt-based Tool Understanding"
    ],
    "Uses": "Bootstrapping tool-use datasets, enhancing tool-use capabilities with minimal supervision, few-shot tool integration."
  },
  {
    "Pattern Name": "Reinforcement Learning from Human Feedback (RLHF) for Tool Learning",
    "Problem": "Aligning AI agent behavior with nuanced human preferences and values in tool-use scenarios is challenging, especially when explicit reward signals are sparse or difficult to define programmatically.",
    "Context": "Training AI agents to perform tool-oriented tasks, where the goal is to achieve human-aligned outcomes and improve user experience.",
    "Solution": "Utilize human feedback (explicit ratings or implicit behaviors) to train a reward model that imitates human preferences. This reward model then guides reinforcement learning algorithms (e.g., PPO) to optimize the agent's policy for tool selection and action, aligning its behavior with desired human expectations.",
    "Result": "Improves tool-use capabilities, ensures agent behavior aligns with human preferences, and helps manipulate tools to achieve desired long-form or subjective outcomes.",
    "Related Patterns": [
      "Feedback Integration",
      "Extrospective Reasoning"
    ],
    "Uses": "Web search (WebGPT), conversational agents, general tool learning where human alignment and preferences are critical."
  },
  {
    "Pattern Name": "Unified Tool Interface",
    "Problem": "Models struggle to transfer learned tool-use knowledge and skills to new tools due to varying interfaces, communication protocols, and action spaces across different tools.",
    "Context": "AI systems interacting with a diverse and rapidly expanding array of tools (APIs, GUIs, physical devices).",
    "Solution": "Design and implement a standardized interface for tool interaction. This can be a semantic interface (natural language action triggers), a GUI interface (mapping predicted tokens to human-like mouse/keyboard actions), or a programming interface (code-based function calls with standardized syntax).",
    "Result": "Facilitates knowledge transfer and generalization among tools, enabling models to identify and abstract essential features more easily, and allows for quicker adaptation to new scenarios and tools.",
    "Related Patterns": [
      "Meta Tool Learning",
      "Curriculum Tool Learning"
    ],
    "Uses": "Robotics, web-based agents, code generation, general tool-learning systems."
  },
  {
    "Pattern Name": "Meta Tool Learning",
    "Problem": "AI models need to generalize tool-use knowledge to new tasks or domains efficiently, beyond merely memorizing specific tool applications, by understanding underlying principles.",
    "Context": "Developing adaptable and intelligent ML models that can effectively use new or unfamiliar tools.",
    "Solution": "Train the model not just to use a specific tool, but to learn the optimal strategy or common underlying principles/patterns in tool-use. This allows it to transfer these high-level strategies to new tasks or similar tools in different domains.",
    "Result": "Enables models to identify commonalities in tool-use strategies and adapt their behaviors when faced with unfamiliar situations, significantly improving generalization and adaptability to novel tools and tasks.",
    "Related Patterns": [
      "Unified Tool Interface"
    ],
    "Uses": "Transferring knowledge between similar tools (e.g., different search engines), applying a calculator for different types of mathematical problems, adapting to new software with similar functionalities."
  },
  {
    "Pattern Name": "Curriculum Tool Learning",
    "Problem": "Introducing models directly to complex tools or tasks from the outset can be overwhelming, hindering effective learning and generalization.",
    "Context": "Training models to use complex tools or perform intricate multi-step tasks.",
    "Solution": "Implement a pedagogical strategy that starts with simple tools or basic operations, gradually introducing the model to more complex tools and advanced concepts. This allows the model to build upon its prior knowledge and develop a deeper, more structured understanding of the tool's capabilities.",
    "Result": "Ensures a manageable and effective learning process, enabling the model to identify similarities and differences between situations, adjust its approach accordingly, and generalize across different tools and tasks more effectively.",
    "Related Patterns": [
      "Unified Tool Interface",
      "LLM as a Planner"
    ],
    "Uses": "Teaching models to use complex software (e.g., Mathematica from basic arithmetic to calculus), mastering progressively difficult tasks in robotics or simulation."
  },
  {
    "Pattern Name": "AI-Driven Tool Creation/Encapsulation",
    "Problem": "Existing tools are often designed for human use and may not be optimal for AI's information processing, or AI needs to adapt/extend tools for new, specialized purposes.",
    "Context": "Advancing AI capabilities from merely tool users to autonomous tool makers and enhancers.",
    "Solution": "Leverage large code models or foundation models to autonomously generate executable programs (new tools) based on natural language descriptions, or to encapsulate/extend existing APIs into more advanced, specialized functions tailored for specific tasks or AI-centric workflows.",
    "Result": "Creates tools that are better suited for AI's information processing, enables autonomous development of sophisticated solutions, and extends tool functionalities beyond their original design, promoting AI creativity and self-improvement.",
    "Related Patterns": [
      "Unified Tool Interface"
    ],
    "Uses": "Generating code for specific tasks, extending weather forecast APIs to compute average temperature, integrating stock market data for investment recommendations, creating automated medical diagnosis systems."
  },
  {
    "Pattern Name": "Personalized Tool Learning",
    "Problem": "Foundation models, typically trained on generic data, struggle to process personal information and provide tailored assistance, adapting tool manipulation to individual user needs and preferences.",
    "Context": "AI systems interacting with diverse users, requiring customized responses and tool usage based on individual profiles.",
    "Solution": "Develop methods to model heterogeneous user information (e.g., language style, historical interactions, social network data) into a unified semantic space. This information is then used to develop personalized tool execution plans and adapt tool calls based on specific user preferences, often leveraging user feedback.",
    "Result": "Provides more personalized and effective tool assistance, aligning tool manipulation with individual user preferences, leading to a better user experience.",
    "Related Patterns": [
      "Feedback Integration",
      "Proactive AI Agent"
    ],
    "Uses": "Personalized email tools, online shopping platforms, user-specific dialogue generation, tailored AI assistants."
  },
  {
    "Pattern Name": "Proactive AI Agent",
    "Problem": "Most foundation models operate as reactive systems, only responding to direct user queries, which limits their ability to anticipate user needs or initiate helpful actions autonomously.",
    "Context": "AI systems aiming for a more seamless, natural, and personalized user experience by anticipating needs and acting on behalf of the user.",
    "Solution": "Design AI agents that can initiate actions proactively, without explicit user prompts, by leveraging the history of user interactions and understanding potential future needs. This involves a paradigm shift from purely reactive to anticipatory behavior.",
    "Result": "Offers a more personalized and seamless user experience, but necessitates careful design with safety mechanisms and ethical considerations to prevent unintended consequences.",
    "Related Patterns": [
      "Personalized Tool Learning",
      "Feedback Integration"
    ],
    "Uses": "Intelligent assistants, automated task completion, personalized recommendations, smart home systems."
  },
  {
    "Pattern Name": "Conflict Resolution for Augmented Knowledge",
    "Problem": "When augmenting foundation models with external tools, knowledge conflicts inevitably arise between the model's internalized knowledge and the real-time augmented knowledge, or among different augmented knowledge sources (e.g., from multiple tools).",
    "Context": "Foundation models enhanced by various external knowledge sources (e.g., real-time APIs, curated databases, web search).",
    "Solution": "Develop mechanisms for conflict detection (identifying discrepancies between knowledge sources) and conflict resolution (verifying the reliability of sources, choosing the most trustworthy information, and providing explanations for the decisions made). Models should be guided to distinguish and verify reliability.",
    "Result": "Improves the accuracy, reliability, and explainability of model generation and planning, especially critical in domains requiring high factual correctness and trustworthiness.",
    "Related Patterns": [
      "Extrospective Reasoning",
      "Formalism-Enhanced Reasoning"
    ],
    "Uses": "Medical assistance, legal advice, financial transactions, fact-checking, open-domain Question Answering (QA)."
  }
]