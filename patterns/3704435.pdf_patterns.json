[
  {
    "Pattern Name": "Zeroshot Prompting",
    "Problem": "How to enable foundation models to understand tool functionalities and usage with minimal or no examples.",
    "Context": "Foundation models with strong few-shot and zero-shot learning capabilities. Tools are accompanied by manuals or descriptions.",
    "Solution": "Construct prompts that describe API functionalities, their input/output formats, and possible parameters.",
    "Result": "The model can understand the tasks each API can tackle without explicit demonstrations.",
    "Related Patterns": ["Fewshot Prompting", "Tool Understanding"],
    "Uses": ["Teaching foundation models about tools", "Rapid adaptation to new tools (e.g., weather API understanding)"]
  },
  {
    "Pattern Name": "Fewshot Prompting",
    "Problem": "How to enable foundation models to learn to utilize tools effectively by observing examples.",
    "Context": "Foundation models with strong few-shot learning capabilities. Availability of concrete tool-use demonstrations.",
    "Solution": "Provide concrete tool-use demonstrations within the prompt to the model.",
    "Result": "The model learns how to utilize tools by mimicking human behaviors from these demonstrations.",
    "Related Patterns": ["Zeroshot Prompting", "Tool Understanding", "Learning from Demonstrations"],
    "Uses": ["Teaching foundation models about tools (e.g., weather API usage examples)"]
  },
  {
    "Pattern Name": "Chain of Thought (CoT) Prompting",
    "Problem": "Foundation models struggle with problems requiring complex reasoning when using vanilla fewshot prompting.",
    "Context": "Large foundation models (hundreds of billions of parameters) that can generate intermediate reasoning traces during complex problem-solving.",
    "Solution": "Insert the reasoning trace required to derive the final answer for each example in the prompt, prompting the model to generate its thoughts on intermediate steps.",
    "Result": "Significantly boosts performance on a wide range of tasks requiring complex reasoning (arithmetic, commonsense, symbolic reasoning), and enables the controller to effectively decompose complex problems and determine which tool to call.",
    "Related Patterns": ["Introspective Reasoning", "Extrospective Reasoning", "Planning with Reasoning"],
    "Uses": ["Arithmetic reasoning", "Commonsense reasoning", "Symbolic reasoning", "Task decomposition", "Tool selection"]
  },
  {
    "Pattern Name": "Instruction Tuning for Intent Understanding",
    "Problem": "How to enable foundation models to accurately understand diverse and potentially vague user instructions for tool-oriented tasks.",
    "Context": "Foundation models can acquire extraordinary proficiency in comprehending user instructions, especially after fine-tuning on diverse instructions.",
    "Solution": "Fine-tune large language models on a collection of datasets templated with human instructions.",
    "Result": "Models generalize effectively to instructions for unseen tasks and provide more personalized responses with a better user experience.",
    "Related Patterns": ["Personalized Tool Learning"],
    "Uses": ["Improving intent understanding for tool selection and planning", "Generalizing to unseen tasks"]
  },
  {
    "Pattern Name": "Introspective Reasoning (Static Planning)",
    "Problem": "Generating a multi-step plan for tool use without immediate feedback from the environment, which can lead to unrealistic plans.",
    "Context": "Tasks where a full plan can be generated upfront. Foundation models with planning capabilities, but without direct environment interaction during planning.",
    "Solution": "The controller directly generates a complete, multi-step plan for tool use without knowing intermediate execution results. This can involve generating code or sequential decisions.",
    "Result": "Enables models to decompose high-level tasks into semantically plausible sub-plans and generate executable programs (e.g., Python code, robot policies).",
    "Related Patterns": ["Chain of Thought Prompting", "Programming Interface", "Extrospective Reasoning"],
    "Uses": ["Generating Python code for reasoning steps (PAL)", "Generating executable programs for embodied agents (ProgPrompt, Code-as-Policies)", "Interleaving vision foundation models with ChatGPT (Visual ChatGPT)"]
  },
  {
    "Pattern Name": "Extrospective Reasoning (Iterative Planning with Feedback)",
    "Problem": "Adapting a plan in response to intermediate execution results and unexpected situations in dynamic environments, which introspective reasoning cannot handle.",
    "Context": "Complex tasks (e.g., multi-step QA, embodied learning) where decision-making at each step depends on the preceding context and environmental feedback.",
    "Solution": "The controller generates plans incrementally, often one step at a time, with subsequent plans dependent on previous execution results and feedback from the environment and user. This creates a closed-loop interaction.",
    "Result": "More rational and feasible plans, improved accuracy on multi-step tasks, and enhanced planning capabilities for embodied agents by handling exceptions and adapting to the current situation.",
    "Related Patterns": ["Chain of Thought Prompting", "Environment Feedback", "Reinforcement Learning for Tool Learning", "Introspective Reasoning"],
    "Uses": ["Multi-step QA (SelfAsk, ReAct, ToolFormer)", "Embodied learning (Inner Monologue, LLMPlanner)", "Determining when to cease generating action tokens during planning (ReAct)"]
  },
  {
    "Pattern Name": "Multi-agent Collaboration",
    "Problem": "Complex tasks often demand collaboration among multiple agents, each possessing unique abilities and expertise, which a single agent may struggle to complete.",
    "Context": "Scenarios where task decomposition allows for parallel or specialized sub-tasks that can be handled by different agents. Foundation models capable of simulating human behaviors and communication.",
    "Solution": "Design methods for communication, coordination, and negotiation among multiple AI agents, each potentially modeled with a foundation model, to work together to achieve complex tasks.",
    "Result": "More effective and efficient problem-solving for complex tasks, unlocking capabilities beyond single-agent systems.",
    "Related Patterns": ["Extrospective Reasoning", "Parallel Tool Execution"],
    "Uses": ["Simulating human behaviors (e.g., interpersonal communication in interactive scenarios)", "Orchestrating complex workflows"]
  },
  {
    "Pattern Name": "Proactive Systems",
    "Problem": "Most foundation models are designed as reactive systems, only responding to user queries without initiating any actions on their own, leading to a less seamless and personalized user experience.",
    "Context": "Systems that can leverage user interaction history and anticipate user needs to improve user experience.",
    "Solution": "Design AI systems that can take action on behalf of the user, continually improving performance and tailoring responses based on learned preferences and historical interactions.",
    "Result": "A more personalized and seamless user experience, with the system anticipating needs and initiating helpful actions. Requires careful design for safety and ethical implications.",
    "Related Patterns": ["Personalized Tool Learning", "Human Feedback"],
    "Uses": ["Personalized assistance", "Context-aware recommendations"]
  },
  {
    "Pattern Name": "Semantic Interface",
    "Problem": "Facilitating a consistent and natural way for models to trigger tool actions using natural language, but mapping needs to be predefined and models may fail to produce precise forms.",
    "Context": "Foundation models excel at generating and understanding natural language. The desire for intuitive and natural interaction with tools.",
    "Solution": "Utilize a specific text span (e.g., action name) as the action trigger, mapping generated natural language directly to specific tool actions.",
    "Result": "An intuitive and natural way for models to interact with tools, leveraging their language generation capabilities.",
    "Related Patterns": ["Programming Interface", "GUI Interface"],
    "Uses": ["Robotic manipulation (e.g., 'pick up the sponge')", "Search engine interaction (e.g., 'Action: Search' for ReAct)"]
  },
  {
    "Pattern Name": "GUI Interface",
    "Problem": "Enabling AI models to interact with digital environments in a human-like manner through graphical user interfaces, which restrict models to predefined options.",
    "Context": "Humans primarily interact with the digital world via GUIs (mouse, keyboard). Models need to map predicted tokens to these physical interactions.",
    "Solution": "Establish a virtual environment that facilitates mapping predicted tokens to human-like mouse movements and keyboard inputs. Leverage foundation models to introduce prior knowledge about common GUI actions.",
    "Result": "Models can perform web-based tasks (e.g., using keyboard and mouse actions), browse and purchase products, expanding potential actions beyond predefined options.",
    "Related Patterns": ["Semantic Interface", "Programming Interface"],
    "Uses": ["Web-based agents to complete tasks (e.g., WebShop)"]
  },
  {
    "Pattern Name": "Programming Interface",
    "Problem": "Enabling models to specify actions with a high degree of flexibility and control, going beyond pure natural language, and modeling complex logic.",
    "Context": "Complex tool learning logic, need for precise control, explicit calls of external APIs. Code-generating language models (CLMs) are available.",
    "Solution": "Allow the model to specify its actions using a program, requiring it to be acquainted with the syntax of function calls. CLMs serve as the backbone for generating this code.",
    "Result": "Models can leverage code grammar to execute complex actions, generalize to novel instructions, and provide precise control with accurate parameter values to functions. Enables modeling complex control flows and explicit API calls.",
    "Related Patterns": ["Introspective Reasoning (PAL, Code-as-Policies)", "Semantic Interface", "GUI Interface"],
    "Uses": ["Robotic control (Code as Policies)", "Mathematical problem solving", "Interacting with databases (SQL queries)", "Software engineering tasks"]
  },
  {
    "Pattern Name": "Formalism Integration for Reasoning",
    "Problem": "Enhancing agents' performance in complex reasoning tasks beyond plain natural text, which may be insufficient for certain domains.",
    "Context": "LLM-based agents inherently comprehend and generate language. External formalisms (mathematical tools, non-natural language forms) can provide structured reasoning capabilities.",
    "Solution": "Incorporate external formalisms such as probabilistic graph models (PGM) or integrate intelligent agents into conventional Robotic Process Automation (RPA) like Agentic Process Automation (APA).",
    "Result": "Significantly enhances agents' decision-making capabilities and intelligence in complex reasoning tasks while remaining controllable.",
    "Related Patterns": ["Knowledge Augmentation", "Extrospective Reasoning"],
    "Uses": ["Multi-agent reasoning (PGM integration)", "Agentic Process Automation (APA)"]
  },
  {
    "Pattern Name": "Retrieval Augmented Generation (RAG)",
    "Problem": "Foundation models suffer from limitations in memorization, real-time knowledge coverage, and can hallucinate knowledge, leading to inaccurate or outdated generations.",
    "Context": "Foundation models need to incorporate domain-specific or up-to-date knowledge. External knowledge sources (local repositories, web) are available.",
    "Solution": "Augment language generation by retrieving knowledge from external sources (e.g., text retrievers, search engines) and integrating it into the model's generation process.",
    "Result": "Mitigates memorization limitations, provides real-time and up-to-date knowledge, enhances factual accuracy, and reduces hallucination.",
    "Related Patterns": ["Knowledge Augmentation", "Conflict Detection & Resolution"],
    "Uses": ["Augmenting language generation", "Open-domain question answering", "Information retrieval (WebGPT)"]
  },
  {
    "Pattern Name": "Supervised Learning (Behavior Cloning for Tool Use)",
    "Problem": "Training foundation models to mimic expert behavior in tool-oriented tasks when expert demonstrations are available.",
    "Context": "Availability of datasets consisting of user queries paired with human demonstration annotations for tool use. Task-general inductive bias of foundation models.",
    "Solution": "Fine-tune foundation models (as policy networks) in a supervised fashion to imitate human experts' actions given certain inputs or conditions.",
    "Result": "Significantly improves both in-domain performance and out-of-distribution generalization for tool use, enabling models to manipulate tools like search engines or interactive web environments.",
    "Related Patterns": ["Learning from Demonstrations", "Semisupervised Learning", "Self-supervised Learning"],
    "Uses": ["Autonomous vehicles and robotic applications", "Finetuning GPT-3 to clone human web search behaviors (WebGPT)", "Training agents for web-based interactive environments (WebShop)"]
  },
  {
    "Pattern Name": "Semisupervised Learning (Pseudo-labeling for Tool Use)",
    "Problem": "Reducing the heavy requirement for human behavior annotation in tool learning when large-scale unlabeled data is available but seed labeled data is limited.",
    "Context": "Human behavior for tool use is costly to record, but unlabeled data is abundant. A small amount of seed labeled data is available.",
    "Solution": "Train a less capable model on a small amount of seed labeled data to predict pseudo-labels of actions on unlabeled data, then use these pseudo-labels to train a more powerful model.",
    "Result": "Enables training powerful tool-using models without requiring extensive human rollout or large-scale gold-standard human behavior annotation.",
    "Related Patterns": ["Supervised Learning (Behavior Cloning)", "Self-supervised Learning"],
    "Uses": ["Training models for Minecraft video game actions"]
  },
  {
    "Pattern Name": "Self-supervised Learning (Bootstrapping Tool Use Examples)",
    "Problem": "Reducing the reliance on human or pseudo-labeled annotations for tool learning, especially for generating diverse tool-use examples.",
    "Context": "Foundation models with in-context learning abilities, and a few human-written examples for tool use.",
    "Solution": "Leverage the in-context learning ability of foundation models to iteratively bootstrap tool-use examples based on a handful of human-written examples. These auto-generated examples are then filtered to reduce noise.",
    "Result": "Creates a sufficient dataset of tool-use supervisions, significantly improving tool-use performance with minimal human effort.",
    "Related Patterns": ["Supervised Learning (Behavior Cloning)", "Semisupervised Learning", "Fewshot Prompting"],
    "Uses": ["Enhancing tool-use capabilities (Toolformer)"]
  },
  {
    "Pattern Name": "Reinforcement Learning for Tool Learning",
    "Problem": "Enabling artificial agents to learn from trial and error and adapt their tool-use behaviors in complex, dynamic environments to maximize rewards.",
    "Context": "Tool learning scenarios where the action space is defined by tools, and agents need to optimize their policy based on consequences. Foundation models can serve as policy initialization.",
    "Solution": "Frame tool learning as an RL scenario, where the agent learns to select appropriate tools and perform correct actions that maximize a reward signal, often initialized by a foundation model.",
    "Result": "Agents learn to reflect on the current state, select tools, and perform actions leading to the highest expected reward, adapting to changes and optimizing decisions based on dynamic feedback.",
    "Related Patterns": ["Environment Feedback", "Human Feedback", "Extrospective Reasoning", "Reinforcement Learning from Human Feedback (RLHF)"],
    "Uses": ["Robotic grasping", "Multi-agent auto-curricula", "Enhancing LLM tool-using capabilities (ETO)"]
  },
  {
    "Pattern Name": "Environment Feedback",
    "Problem": "Providing agents with information about the consequences of their tool actions to allow for policy updates and behavior adaptation.",
    "Context": "Interactive environments where tool actions trigger observable changes. Feedback can be ultimate (result) or intermediate (state changes).",
    "Solution": "The controller interacts with the environment and receives feedback, which can be 1) result feedback (indicating task completion success/failure) or 2) intermediate feedback (state changes triggered by an action).",
    "Result": "Models can iteratively update their planning strategy, adjust decision-making, and learn whether each action is effective and appropriate, improving tool-use behavior.",
    "Related Patterns": ["Extrospective Reasoning", "Reinforcement Learning for Tool Learning"],
    "Uses": ["WebShop (reward based on product similarity)", "Search engine interaction (observing rendered information)", "Embodied learning (current scene information)"]
  },
  {
    "Pattern Name": "Human Feedback",
    "Problem": "Aligning model behavior with human preferences and values in tool-use scenarios and regulating its behavior.",
    "Context": "Human judgment is crucial for assessing the quality and appropriateness of model-generated plans and actions. Feedback can be explicit or implicit.",
    "Solution": "Humans provide the model with rewards and penalties based on its generated plans, which can be explicit (direct ratings on a scale) or implicit (derived from user behavior like comparisons, response time, or actions taken).",
    "Result": "Regulates model behavior, aligns tool-use with human preferences, and helps in manipulating tools more effectively to answer questions or complete tasks.",
    "Related Patterns": ["Reinforcement Learning from Human Feedback (RLHF)", "Proactive Systems"],
    "Uses": ["Guiding policy models to align with human preferences in search engines (WebGPT)", "Text summarization"]
  },
  {
    "Pattern Name": "Reinforcement Learning from Human Feedback (RLHF)",
    "Problem": "The accuracy and stability of human feedback are valuable, but it is label-intensive and has high latency for direct use in training.",
    "Context": "Availability of human feedback (explicit or implicit) on model-generated outputs or actions.",
    "Solution": "Fine-tune a separate model to imitate humans in giving rewards, and then use these learned rewards to optimize the main policy model with RL algorithms (e.g., PPO).",
    "Result": "Yields exceptional performance in aligning models with human preferences, improving tool-use capabilities even after supervised training, by leveraging human judgment more efficiently.",
    "Related Patterns": ["Human Feedback", "Reinforcement Learning for Tool Learning"],
    "Uses": ["Text summarization", "Improving search engine manipulation (WebGPT)", "Enhancing LLM tool-using proficiency (e.g., DPO algorithm)"]
  },
  {
    "Pattern Name": "Meta Tool Learning",
    "Problem": "Enabling models to generalize tool-use knowledge and strategies to new, unfamiliar tasks or domains efficiently.",
    "Context": "Models need to identify common underlying principles or patterns in tool-use strategies across different tools or domains.",
    "Solution": "Train the model to not only use a tool but also to learn the optimal strategy for its use, allowing it to identify common patterns in tool-use strategies.",
    "Result": "Models can transfer their knowledge of tool-use strategies to new tools or domains (e.g., from one search engine to another, or a calculator for different mathematical problems), leading to more adaptable and intelligent ML models.",
    "Related Patterns": ["Curriculum Tool Learning", "Generalizable Tool Learning"],
    "Uses": ["Transferring knowledge between similar search engines (e.g., Bing to Google Search)", "Generalizing calculator use to solve different types of mathematical problems"]
  },
  {
    "Pattern Name": "Curriculum Tool Learning",
    "Problem": "Effectively teaching models to use complex tools by gradually building knowledge and skills in a manageable way.",
    "Context": "Tools with varying levels of complexity, where starting with simple functionalities can ease the learning curve.",
    "Solution": "A pedagogical strategy that starts with simple tools or basic functionalities of a tool and gradually introduces the model to more complex tools or advanced concepts, allowing it to build upon prior knowledge.",
    "Result": "Ensures the model masters essential features before moving to complex concepts, making learning manageable and effective. Improves generalization by enabling the model to identify similarities/differences and adapt its approach.",
    "Related Patterns": ["Meta Tool Learning", "Generalizable Tool Learning"],
    "Uses": ["Teaching models to use mathematical software (e.g., Mathematica, starting with addition/subtraction then calculus)", "Learning complex algorithms or operations"]
  },
  {
    "Pattern Name": "Personalized Tool Learning",
    "Problem": "Foundation models, typically trained on generic domains, struggle to provide tailored assistance to users with varying needs and preferences for tool learning.",
    "Context": "Users have diverse preferences for tool planning, selection, and interaction. Personal information can be heterogeneous.",
    "Solution": "Integrate user-specific information (e.g., language style, social networks, preferences for platforms) into general-purpose tool learning models. This involves: 1) modeling heterogeneous user information, 2) personalized tool planning, and 3) personalized tool calls.",
    "Result": "Models provide tailored assistance, adapt to diverse expressions of intent, and generate personalized tool execution plans and inputs, leading to a more personalized user experience.",
    "Related Patterns": ["Proactive Systems", "Human Feedback", "Instruction Tuning for Intent Understanding"],
    "Uses": ["Personalized email tool usage", "Customized online shopping experiences"]
  },
  {
    "Pattern Name": "Conflict Detection & Resolution",
    "Problem": "Discrepancies and inconsistencies (knowledge conflicts) arise between model knowledge (memorized from training data) and augmented knowledge (from tool execution), or among knowledge from different tools.",
    "Context": "Foundation models augmented by various knowledge sources, where some knowledge might be outdated, false, or biased. Need for accuracy and reliability in model generation.",
    "Solution": "Implement mechanisms for: 1) Conflict Detection: Identify potential conflicts among different knowledge sources and flag them. 2) Conflict Resolution: Verify reliability, choose trustworthy sources, and provide explanations for the model's final generation by interpreting which knowledge source was considered.",
    "Result": "Improves the accuracy and reliability of model generation and planning, especially in high-stakes domains, by ensuring models can distinguish and verify knowledge sources.",
    "Related Patterns": ["Retrieval Augmented Generation (RAG)", "Knowledge Augmentation"],
    "Uses": ["Medical assistance", "Legal advice", "Question answering", "Correcting model beliefs with retrieved information", "Discerning knowledge conflicts from different sources"]
  },
  {
    "Pattern Name": "Tools by AI (AI-Generated Tools)",
    "Problem": "The traditional limitation of humans being the sole creators of tools, hindering the potential for AI to develop solutions specifically optimized for its own use or to encapsulate existing functionalities.",
    "Context": "Large code models capable of generating executable programs based on language descriptions. Foundation models can understand and extend existing API functionalities.",
    "Solution": "Leverage foundation models, particularly large code models, to autonomously generate executable programs or encapsulate existing APIs into more advanced and tailored functions.",
    "Result": "AI systems can transition from merely tool users to tool makers, creating tools optimized for their own processes, extending existing functionalities, and developing sophisticated solutions autonomously.",
    "Related Patterns": ["Programming Interface", "Tools for AI"],
    "Uses": ["Generating executable programs from language descriptions (large code models)", "Encapsulating existing APIs into more advanced functions (e.g., extending weather forecast API, integrating stock market data, automated medical diagnosis systems)"]
  },
  {
    "Pattern Name": "Tools for AI (Model-Optimized Tools)",
    "Problem": "Existing tools are primarily designed for human preference and convenience, not necessarily optimal for how AI models process information, leading to suboptimal interaction and utilization.",
    "Context": "AI models process information differently from humans, and current tools may not be modular or have suitable input/output formats for AI.",
    "Solution": "Create tools specifically suited for models by: 1) Modularity: Decomposing tools into smaller, more modular units. 2) New Input/Output Formats: Developing formats tailored to the needs of AI models.",
    "Result": "Improves interaction and utilization of tools by AI models, enabling more seamless integration and communication between models and tools, and allowing models to use components in a fine-grained and compositional manner.",
    "Related Patterns": ["Tools by AI"],
    "Uses": ["Designing tools with AI consumption in mind", "Developing new input/output formats for AI-tool interaction"]
  },
  {
    "Pattern Name": "Interpretability through Tool Execution",
    "Problem": "Foundation models are often criticized for lacking transparency (being 'black boxes') in their decision-making processes, which is a significant concern in critical applications.",
    "Context": "Applications like healthcare or finance where understanding the rationale behind AI decisions is critical for making informed decisions and building trust.",
    "Solution": "Design the AI system such that the process of tool execution reflects the steps taken by the model to solve complex requests.",
    "Result": "Allows for better interpretability and transparency. Users can easily understand why certain tools were called and how they contribute to the final output, improving trust and facilitating human-machine collaboration.",
    "Related Patterns": ["Extrospective Reasoning", "Chain of Thought Prompting"],
    "Uses": ["Healthcare", "Finance", "Improving human-machine collaboration"]
  },
  {
    "Pattern Name": "Robustness through Tools",
    "Problem": "Foundation models are susceptible to adversarial attacks (slight input modifications flipping predictions) due to their reliance on statistical patterns.",
    "Context": "Applications requiring high reliability and resistance to malicious inputs.",
    "Solution": "Augment foundation models with specialized tools designed for specific use cases, which may be agnostic to input perturbation.",
    "Result": "Tools make the overall AI system more resistant to adversarial attacks, enhancing its reliability and stability in real-world deployments.",
    "Related Patterns": [],
    "Uses": ["Enhancing security in AI applications", "Defending against adversarial attacks"]
  },
  {
    "Pattern Name": "Democratizing Tool Access",
    "Problem": "Complex tools often have steep learning curves and require specialized technical expertise, limiting their accessibility to non-technical users.",
    "Context": "The powerful intent understanding capabilities of foundation models.",
    "Solution": "Leverage foundation models to simplify intricate tasks into a natural language format, allowing users to provide high-level guidance and direction. The model then comprehends the intent and manipulates complex tools.",
    "Result": "Lowers the barrier to entry for new users, enabling even novice users to easily and quickly get started with new tools, regardless of their prior experience or technical expertise, unlocking innovation and creativity.",
    "Related Patterns": ["Instruction Tuning for Intent Understanding", "Personalized Tool Learning"],
    "Uses": ["Making complex tools accessible to individuals without specialized technical knowledge"]
  }
]