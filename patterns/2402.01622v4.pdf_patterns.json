[
  {
    "Pattern Name": "Direct Prompting",
    "Problem": "To obtain a basic, single-turn response from an LLM.",
    "Context": "Used as a baseline for evaluating more complex strategies, or for straightforward tasks where extensive reasoning or tool use is not required.",
    "Solution": "The user's query is input directly into the LLM, possibly along with relevant information, without explicit instructions for intermediate steps or iterative processes.",
    "Result": "Provides a direct response. The paper's results (Table 3) show it yields very low final pass rates for complex, multi-constraint tasks like TravelPlanner, highlighting its insufficiency.",
    "Related Patterns": [],
    "Uses": "Baseline evaluation, simple information retrieval.",
    "Category": "Prompt Design"
  },
  {
    "Pattern Name": "Chain-of-Thought (CoT)",
    "Problem": "Large Language Models (LLMs) often struggle with complex reasoning tasks, providing direct but incorrect answers without showing their thought process.",
    "Context": "LLMs are applied to problems requiring multi-step reasoning, logical deduction, or problem-solving, where explicit intermediate steps can aid in finding a solution.",
    "Solution": "The prompt is designed to instruct the LLM to generate a series of intermediate reasoning steps before arriving at the final answer. A common technique (Zero-Shot Chain-of-Thought, ZSCoT) involves adding a phrase like 'Let's think step by step.'",
    "Result": "Improves the LLM's reasoning ability and capacity to handle complex problems by making the thought process transparent. In TravelPlanner, it shows a slight improvement over Direct Prompting for GPT3.5-Turbo but remains insufficient for the benchmark's complexity.",
    "Related Patterns": [
      "Task Decomposition",
      "ReAct (Reasoning and Acting)",
      "Tree-of-Thoughts (ToT) / Graph-of-Thoughts (GoT)"
    ],
    "Uses": "Enhancing reasoning in LLMs, complex problem-solving, planning.",
    "Category": "Prompt Design"
  },
  {
    "Pattern Name": "ReAct (Reasoning and Acting)",
    "Problem": "Language agents need to effectively interact with dynamic, partially observable environments by interleaving reasoning with actions and observing their outcomes to make progress.",
    "Context": "LLM-powered agents are deployed in environments where tasks require information collection, tool use, and dynamic decision-making, such as travel planning scenarios with various search tools.",
    "Solution": "The framework guides the LLM to alternate between 'Thought' (reasoning about the current situation and next steps), 'Action' (executing a tool or interacting with the environment), and 'Observation' (receiving feedback or results from the action). This iterative cycle incorporates environmental feedback into the reasoning process.",
    "Result": "Enhances the language agent's reasoning ability and enables effective iteration with tools for information collection. However, for highly complex, multi-constraint tasks like TravelPlanner, it is found to be insufficient, often failing to convert reasoning into correct actions or track multiple constraints.",
    "Related Patterns": [
      "Tool Use / Tool Augmentation",
      "Task Decomposition",
      "Chain-of-Thought (CoT)",
      "Reflexion (Self-Correction with Verbal Reinforcement Learning)"
    ],
    "Uses": "Information collection, planning in dynamic environments, tool-augmented LLMs, language agents.",
    "Category": "Agentic AI"
  },
  {
    "Pattern Name": "Reflexion (Self-Correction with Verbal Reinforcement Learning)",
    "Problem": "Language agents often get trapped in dead loops, make invalid actions, or fail to dynamically adjust their plans based on environment feedback, indicating a struggle to identify and correct flawed reasoning.",
    "Context": "Language agents are performing complex tasks where errors are common, and there's a need for a mechanism to learn from past failures and improve decision-making.",
    "Solution": "This approach utilizes a 'reflection model' that provides high-level insights or critiques on previous erroneous attempts. This reflective guidance aids language agents in identifying and correcting flawed reasoning and actions.",
    "Result": "Aims to improve the agent's ability to self-correct and dynamically adjust plans, potentially reducing persistent errors and dead loops. While showing some benefits over basic ReAct in some metrics, it is still insufficient for the multi-constraint complexity of TravelPlanner. The paper notes agents struggle to align actions with reasoning despite recognizing flaws.",
    "Related Patterns": [
      "ReAct (Reasoning and Acting)",
      "Chain-of-Thought (CoT)"
    ],
    "Uses": "Error correction, improving reasoning, learning from past failures, enhancing agent robustness.",
    "Category": "Agentic AI"
  },
  {
    "Pattern Name": "Tool Use / Tool Augmentation",
    "Problem": "Language agents have inherent limitations in their capabilities (e.g., knowledge cut-off, lack of real-time data, inability to perform specific computations) and need to proactively acquire necessary information from external sources.",
    "Context": "LLM-powered agents require access to dynamic, external, or specialized information (e.g., flight schedules, restaurant details, accommodation availability) or need to interact with external systems to complete complex tasks.",
    "Solution": "Empower LLMs to interact with a 'Toolbox' of external tools (e.g., CitySearch, FlightSearch, DistanceMatrix, RestaurantSearch, AttractionSearch, AccommodationSearch). Agents are instructed to employ these tools to gather information from a partially observable environment.",
    "Result": "Significantly expands the potential capabilities of language agents by allowing them to collect necessary information and interact with the real world. However, agents still face challenges like argument errors in tool use and getting trapped in dead loops during information collection.",
    "Related Patterns": [
      "ReAct (Reasoning and Acting)",
      "Memory Augmentation (Long-term and Short-term)"
    ],
    "Uses": "Information collection, expanding LLM capabilities, interacting with dynamic environments, complex planning (e.g., travel planning).",
    "Category": "Tools Integration"
  },
  {
    "Pattern Name": "Memory Augmentation (Long-term and Short-term)",
    "Problem": "Language agents have limited cognitive capacity, especially for long-horizon tasks, and struggle with working memory management, leading to issues like context accumulation exceeding token limits or forgetting past information.",
    "Context": "LLM-powered agents need to maintain context over extended interactions, store intermediate plans, and recall information to make informed decisions for multi-day itineraries or complex planning scenarios.",
    "Solution": "Integrate mechanisms for both short-term and long-term memory. Short-term memory is managed through techniques like context summarization and a 'NotebookWrite' tool to record necessary information, preventing token limit issues. Long-term memory involves parametric memory inherent in LLMs and retrieval techniques for acquiring and processing information.",
    "Result": "Enhances the agent's ability to acquire and process information, manage working memory, and maintain context over longer tasks. However, the paper suggests that existing methods are still insufficient for the demands of complex, long-horizon planning.",
    "Related Patterns": [
      "Tool Use / Tool Augmentation",
      "ReAct (Reasoning and Acting)"
    ],
    "Uses": "Managing context, storing intermediate plans, retrieving information, long-horizon tasks, conversational AI.",
    "Category": "Knowledge & Reasoning"
  },
  {
    "Pattern Name": "Task Decomposition",
    "Problem": "Complex, long-horizon tasks, such as planning a multi-day itinerary with numerous interdependent decisions and constraints, are difficult for language agents to handle directly.",
    "Context": "LLM-powered agents are faced with multi-step, intricate problems (e.g., travel planning involving places, lodging, transportation, dining) that require breaking down into more manageable parts.",
    "Solution": "Language agents are endowed with the capability to decompose complex tasks into a series of reasoned actions or sub-tasks, addressing individual components of the larger problem sequentially or hierarchically.",
    "Result": "Enables language agents to approach and make progress on complex problems by breaking them into simpler components. However, for multi-constraint, long-horizon tasks, agents still struggle to holistically consider all constraints during decomposition and execution.",
    "Related Patterns": [
      "Chain-of-Thought (CoT)",
      "ReAct (Reasoning and Acting)",
      "Tree-of-Thoughts (ToT) / Graph-of-Thoughts (GoT)"
    ],
    "Uses": "Planning, problem-solving, multi-step instruction following, agentic control.",
    "Category": "Planning"
  },
  {
    "Pattern Name": "Tree-of-Thoughts (ToT) / Graph-of-Thoughts (GoT)",
    "Problem": "Optimizing solution searches for complex problems often requires more than linear reasoning, necessitating exploration of multiple reasoning paths and potentially backtracking.",
    "Context": "LLM-powered agents need to find optimal solutions in scenarios that involve a large search space and complex interdependencies, where evaluating multiple alternatives is beneficial.",
    "Solution": "Employ classical data structures like trees (Tree-of-Thoughts) or graphs (Graph-of-Thoughts) to structure the search for solutions. This allows for generating and evaluating multiple candidate 'thoughts' or reasoning steps, enabling a more deliberate and potentially more optimal exploration of the problem space.",
    "Result": "Implied to enhance planning capabilities by optimizing solution searches in fewer steps for less complex problems. The paper notes these methods were 'prohibitively costly' and thus not directly evaluated for TravelPlanner's complexity, despite their proven effectiveness in prior studies.",
    "Related Patterns": [
      "Task Decomposition",
      "Chain-of-Thought (CoT)",
      "ReAct (Reasoning and Acting)"
    ],
    "Uses": "Optimizing solution searches, complex reasoning, strategic problem-solving.",
    "Category": "Knowledge & Reasoning"
  }
]