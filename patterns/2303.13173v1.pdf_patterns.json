[
  {
    "Pattern Name": "Workflow Pipeline",
    "Problem": "Creating an end-to-end reproducible training and deployment pipeline for a machine learning component is difficult, and data science notebooks do not scale for this purpose.",
    "Context": "ML components require reproducible training and scalable deployment, but existing methods like data science notebooks fall short.",
    "Solution": "Each pipeline step is containerized as a separate service, which are then orchestrated and chained together to form a pipeline executable via REST API calls.",
    "Result": "Improved portability, scalability, and maintainability of individual pipeline steps, though at the cost of increased overall solution complexity.",
    "Related Patterns": [],
    "Uses": "AWS Blog examples for building MLOps workflows.",
    "Category": "MLOps"
  },
  {
    "Pattern Name": "Two-Phase Predictions",
    "Problem": "Executing large, complex ML models is time-consuming and costly, especially when lightweight clients (e.g., mobile, IoT devices) are involved.",
    "Context": "Systems where predictions are needed on resource-constrained clients or where high-latency predictions from large models are undesirable for all requests.",
    "Solution": "Split the prediction process into two phases: first, a simple, fast model is executed on the client, and then, optionally, a large, complex model is executed in the cloud for deeper insights.",
    "Result": "Reduced prediction response time for some cases, decreased number of large, expensive predictions, and a fallback model available on the client even without internet connection.",
    "Related Patterns": [],
    "Uses": "Voice activation in AI assistants like Alexa or Google Assistant.",
    "Category": "MLOps"
  },
  {
    "Pattern Name": "Encapsulating ML Models within Rule-based Safeguards",
    "Problem": "The inherent non-guarantee of correctness in ML model predictions makes them unsuitable for direct use in safety or security-related functions, and they are vulnerable to adversarial attacks, data noise, and drift.",
    "Context": "AI systems operating in safety-critical or security-sensitive environments where the unreliability of ML models poses significant risks.",
    "Solution": "Introduce a deterministic rule-based mechanism that evaluates and decides how to handle ML prediction results, often based on additional quality checks.",
    "Result": "Reduced risk of negative impacts from incorrect predictions, but the architecture becomes more complex.",
    "Related Patterns": [],
    "Uses": [],
    "Category": "Agentic AI, AI–Human Interaction"
  },
  {
    "Pattern Name": "AI Pipelines",
    "Problem": "Complex prediction or synthesis use cases are often difficult to accomplish effectively with a single AI tool or model.",
    "Context": "AI systems requiring a sequence of specialized AI processing steps to achieve a high-quality final result, such as in computer vision or complex natural language generation.",
    "Solution": "Divide the overall problem into smaller, consecutive steps. Then, combine several existing AI tools or custom models into an inference-time AI pipeline, with each specialized tool or model responsible for a single step.",
    "Result": "Higher quality results, with the ability to optimize each step individually, but requires integrating more tools and models.",
    "Related Patterns": [],
    "Uses": "Typical computer vision inference pipelines.",
    "Category": "Tools Integration, Classical AI"
  },
  {
    "Pattern Name": "Ethics Credentials",
    "Problem": "Responsible AI requirements are frequently omitted or stated as vague high-level objectives, lacking explicit, verifiable specifications as system outputs, leading to user distrust or non-adoption.",
    "Context": "AI systems where user trust, ethical compliance, and accountability are paramount, but current methods for demonstrating these are insufficient.",
    "Solution": "Provide verifiable ethics credentials for the AI system or component, leveraging publicly accessible and trusted data infrastructure for verification. Users may also need to verify their credentials to access the system.",
    "Result": "Increased trust and system acceptance, raised awareness of ethical issues. Requires a trusted public data infrastructure and ongoing maintenance/refresh of credentials.",
    "Related Patterns": [],
    "Uses": [],
    "Category": "AI–Human Interaction"
  },
  {
    "Pattern Name": "Distinguish Business Logic from ML Model",
    "Problem": "ML systems are complex due to regular retraining requirements and intrinsic non-deterministic behavior of ML components, alongside evolving business requirements and ML algorithms.",
    "Context": "Any system integrating ML components where clear separation of concerns is needed between the stable business logic and the dynamic, evolving ML models.",
    "Solution": "Define clear APIs between traditional (business logic) and ML components. Structure the system into layers, separating business and ML components based on their distinct responsibilities, and divide data flows accordingly.",
    "Result": "Improved manageability and adaptability of ML systems by isolating the volatile ML parts from the stable business logic.",
    "Related Patterns": [],
    "Uses": [],
    "Category": "MLOps"
  },
  {
    "Pattern Name": "Microservice Vertical Pattern",
    "Problem": "Managing several ML inferences that need to run in a specific order or have dependencies on each other within an ML system.",
    "Context": "AI systems requiring sequential execution of multiple prediction models, where the output of one model serves as input for the next.",
    "Solution": "Deploy individual prediction models as separate services (servers or containers). Prediction requests are executed synchronously from top to bottom, with results gathered to form the final response to the client.",
    "Result": "Facilitates ordered execution and dependency management for multi-stage ML inference.",
    "Related Patterns": [],
    "Uses": [],
    "Category": "MLOps, Tools Integration"
  },
  {
    "Pattern Name": "Microservice Horizontal Pattern",
    "Problem": "Workflows that can execute multiple ML predictions in parallel, or when multiple predictions need to be integrated into a single response for one request.",
    "Context": "AI systems that benefit from parallel execution of independent prediction models to handle a single request, or where an ensemble of models is used.",
    "Solution": "Deploy multiple prediction models in parallel as separate services. A single request can be sent to these models simultaneously to acquire multiple predictions or an integrated prediction.",
    "Result": "Enables efficient parallel inference and integration of results from multiple models for a single request.",
    "Related Patterns": [],
    "Uses": [],
    "Category": "MLOps, Tools Integration"
  },
  {
    "Pattern Name": "Deploy Canary Model",
    "Problem": "Uncertainty about whether a newly trained ML model, assumed to have better prediction quality, will perform as expected in production, and to mitigate risks of new model issues affecting all users.",
    "Context": "MLOps environments where new ML models are frequently deployed and need rigorous, real-world validation before full rollout.",
    "Solution": "Deploy the new model alongside existing ones and route a small fraction of production requests to it. Evaluate its performance with this limited exposure. If successful, replace existing models; otherwise, improve the new model.",
    "Result": "Minimizes user exposure to potential bugs or low-quality predictions from new models, but requires additional serving and monitoring infrastructure.",
    "Related Patterns": [],
    "Uses": [],
    "Category": "MLOps"
  }
]