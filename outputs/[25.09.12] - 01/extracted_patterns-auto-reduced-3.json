[
  {
    "Pattern Name": "Reasoning on Graphs (RoG)",
    "Problem": "Large Language Models (LLMs) suffer from hallucinations and lack of up-to-date knowledge, leading to incorrect and untrustworthy reasoning, especially in complex tasks requiring factual and structural knowledge. Existing Knowledge Graph (KG)-based LLM reasoning methods often overlook the importance of KG structural information.",
    "Context": "Designing AI/ML systems where LLMs need to perform faithful and interpretable reasoning on complex, knowledge-intensive tasks, particularly those that can benefit from structured knowledge bases like KGs, and where the reasoning process needs to be verifiable.",
    "Solution": "A comprehensive Planning-Retrieval-Reasoning framework that synergizes LLMs with KGs. It involves:\n1.  **Planning Module:** LLMs generate 'relation paths' (sequences of relations) grounded by KGs as faithful plans. This module is optimized to distill KG knowledge into the LLM to generate valid paths.\n2.  **Retrieval Module:** Based on the generated relation paths, valid 'reasoning paths' (instances of relation paths with specific entities) are retrieved from the KGs using a constrained search.\n3.  **Reasoning Module:** LLMs conduct faithful reasoning based on the retrieved reasoning paths to generate answers and interpretable explanations. This module is optimized to identify important paths and filter noise.\nThe entire system is jointly trained through 'Planning Optimization' and 'Retrieval-Reasoning Optimization' to maximize the probability of reasoning the correct answer from the KG.",
    "Result": "Achieves state-of-the-art performance on KG reasoning tasks, generates faithful and interpretable reasoning results, and allows LLMs to access the latest knowledge from KGs. The planning module can be seamlessly integrated with other LLMs during inference.",
    "Related Patterns": [
      "KG-Grounded Planning",
      "Reasoning Path Retrieval",
      "Path-Based Interpretable Reasoning"
    ],
    "Uses": [
      "Knowledge Graph Question Answering (KGQA)",
      "Complex multi-hop reasoning",
      "Factual verification",
      "Any application requiring LLMs to provide verifiable and transparent reasoning based on structured knowledge."
    ]
  },
  {
    "Pattern Name": "KG-Grounded Planning",
    "Problem": "Large Language Models (LLMs) are prone to generating incorrect or hallucinated reasoning plans, diminishing performance and trustworthiness, especially when external, structured knowledge is required.",
    "Context": "Building LLM-based systems for complex reasoning tasks where the correctness and faithfulness of the reasoning process are critical, and where structured knowledge from Knowledge Graphs (KGs) can provide reliable guidance for planning.",
    "Solution": "An LLM is trained (via 'Planning Optimization') to distill knowledge from KGs to generate 'relation paths' (sequences of relations) that are grounded by the KG as faithful plans. These plans are structurally formatted and represent valid reasoning steps within the KG. The optimization encourages the LLM to generate paths that exist in the KG, often using shortest paths between question and answer entities as supervision.",
    "Result": "LLMs generate reasoning plans that are faithful to the underlying knowledge base, significantly reducing hallucinations and improving the reliability of subsequent reasoning steps. This module can be integrated as a plug-and-play component with various LLMs.",
    "Related Patterns": [
      "Reasoning on Graphs (RoG)",
      "Reasoning Path Retrieval"
    ],
    "Uses": [
      "Guiding LLM reasoning in knowledge-intensive domains",
      "Improving the trustworthiness of LLM outputs",
      "Enabling structured knowledge retrieval",
      "Decomposing complex problems into verifiable steps."
    ]
  },
  {
    "Pattern Name": "Reasoning Path Retrieval",
    "Problem": "LLMs need to access and leverage the structural information within Knowledge Graphs (KGs) effectively for reasoning, but existing retrieval methods often treat KGs as flat factual bases or retrieve noisy, irrelevant triples.",
    "Context": "LLM-based systems that require precise, structured, and up-to-date knowledge from KGs to support faithful and interpretable reasoning, guided by a specific reasoning intent or plan.",
    "Solution": "Given a question and a faithful 'relation path' (plan) generated by an LLM, a retrieval module identifies and extracts specific 'reasoning paths' (instances of the relation path, i.e., sequences of entities and relations) from the Knowledge Graph. This process is typically conducted using a constrained breadth-first search, starting from question entities and strictly following the relations specified in the relation path plan.",
    "Result": "Provides LLMs with highly relevant, structured, and grounded knowledge in the form of verifiable reasoning paths, which directly support faithful reasoning and explanation generation, and significantly reduces noise compared to less structured retrieval methods.",
    "Related Patterns": [
      "Reasoning on Graphs (RoG)",
      "KG-Grounded Planning",
      "Path-Based Interpretable Reasoning"
    ],
    "Uses": [
      "Providing structured context for LLM reasoning",
      "Enabling multi-hop reasoning over KGs",
      "Reducing the search space for relevant knowledge",
      "Supporting the generation of interpretable explanations."
    ]
  },
  {
    "Pattern Name": "Path-Based Interpretable Reasoning",
    "Problem": "Large Language Models (LLMs) often provide answers without clear, verifiable explanations, diminishing user trust and making it difficult to debug incorrect reasoning or understand the basis of a decision.",
    "Context": "AI/ML systems where transparency, trustworthiness, and the ability to provide human-understandable justifications for LLM-generated answers are crucial, especially in high-stakes scenarios or when leveraging structured knowledge.",
    "Solution": "An LLM is guided (via 'Retrieval-Reasoning Optimization' and specific instruction prompts) to conduct reasoning based on a set of retrieved 'reasoning paths' from a Knowledge Graph and then generate answers accompanied by explicit, interpretable explanations. These explanations directly reference and articulate how the retrieved reasoning paths lead to the final answer, effectively tracing the reasoning steps back to verifiable facts and structures within the KG.",
    "Result": "LLM outputs are accompanied by clear, grounded, and verifiable explanations that enhance trustworthiness, allow for easier debugging, and improve user understanding of the reasoning process.",
    "Related Patterns": [
      "Reasoning on Graphs (RoG)",
      "Reasoning Path Retrieval"
    ],
    "Uses": [
      "Building trustworthy AI systems",
      "Debugging and auditing LLM reasoning",
      "Providing transparent decision support",
      "Enhancing user comprehension in knowledge-intensive applications."
    ]
  }
]