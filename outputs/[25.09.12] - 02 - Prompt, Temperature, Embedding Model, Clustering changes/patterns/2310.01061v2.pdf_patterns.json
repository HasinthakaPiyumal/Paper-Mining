[
  {
    "Pattern Name": "Chain-of-Thought (CoT) Prompting",
    "Problem": "Large Language Models (LLMs) struggle with complex multi-step reasoning tasks, often producing incorrect or non-transparent answers.",
    "Context": "Tasks requiring sequential logical steps, arithmetic, or symbolic manipulation, where intermediate thoughts can guide the final answer.",
    "Solution": "Prompt the LLM to generate a series of intermediate reasoning steps or 'thoughts' before providing the final answer. This makes the LLM's reasoning process explicit.",
    "Result": "Improves the LLM's ability to perform complex reasoning, enhances transparency, and often leads to more accurate results.",
    "Related Patterns": [
      "Tree of Thoughts / Graph of Thoughts",
      "Plan-and-Solve Prompting / Decomposed Prompting"
    ],
    "Uses": "Complex question answering, mathematical problem solving, logical deduction."
  },
  {
    "Pattern Name": "Tree of Thoughts / Graph of Thoughts",
    "Problem": "Linear Chain-of-Thought reasoning can be limited, potentially getting stuck on incorrect paths or failing to explore diverse reasoning trajectories.",
    "Context": "Highly complex problems where multiple reasoning paths might exist, or where intermediate steps have non-linear dependencies and require aggregation.",
    "Solution": "Expands the reasoning process into a non-linear structure. Tree of Thoughts allows the LLM to explore multiple reasoning branches, evaluate intermediate thoughts, and backtrack. Graph of Thoughts further models reasoning as a graph, enabling more flexible connections between thoughts, aggregation of information from multiple paths, and handling of complex dependencies.",
    "Result": "Enhances the robustness and comprehensiveness of LLM reasoning by allowing for broader exploration, self-correction, and synergistic combination of ideas.",
    "Related Patterns": [
      "Chain-of-Thought (CoT) Prompting",
      "Plan-and-Solve Prompting / Decomposed Prompting"
    ],
    "Uses": "Strategic planning, complex problem-solving, multi-faceted decision making."
  },
  {
    "Pattern Name": "Plan-and-Solve Prompting / Decomposed Prompting",
    "Problem": "LLMs often struggle with complex, multi-faceted tasks that require a structured approach, leading to errors or incomplete solutions.",
    "Context": "Tasks that can be naturally broken down into a sequence of smaller, more manageable subtasks or require a strategic approach before execution.",
    "Solution": "Prompt the LLM to first generate a high-level plan or decompose the complex task into a series of subtasks. Then, the LLM executes each subtask or step of the plan sequentially.",
    "Result": "Improves the LLM's ability to tackle complex problems by providing a structured framework, reducing cognitive load, and making the problem-solving process more systematic.",
    "Related Patterns": [
      "Chain-of-Thought (CoT) Prompting",
      "Tree of Thoughts / Graph of Thoughts"
    ],
    "Uses": "Multi-step instruction following, complex code generation, long-horizon task execution."
  },
  {
    "Pattern Name": "Agentic LLM with Tool Use",
    "Problem": "Large Language Models (LLMs) are limited by their training data cutoff, lack real-time information, and cannot interact with external environments or perform actions.",
    "Context": "Tasks requiring up-to-date factual knowledge, interaction with external APIs/databases, environment manipulation, or dynamic information retrieval.",
    "Solution": "Treat the LLM as an autonomous agent that can both reason (generate thoughts) and act (execute external tools or interact with an environment). The LLM observes the environment, decides on an action, executes it, and then incorporates the observation into its next reasoning step.",
    "Result": "Extends LLM capabilities beyond static knowledge, enabling real-time information access, dynamic problem-solving, and interaction with the real world.",
    "Related Patterns": [
      "Retrieval-Augmented Reasoning",
      "Reasoning on Graphs"
    ],
    "Uses": "Web browsing, API interaction, robotics, complex data analysis, knowledge graph querying."
  },
  {
    "Pattern Name": "Reasoning Verification (Entailer)",
    "Problem": "LLMs can generate plausible but incorrect or unfaithful reasoning steps, leading to unreliable outputs, especially in critical applications.",
    "Context": "Scenarios where the truthfulness and faithfulness of each reasoning step are paramount, and errors can have significant consequences.",
    "Solution": "Introduce a separate verification mechanism (e.g., another LLM, a rule-based system, or a factual knowledge base checker) to validate the logical consistency and factual accuracy of the reasoning steps generated by the primary LLM.",
    "Result": "Enhances the trustworthiness and reliability of LLM reasoning by identifying and potentially correcting erroneous or hallucinated steps.",
    "Related Patterns": [
      "Monte-Carlo Planning for Faithful Reasoning"
    ],
    "Uses": "High-stakes decision support, legal reasoning, medical diagnosis, scientific discovery."
  },
  {
    "Pattern Name": "Monte-Carlo Planning for Faithful Reasoning (FAME)",
    "Problem": "Generating reasoning steps that are consistently faithful to the underlying facts or logical rules, especially in complex, multi-step scenarios.",
    "Context": "Tasks where the faithfulness of the reasoning process is critical, and exploring multiple potential reasoning paths can help identify the most reliable one.",
    "Solution": "Employ Monte-Carlo planning techniques to explore a search space of possible reasoning steps. This involves simulating different reasoning trajectories and evaluating their faithfulness or correctness to guide the generation of more reliable steps.",
    "Result": "Improves the faithfulness of LLM-generated reasoning by systematically exploring and validating potential paths, reducing the likelihood of unfaithful deductions.",
    "Related Patterns": [
      "Reasoning Verification",
      "Tree of Thoughts / Graph of Thoughts"
    ],
    "Uses": "Complex logical inference, knowledge graph reasoning, multi-hop question answering."
  },
  {
    "Pattern Name": "Retrieval-Augmented Reasoning",
    "Problem": "LLMs suffer from a lack of up-to-date knowledge, are prone to factual hallucinations, and have limited capacity for very long contexts.",
    "Context": "Knowledge-intensive tasks, factual question answering, or scenarios where LLMs need to reason over specific, external, or dynamic information.",
    "Solution": "Integrate a retrieval mechanism that fetches relevant external knowledge (e.g., documents, knowledge graph triples, database entries) based on the input query or intermediate reasoning steps. This retrieved knowledge is then provided to the LLM as context to inform its reasoning and generation.",
    "Result": "Significantly improves factual accuracy, reduces hallucinations, enables access to real-time or proprietary knowledge, and enhances the faithfulness of LLM reasoning.",
    "Related Patterns": [
      "Agentic LLM with Tool Use",
      "Reasoning on Graphs"
    ],
    "Uses": "Open-domain question answering, factual summarization, knowledge graph question answering."
  },
  {
    "Pattern Name": "LLM as a Semantic Parser",
    "Problem": "Translating natural language questions or commands into precise, executable structured queries (e.g., SPARQL, SQL) for knowledge bases or databases.",
    "Context": "Question answering systems that need to leverage structured data for accurate and interpretable answers, where direct natural language processing is insufficient.",
    "Solution": "Use an LLM to generate a structured query from a natural language input. This query is then executed against a knowledge graph or database to retrieve the answer.",
    "Result": "Enables LLMs to access and reason over structured knowledge with high precision, providing interpretable results by showing the executed query. However, it relies on the executability and correctness of the generated query.",
    "Related Patterns": [
      "Agentic LLM with Tool Use",
      "Retrieval-Augmented Reasoning"
    ],
    "Uses": "Knowledge Graph Question Answering (KGQA), database querying, structured data analysis."
  },
  {
    "Pattern Name": "Reasoning on Graphs (RoG)",
    "Problem": "LLMs lack up-to-date knowledge and hallucinate during reasoning on complex Knowledge Graph Question Answering (KGQA) tasks, and existing KG-LLM methods often overlook the crucial structural information of KGs.",
    "Context": "Knowledge Graph Question Answering (KGQA) tasks requiring faithful, interpretable, and structurally-aware reasoning over large and dynamic knowledge graphs.",
    "Solution": "A planning-retrieval-reasoning framework that synergizes LLMs with KGs:\n1.  **Planning Module:** LLMs generate 'relation paths' (sequences of relations grounded by KGs) as faithful plans.\n2.  **Retrieval Module:** These relation paths are used to retrieve valid 'reasoning paths' (instances of relation paths with specific entities) from the KGs.\n3.  **Reasoning Module:** The LLM then conducts faithful reasoning based on the retrieved reasoning paths and generates answers with interpretable explanations.\nThe system is optimized through planning optimization (distilling KG knowledge into LLMs for path generation) and retrieval-reasoning optimization (enabling LLMs to reason based on retrieved paths). It's also designed to be plug-and-play with different LLMs during inference.",
    "Result": "Achieves state-of-the-art performance on KG reasoning tasks, generates faithful and interpretable reasoning results by leveraging KG structure, and can seamlessly integrate with and improve the performance of arbitrary LLMs.",
    "Related Patterns": [
      "Retrieval-Augmented Reasoning",
      "Plan-and-Solve Prompting / Decomposed Prompting",
      "Agentic LLM with Tool Use",
      "Monte-Carlo Planning for Faithful Reasoning"
    ],
    "Uses": "Knowledge Graph Question Answering, complex factual reasoning, interpretable AI."
  }
]